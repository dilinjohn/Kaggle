{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT on COLA dataset.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "85e09e40e69d422f9750e85da0174d6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_fba5d113a7e142219c1cd2b53a0c5763",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ed1ec3cdf3c14192ad05e50f4e397d5c",
              "IPY_MODEL_6e19ef189c2e4811b2a037b0dc103134"
            ]
          }
        },
        "fba5d113a7e142219c1cd2b53a0c5763": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ed1ec3cdf3c14192ad05e50f4e397d5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_db643c86af78438881a31cb133f95cc7",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_66e4d1c564dd4016837c6b196e0ee463"
          }
        },
        "6e19ef189c2e4811b2a037b0dc103134": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_06f2c84bb48349398ab0f9c8bc824b0a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 817kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_39284bc011ff4faf98a35794be5e3344"
          }
        },
        "db643c86af78438881a31cb133f95cc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "66e4d1c564dd4016837c6b196e0ee463": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "06f2c84bb48349398ab0f9c8bc824b0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "39284bc011ff4faf98a35794be5e3344": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2f7283cda67e4235af19cece2a9e67ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c969212bb7db4c11a4d1259dc1c78476",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_77dbf8d14334431ea66abd41c6865e0f",
              "IPY_MODEL_9d5c22589beb436dabdf48c901bfb0ac"
            ]
          }
        },
        "c969212bb7db4c11a4d1259dc1c78476": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "77dbf8d14334431ea66abd41c6865e0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4e53092ff6c949599169f5901832b885",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1ff639a7298e4cdd9d566fab314b5015"
          }
        },
        "9d5c22589beb436dabdf48c901bfb0ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6a71d6c4be80439dbd0c3c8f12dee37b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:00&lt;00:00, 2.87kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fa1cb8d19dcc438a87d365537d79c7fa"
          }
        },
        "4e53092ff6c949599169f5901832b885": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1ff639a7298e4cdd9d566fab314b5015": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6a71d6c4be80439dbd0c3c8f12dee37b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fa1cb8d19dcc438a87d365537d79c7fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cac7cf493ca84dcba55619d647f2f0af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0a2913ffa61b45e699fe56d1518e454c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a3f28798584d4a95894c63766f384aa5",
              "IPY_MODEL_05950e16f47c4500868e303eaa03ad28"
            ]
          }
        },
        "0a2913ffa61b45e699fe56d1518e454c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a3f28798584d4a95894c63766f384aa5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4d91a3ffd32e4bfea197224e110674ca",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_95d7e5901f804254bbb0cb78408db546"
          }
        },
        "05950e16f47c4500868e303eaa03ad28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5f1a4e39940a4ba6b428baa4f74bcf8c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:21&lt;00:00, 20.4MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4370c3a553094842927eb3e4ea975cf3"
          }
        },
        "4d91a3ffd32e4bfea197224e110674ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "95d7e5901f804254bbb0cb78408db546": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5f1a4e39940a4ba6b428baa4f74bcf8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4370c3a553094842927eb3e4ea975cf3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "sc6x4l38hCUH",
        "colab_type": "code",
        "outputId": "b0da2e39-3f1e-49d5-d923-5e4b676e8cc7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# get the GPU device\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "if device_name == '/device:GPU:0':\n",
        "  print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "  print('No GPU found')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjGtB8rShMR3",
        "colab_type": "code",
        "outputId": "2b7e21a4-8d95-495f-ef7f-cc5249d0b14f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "\n",
        "  # tell PyTorch to use the GPU\n",
        "  device = torch.device('cuda')\n",
        "\n",
        "  print(\"There are %d GPUs available\" %torch.cuda.device_count())\n",
        "  print('Use GPU:', torch.cuda.get_device_name(0))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPUs available\n",
            "Use GPU: Tesla P100-PCIE-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jp8JoPnGi41g",
        "colab_type": "code",
        "outputId": "f55d1894-0bdf-445e-e2af-e46f7466db77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 599
        }
      },
      "source": [
        "! pip install Transformers"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting Transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/22/97/7db72a0beef1825f82188a4b923e62a146271ac2ced7928baa4d47ef2467/transformers-2.9.1-py3-none-any.whl (641kB)\n",
            "\r\u001b[K     |▌                               | 10kB 28.6MB/s eta 0:00:01\r\u001b[K     |█                               | 20kB 6.3MB/s eta 0:00:01\r\u001b[K     |█▌                              | 30kB 7.6MB/s eta 0:00:01\r\u001b[K     |██                              | 40kB 8.1MB/s eta 0:00:01\r\u001b[K     |██▌                             | 51kB 7.2MB/s eta 0:00:01\r\u001b[K     |███                             | 61kB 8.2MB/s eta 0:00:01\r\u001b[K     |███▋                            | 71kB 8.5MB/s eta 0:00:01\r\u001b[K     |████                            | 81kB 8.9MB/s eta 0:00:01\r\u001b[K     |████▋                           | 92kB 9.0MB/s eta 0:00:01\r\u001b[K     |█████                           | 102kB 9.5MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 112kB 9.5MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 122kB 9.5MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 133kB 9.5MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 143kB 9.5MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 153kB 9.5MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 163kB 9.5MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 174kB 9.5MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 184kB 9.5MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 194kB 9.5MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 204kB 9.5MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 215kB 9.5MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 225kB 9.5MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 235kB 9.5MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 245kB 9.5MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 256kB 9.5MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 266kB 9.5MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 276kB 9.5MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 286kB 9.5MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 296kB 9.5MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 307kB 9.5MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 317kB 9.5MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 327kB 9.5MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 337kB 9.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 348kB 9.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 358kB 9.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 368kB 9.5MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 378kB 9.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 389kB 9.5MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 399kB 9.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 409kB 9.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 419kB 9.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 430kB 9.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 440kB 9.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 450kB 9.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 460kB 9.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 471kB 9.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 481kB 9.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 491kB 9.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 501kB 9.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 512kB 9.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 522kB 9.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 532kB 9.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 542kB 9.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 552kB 9.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 563kB 9.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 573kB 9.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 583kB 9.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 593kB 9.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 604kB 9.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 614kB 9.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 624kB 9.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 634kB 9.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 645kB 9.5MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3b/88/49e772d686088e1278766ad68a463513642a2a877487decbd691dec02955/sentencepiece-0.1.90-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\r\u001b[K     |▎                               | 10kB 24.7MB/s eta 0:00:01\r\u001b[K     |▋                               | 20kB 31.1MB/s eta 0:00:01\r\u001b[K     |█                               | 30kB 38.5MB/s eta 0:00:01\r\u001b[K     |█▎                              | 40kB 43.9MB/s eta 0:00:01\r\u001b[K     |█▌                              | 51kB 46.5MB/s eta 0:00:01\r\u001b[K     |█▉                              | 61kB 49.5MB/s eta 0:00:01\r\u001b[K     |██▏                             | 71kB 50.5MB/s eta 0:00:01\r\u001b[K     |██▌                             | 81kB 50.8MB/s eta 0:00:01\r\u001b[K     |██▊                             | 92kB 52.5MB/s eta 0:00:01\r\u001b[K     |███                             | 102kB 31.8MB/s eta 0:00:01\r\u001b[K     |███▍                            | 112kB 31.8MB/s eta 0:00:01\r\u001b[K     |███▊                            | 122kB 31.8MB/s eta 0:00:01\r\u001b[K     |████                            | 133kB 31.8MB/s eta 0:00:01\r\u001b[K     |████▎                           | 143kB 31.8MB/s eta 0:00:01\r\u001b[K     |████▋                           | 153kB 31.8MB/s eta 0:00:01\r\u001b[K     |█████                           | 163kB 31.8MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 174kB 31.8MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 184kB 31.8MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 194kB 31.8MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 204kB 31.8MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 215kB 31.8MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 225kB 31.8MB/s eta 0:00:01\r\u001b[K     |███████                         | 235kB 31.8MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 245kB 31.8MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 256kB 31.8MB/s eta 0:00:01\r\u001b[K     |████████                        | 266kB 31.8MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 276kB 31.8MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 286kB 31.8MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 296kB 31.8MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 307kB 31.8MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 317kB 31.8MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 327kB 31.8MB/s eta 0:00:01\r\u001b[K     |██████████                      | 337kB 31.8MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 348kB 31.8MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 358kB 31.8MB/s eta 0:00:01\r\u001b[K     |███████████                     | 368kB 31.8MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 378kB 31.8MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 389kB 31.8MB/s eta 0:00:01\r\u001b[K     |████████████                    | 399kB 31.8MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 409kB 31.8MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 419kB 31.8MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 430kB 31.8MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 440kB 31.8MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 450kB 31.8MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 460kB 31.8MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 471kB 31.8MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 481kB 31.8MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 491kB 31.8MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 501kB 31.8MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 512kB 31.8MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 522kB 31.8MB/s eta 0:00:01\r\u001b[K     |████████████████                | 532kB 31.8MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 542kB 31.8MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 552kB 31.8MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 563kB 31.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 573kB 31.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 583kB 31.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 593kB 31.8MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 604kB 31.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 614kB 31.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 624kB 31.8MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 634kB 31.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 645kB 31.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 655kB 31.8MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 665kB 31.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 675kB 31.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 686kB 31.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 696kB 31.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 706kB 31.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 716kB 31.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 727kB 31.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 737kB 31.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 747kB 31.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 757kB 31.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 768kB 31.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 778kB 31.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 788kB 31.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 798kB 31.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 808kB 31.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 819kB 31.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 829kB 31.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 839kB 31.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 849kB 31.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 860kB 31.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 870kB 31.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 880kB 31.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 890kB 31.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 901kB 31.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 911kB 31.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 921kB 31.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 931kB 31.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 942kB 31.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 952kB 31.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 962kB 31.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 972kB 31.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 983kB 31.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 993kB 31.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.0MB 31.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.0MB 31.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 1.0MB 31.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.0MB 31.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.0MB 31.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.1MB 31.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.1MB 31.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.1MB 31.8MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/e5/a26eb4716523808bb0a799fcfdceb6ebf77a18169d9591b2f46a9adb87d9/tokenizers-0.7.0-cp36-cp36m-manylinux1_x86_64.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 358kB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from Transformers) (2.23.0)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from Transformers) (0.7)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from Transformers) (4.41.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from Transformers) (2019.12.20)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from Transformers) (1.18.4)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 60.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from Transformers) (3.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->Transformers) (2020.4.5.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->Transformers) (2.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->Transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->Transformers) (3.0.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->Transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->Transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->Transformers) (0.14.1)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=f45b77e0f37fb7a3f22799d6cfe9f6315ccb773609c7550ab7518d7b0f94a3a2\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sentencepiece, tokenizers, sacremoses, Transformers\n",
            "Successfully installed Transformers-2.9.1 sacremoses-0.0.43 sentencepiece-0.1.90 tokenizers-0.7.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bx4danQujOuR",
        "colab_type": "text"
      },
      "source": [
        "Loading the `Cola Dataset`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJpTrFiDjFjK",
        "colab_type": "code",
        "outputId": "5582b60d-296c-4a47-ca27-94aa89c14037",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "!pip install wget"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wget\n",
            "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-cp36-none-any.whl size=9682 sha256=9181bceed75eb201f7577b311897dd6663585c55ca1f01147560180a6ccf4a0d\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRO6bHrtjYvL",
        "colab_type": "code",
        "outputId": "7ea7cd89-6354-4640-b8d6-b063437f7af9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import os\n",
        "import wget\n",
        "\n",
        "url = 'https://nyu-mll.github.io/CoLA/cola_public_1.1.zip'\n",
        "\n",
        "if not os.path.exists('./cola_public_1.1.zip'):\n",
        "  wget.download(url, './cola_public_1.1.zip')\n",
        "  #!wget url\n",
        "\n",
        "for dirname, _, filenames in os.walk('./'):\n",
        "  for filename in filenames:\n",
        "    if 'cola' in filename:\n",
        "      print(os.path.join(dirname, filename))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "./cola_public_1.1.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PwOZjLvTjyff",
        "colab_type": "code",
        "outputId": "29374ba6-99ba-4720-dcf6-2773de134c7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        }
      },
      "source": [
        "# unzip the data\n",
        "if not os.path.exists('./cola_public_1.1/'):\n",
        "  !unzip ./cola_public_1.1.zip"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  ./cola_public_1.1.zip\n",
            "   creating: cola_public/\n",
            "  inflating: cola_public/README      \n",
            "   creating: cola_public/tokenized/\n",
            "  inflating: cola_public/tokenized/in_domain_dev.tsv  \n",
            "  inflating: cola_public/tokenized/in_domain_train.tsv  \n",
            "  inflating: cola_public/tokenized/out_of_domain_dev.tsv  \n",
            "   creating: cola_public/raw/\n",
            "  inflating: cola_public/raw/in_domain_dev.tsv  \n",
            "  inflating: cola_public/raw/in_domain_train.tsv  \n",
            "  inflating: cola_public/raw/out_of_domain_dev.tsv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXIkyjWGly3w",
        "colab_type": "code",
        "outputId": "325ae7a4-bdaa-4e20-fbda-a40dd09bd23e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        }
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('./cola_public/tokenized/in_domain_train.tsv', sep='\\t', header=None, names=['sentence_source', 'label', 'label_notes', 'sentence'])\n",
        "\n",
        "print(df.shape)\n",
        "df.sample(10)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(8551, 4)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_source</th>\n",
              "      <th>label</th>\n",
              "      <th>label_notes</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4119</th>\n",
              "      <td>ks08</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>we know the defendants seem eager to testify a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3674</th>\n",
              "      <td>ks08</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>his friend kicked a ball .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3499</th>\n",
              "      <td>ks08</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>visiting relatives can be boring .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>239</th>\n",
              "      <td>cj99</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>he ate so much that he got sick .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>cj99</td>\n",
              "      <td>0</td>\n",
              "      <td>*</td>\n",
              "      <td>it is important for the more you to eat , the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>415</th>\n",
              "      <td>bc01</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>john believes that he is sick .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4014</th>\n",
              "      <td>ks08</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>the monkey seems despondent .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3750</th>\n",
              "      <td>ks08</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>thunder frightens the dog .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1481</th>\n",
              "      <td>r-67</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>it is not true that it was obvious that it wou...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4799</th>\n",
              "      <td>ks08</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>which book by his father did he read ?</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     sentence_source  ...                                           sentence\n",
              "4119            ks08  ...  we know the defendants seem eager to testify a...\n",
              "3674            ks08  ...                         his friend kicked a ball .\n",
              "3499            ks08  ...                 visiting relatives can be boring .\n",
              "239             cj99  ...                  he ate so much that he got sick .\n",
              "145             cj99  ...  it is important for the more you to eat , the ...\n",
              "415             bc01  ...                    john believes that he is sick .\n",
              "4014            ks08  ...                      the monkey seems despondent .\n",
              "3750            ks08  ...                        thunder frightens the dog .\n",
              "1481            r-67  ...  it is not true that it was obvious that it wou...\n",
              "4799            ks08  ...             which book by his father did he read ?\n",
              "\n",
              "[10 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Z6tFFo2m2S1",
        "colab_type": "text"
      },
      "source": [
        "We care about `sentence` and `label`\n",
        "`label` = 0 , means not grammatically not acceptable\n",
        "`label` = 1, means grammatrically acceptable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gv82lD_wm-pR",
        "colab_type": "code",
        "outputId": "3195e143-c3b6-4bbb-af6f-3b32a0c0b6bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        }
      },
      "source": [
        "df.loc[df.label == 0].sample(5)[['sentence', 'label']]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7829</th>\n",
              "      <td>he replied his answer .</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2245</th>\n",
              "      <td>janet broke at the bread .</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1221</th>\n",
              "      <td>the money which i am discussing the claim that...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5125</th>\n",
              "      <td>which book he read the book was that one .</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7791</th>\n",
              "      <td>what i arranged for jenny was to be present .</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               sentence  label\n",
              "7829                            he replied his answer .      0\n",
              "2245                         janet broke at the bread .      0\n",
              "1221  the money which i am discussing the claim that...      0\n",
              "5125         which book he read the book was that one .      0\n",
              "7791      what i arranged for jenny was to be present .      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0HmVe_AnW_S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get the list of sentences and their lables\n",
        "\n",
        "sentences = df.sentence.values\n",
        "labels = df.label.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fq4M0ZrmnxeN",
        "colab_type": "text"
      },
      "source": [
        "## Using BERT tokenizer\n",
        "we need to use Bert tokenizer before feeding to BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80DKSXbinr8h",
        "colab_type": "code",
        "outputId": "1a4b4dcf-df4e-425d-c8b4-9bfd72cbbe9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "85e09e40e69d422f9750e85da0174d6f",
            "fba5d113a7e142219c1cd2b53a0c5763",
            "ed1ec3cdf3c14192ad05e50f4e397d5c",
            "6e19ef189c2e4811b2a037b0dc103134",
            "db643c86af78438881a31cb133f95cc7",
            "66e4d1c564dd4016837c6b196e0ee463",
            "06f2c84bb48349398ab0f9c8bc824b0a",
            "39284bc011ff4faf98a35794be5e3344"
          ]
        }
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "print('Loading Bert tokenizer.....')\n",
        "# use the uncased pretrained version of the BertTokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading Bert tokenizer.....\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "85e09e40e69d422f9750e85da0174d6f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUnCvhRPpYIT",
        "colab_type": "code",
        "outputId": "8ff73c1f-bf2a-44e8-9f3b-b1be875258eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "# Apply to one sentence and see\n",
        "print('original sentence', sentences[0])\n",
        "print('tokenized', tokenizer.tokenize(sentences[0]))\n",
        "\n",
        "# sentence mapped to token ids\n",
        "print('Token ids: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "original sentence our friends wo n't buy this analysis , let alone the next one we propose .\n",
            "tokenized ['our', 'friends', 'wo', 'n', \"'\", 't', 'buy', 'this', 'analysis', ',', 'let', 'alone', 'the', 'next', 'one', 'we', 'propose', '.']\n",
            "Token ids:  [2256, 2814, 24185, 1050, 1005, 1056, 4965, 2023, 4106, 1010, 2292, 2894, 1996, 2279, 2028, 2057, 16599, 1012]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AuUbfwQ6qKi9",
        "colab_type": "text"
      },
      "source": [
        "The above can be done using `tokenizer.encode(sentences[0])`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVZwnFY4plYt",
        "colab_type": "code",
        "outputId": "029769b7-3135-4eb3-b1fd-394e8251455d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        }
      },
      "source": [
        "print(sentences[0])\n",
        "tokenizer.encode(sentences[0])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "our friends wo n't buy this analysis , let alone the next one we propose .\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[101,\n",
              " 2256,\n",
              " 2814,\n",
              " 24185,\n",
              " 1050,\n",
              " 1005,\n",
              " 1056,\n",
              " 4965,\n",
              " 2023,\n",
              " 4106,\n",
              " 1010,\n",
              " 2292,\n",
              " 2894,\n",
              " 1996,\n",
              " 2279,\n",
              " 2028,\n",
              " 2057,\n",
              " 16599,\n",
              " 1012,\n",
              " 102]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kwH8Dzr1q9Pg",
        "colab_type": "text"
      },
      "source": [
        "## Tokenize Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTefE8zgqUn6",
        "colab_type": "code",
        "outputId": "80034f23-b26a-4451-d2db-7dfec5160735",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# maximum sentence length for padding and truncating\n",
        "\n",
        "max_len = 0\n",
        "for sent in sentences:\n",
        "  # tokenize the text and add the '[CLS]' and '[SEP] tokens\n",
        "  input_ids = tokenizer.encode(sent, add_special_tokens=True)\n",
        "\n",
        "  # update the max_len\n",
        "  max_len = max(max_len, len(input_ids))\n",
        "\n",
        "print('Max sentence length', max_len)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max sentence length 47\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OggpO8IWr5ak",
        "colab_type": "text"
      },
      "source": [
        "In case there are some bigger sentences in text, maximum lenght will be set as `64` instead of `47`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSxSLrkysI9_",
        "colab_type": "text"
      },
      "source": [
        "Now we're ready to perform the real tokenization.\n",
        "\n",
        "The `tokenizer.encode_plus` function combines multiple steps for us:\n",
        "\n",
        "1. Split the sentence into tokens.\n",
        "2. Add the special `[CLS]` and `[SEP]` tokens.\n",
        "3. Map the tokens to their IDs.\n",
        "4. Pad or truncate all sentences to the same length.\n",
        "5. Create the attention masks which explicitly differentiate real tokens from `[PAD]` tokens.\n",
        "  * Mask: 1, means real token\n",
        "  * Mask: 0, mean padded token\n",
        "\n",
        "6. It returns a dictionary of input_ids, token_type_ids and the attention_mask"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eA9yOLKRrwgk",
        "colab_type": "code",
        "outputId": "d696abde-adba-46d2-ed85-ffe83894e3f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        }
      },
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 64,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', sentences[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original:  our friends wo n't buy this analysis , let alone the next one we propose .\n",
            "Token IDs: tensor([  101,  2256,  2814, 24185,  1050,  1005,  1056,  4965,  2023,  4106,\n",
            "         1010,  2292,  2894,  1996,  2279,  2028,  2057, 16599,  1012,   102,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKwvJBimtlUX",
        "colab_type": "code",
        "outputId": "9f8facbb-4a15-4d6e-80f1-798c4ee96d80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "tokenizer.encode_plus(sentences[0])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [101, 2256, 2814, 24185, 1050, 1005, 1056, 4965, 2023, 4106, 1010, 2292, 2894, 1996, 2279, 2028, 2057, 16599, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mS4feTrCtqlq",
        "colab_type": "code",
        "outputId": "0190a1b4-1ec6-471d-9610-7280f34971ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        }
      },
      "source": [
        "input_ids"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 101, 2256, 2814,  ...,    0,    0,    0],\n",
              "        [ 101, 2028, 2062,  ...,    0,    0,    0],\n",
              "        [ 101, 2028, 2062,  ...,    0,    0,    0],\n",
              "        ...,\n",
              "        [ 101, 2009, 2003,  ...,    0,    0,    0],\n",
              "        [ 101, 1045, 2018,  ...,    0,    0,    0],\n",
              "        [ 101, 2054, 2035,  ...,    0,    0,    0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T0SvPdNkRRCS",
        "colab_type": "text"
      },
      "source": [
        "## Training and Validation splits"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dW9B-s09PgpS",
        "colab_type": "code",
        "outputId": "b9a48611-0bb4-4224-8c4e-b3a8b54223ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "\n",
        "# Combine the training inputs into a Tensor Dataset\n",
        "dataset  = TensorDataset(input_ids, attention_masks, labels)\n",
        "\n",
        "# create a 90-10 split for train-validation\n",
        "train_size = int(0.9 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "# divide the dataset by randomly selecting samples\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "print('{:>5,} training samples'.format(train_size))\n",
        "print('{:>5} validation samples'.format(val_size))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7,695 training samples\n",
            "  856 validation samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0dXoFcIYZ9o8",
        "colab_type": "text"
      },
      "source": [
        "create an iterator for a dataset using the torch DataLoader class. This helps to save on memory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0DjnlAuZZ9a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# batch size is requires. For fine tuning BERT, author recommends a batch size of 16 or 32\n",
        "batch_size=32\n",
        "\n",
        "# Data loader for training dataset\n",
        "train_dataloader  = DataLoader(\n",
        "                      train_dataset,\n",
        "                      batch_size = batch_size,\n",
        "                      sampler = RandomSampler(train_dataset)\n",
        "                      )\n",
        "\n",
        "# Data loader for validation\n",
        "# the order does not matter and hence we will just read sequentially\n",
        "validation_dataloader = DataLoader(\n",
        "                          val_dataset,\n",
        "                          batch_size = batch_size,\n",
        "                          sampler = SequentialSampler(val_dataset) # pulls batches sequentially\n",
        "                            )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1up-U0GVbU7J",
        "colab_type": "text"
      },
      "source": [
        "## Train Classification model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-e6gYaDbaOZ",
        "colab_type": "text"
      },
      "source": [
        "For this task, \n",
        "1. we first want to modify the `pre-trained BERT model` to give outputs for classification\n",
        "2. and then we want to continue training the model on our dataset until that the entire model, end-to-end, is well-suited for our task.\n",
        "\n",
        "Thankfully, the **huggingface** pytorch implementation includes a set of interfaces designed for a variety of NLP tasks. **Though these interfaces are all built on top of a trained BERT model, each has different top layers and output types designed to accomodate their specific NLP task**\n",
        "\n",
        "Here is the current list of classes provided for fine-tuning:\n",
        "\n",
        "* BertModel\n",
        "* BertForPreTraining\n",
        "* BertForMaskedLM\n",
        "* BertForNextSentencePrediction\n",
        "* **BertForSequenceClassification** - The one we'll use.\n",
        "* BertForTokenClassification\n",
        "* BertForQuestionAnswering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lKj2HDNbQov",
        "colab_type": "code",
        "outputId": "e252c63a-1c8a-457b-d5b0-5becb0d58529",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "2f7283cda67e4235af19cece2a9e67ea",
            "c969212bb7db4c11a4d1259dc1c78476",
            "77dbf8d14334431ea66abd41c6865e0f",
            "9d5c22589beb436dabdf48c901bfb0ac",
            "4e53092ff6c949599169f5901832b885",
            "1ff639a7298e4cdd9d566fab314b5015",
            "6a71d6c4be80439dbd0c3c8f12dee37b",
            "fa1cb8d19dcc438a87d365537d79c7fa",
            "cac7cf493ca84dcba55619d647f2f0af",
            "0a2913ffa61b45e699fe56d1518e454c",
            "a3f28798584d4a95894c63766f384aa5",
            "05950e16f47c4500868e303eaa03ad28",
            "4d91a3ffd32e4bfea197224e110674ca",
            "95d7e5901f804254bbb0cb78408db546",
            "5f1a4e39940a4ba6b428baa4f74bcf8c",
            "4370c3a553094842927eb3e4ea975cf3"
          ]
        }
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "# load the pretrained BERT model with a single linear classification at the top\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "              'bert-base-uncased', # use the 12 layer BERT model with uncased vocab\n",
        "              num_labels = 2, # for binary_classification\n",
        "              output_attentions = False, # whether the model returns attention weights\n",
        "              output_hidden_states = False, # whether the model outputs all hidden states\n",
        "        )\n",
        "\n",
        "# Tell pytorch to run this model on GPU\n",
        "model.cuda()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2f7283cda67e4235af19cece2a9e67ea",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cac7cf493ca84dcba55619d647f2f0af",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8oHpqH7TeJBf",
        "colab_type": "text"
      },
      "source": [
        "Explore all the model parameters by name\n",
        "Names and dimensions of the weights for:\n",
        "1. The embedding layer\n",
        "2. the first of the 12 transformers\n",
        "3. Output layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myscgiDfdv7r",
        "colab_type": "code",
        "outputId": "27d13515-5e71-41a8-f647-ac6b1df49451",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 632
        }
      },
      "source": [
        "# get the model parameters as a list of tuples\n",
        "params = list(model.named_parameters())\n",
        "\n",
        "print('The BERT model has {:} parameters'.format(len(params)))\n",
        "\n",
        "print('\\n--------Embedding layer-------------\\n')\n",
        "\n",
        "for p in params[0:5]:\n",
        "  #print('{} ------------------------ {}'.format(p[0], str(tuple(p[1].size()))))\n",
        "  # Using {:<55}  {:>12} is text aligment\n",
        "  # {:<55}: allocate 55 spaces to the left for the text, so this aligns from the left\n",
        "  # {:>12}: allocate 12 spaces starting from right, so this aligns from the right\n",
        "  print('{:<55}  {:>12}'.format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n----------First Transformer----------------\\n')\n",
        "for p in params[5:21]:\n",
        "  #print('{} ------------------------- {}'.format(p[0], str(tuple(p[1].size()))))\n",
        "  print('{:<55}  {:>12}'.format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n-----------------Output Layer--------------------\\n')\n",
        "for p in params[-4:]:\n",
        "  #print('{} -------------------------{}'.format(p[0], str(tuple(p[1].size()))))\n",
        "  print('{:<55}  {:>12}'.format(p[0], str(tuple(p[1].size()))))\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The BERT model has 201 parameters\n",
            "\n",
            "--------Embedding layer-------------\n",
            "\n",
            "bert.embeddings.word_embeddings.weight                   (30522, 768)\n",
            "bert.embeddings.position_embeddings.weight                 (512, 768)\n",
            "bert.embeddings.token_type_embeddings.weight                 (2, 768)\n",
            "bert.embeddings.LayerNorm.weight                               (768,)\n",
            "bert.embeddings.LayerNorm.bias                                 (768,)\n",
            "\n",
            "----------First Transformer----------------\n",
            "\n",
            "bert.encoder.layer.0.attention.self.query.weight           (768, 768)\n",
            "bert.encoder.layer.0.attention.self.query.bias                 (768,)\n",
            "bert.encoder.layer.0.attention.self.key.weight             (768, 768)\n",
            "bert.encoder.layer.0.attention.self.key.bias                   (768,)\n",
            "bert.encoder.layer.0.attention.self.value.weight           (768, 768)\n",
            "bert.encoder.layer.0.attention.self.value.bias                 (768,)\n",
            "bert.encoder.layer.0.attention.output.dense.weight         (768, 768)\n",
            "bert.encoder.layer.0.attention.output.dense.bias               (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight         (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias           (768,)\n",
            "bert.encoder.layer.0.intermediate.dense.weight            (3072, 768)\n",
            "bert.encoder.layer.0.intermediate.dense.bias                  (3072,)\n",
            "bert.encoder.layer.0.output.dense.weight                  (768, 3072)\n",
            "bert.encoder.layer.0.output.dense.bias                         (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.weight                   (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.bias                     (768,)\n",
            "\n",
            "-----------------Output Layer--------------------\n",
            "\n",
            "bert.pooler.dense.weight                                   (768, 768)\n",
            "bert.pooler.dense.bias                                         (768,)\n",
            "classifier.weight                                            (2, 768)\n",
            "classifier.bias                                                  (2,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WmjdLmq6oDTJ",
        "colab_type": "text"
      },
      "source": [
        "## Optimizer and Learning Rate scheduler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cqOgcfDoNrv",
        "colab_type": "text"
      },
      "source": [
        "Model is loaded. Now we need to grab the training `hyperparameters` from within the stored model\n",
        "\n",
        "For the purpose of tuning, it is recommended to choose from the following values based on from Appendix A.3 of the [BERT paper]((https://arxiv.org/pdf/1810.04805.pdf):\n",
        "\n",
        ">- **Batch Size**: 16, 32\n",
        "- **Learning Rate(Adam)**: 5e-5, 3e-5, 2e-5\n",
        "- **Number of epochs**: 2, 4\n",
        "\n",
        "The epsilon parameter `eps = 1e-8` is \"a very small number to prevent any division by zero in the implementation\" (from [here](https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QiPEq1Eqe8Ox",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# AdamW is a class from the hugging face library\n",
        "# Adam optimizer with weight decay fix\n",
        "# the parameters passed to the optmizer are the model parameters\n",
        "\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # initial learning rate\n",
        "                  eps = 1e-8 # default\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PU_2UytBtdEh",
        "colab_type": "text"
      },
      "source": [
        "Define the `scheduler` which handles the 'learning rate decay`.\n",
        "When training a NN, you want to take large steps initially for the  initial learning decay rate and take progessively smaller steps as we horne in on the optimal value for the weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAjMa7UHpxex",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# number of training epochs\n",
        "epochs =4\n",
        "\n",
        "# Total number of training steps = [number of batches]  X [number of epochs]\n",
        "# this is not the same as the number of training samples\n",
        "\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# create the learning rate scheduler\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "                                          optimizer,\n",
        "                                          num_warmup_steps = 0, # default value\n",
        "                                          num_training_steps = total_steps\n",
        "                                          )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O13bcsDguoNO",
        "colab_type": "text"
      },
      "source": [
        "## Training Loop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5iCz0ZtvhdD",
        "colab_type": "text"
      },
      "source": [
        "Below is our training loop. There's a lot going on, but fundamentally for each pass in our loop we have a trianing phase and a validation phase. \n",
        "\n",
        "\n",
        "**Training:**\n",
        "- Unpack our data inputs and labels\n",
        "- Load data onto the GPU for acceleration\n",
        "- Clear out the gradients calculated in the previous pass. \n",
        "    - In pytorch the gradients accumulate by default (useful for things like RNNs) unless you explicitly clear them out.\n",
        "- Forward pass (feed input data through the network)\n",
        "- Backward pass (backpropagation)\n",
        "- Tell the network to update parameters with optimizer.step()\n",
        "- Track variables for monitoring progress\n",
        "\n",
        "**Evalution:**\n",
        "- Unpack our data inputs and labels\n",
        "- Load data onto the GPU for acceleration\n",
        "- Forward pass (feed input data through the network)\n",
        "- Compute loss on our validation data and track variables for monitoring progress"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pO8ph_vOvqLk",
        "colab_type": "text"
      },
      "source": [
        "define a helper function for accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQdklmTsuODd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# find accuracy of prediction vs labels\n",
        "\n",
        "def flat_accuracy(preds, labels):\n",
        "  pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "  labels_flat = labels.flatten()\n",
        "  return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7_7vvgNyvmN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# helper function for elaped time\n",
        "\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "  '''\n",
        "  Takes time in seconds and returns\n",
        "  a string in hh:mm:ss\n",
        "  '''\n",
        "  elapsed_rounded = int(round(elapsed))\n",
        "\n",
        "  # format in hh:mm:ss\n",
        "  return str(datetime.timedelta(seconds = elapsed_rounded))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1CkXwCnazzXR",
        "colab_type": "text"
      },
      "source": [
        "## Kick of training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWkX-S_XYSR5",
        "colab_type": "code",
        "outputId": "354ba72a-ea22-4565-bfb4-160cfc9b6026",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import numpy as np\n",
        "import random\n",
        "\n",
        "seed_val = 42\n",
        "\n",
        "epochs=4\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# We'll store a number of quantities such as training and validation loss, \n",
        "# validation accuracy, and timings\n",
        "training_stats= []\n",
        "\n",
        "# measure total time take for the whole run\n",
        "total_t0 = time.time()\n",
        "\n",
        "# for each epoch\n",
        "for epoch_i in range(0, epochs):\n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "\n",
        "    # perform one full pass on the training set\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # measure how long the training epoch takes\n",
        "    t0 = time.time()\n",
        "\n",
        "    # reset the training loss for this epoch\n",
        "    total_train_loss = 0\n",
        "\n",
        "    # put the model in 'train' mode\n",
        "    model.train()\n",
        "\n",
        "    # for each batch of the training data\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        \n",
        "        # progress update every 40 batches\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "          # calculate the elaped time\n",
        "          elapsed = format_time(time.time() - t0)\n",
        "\n",
        "          # report progress\n",
        "          print('Batch: {} of {}.. Elaped time: {:}'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels\n",
        "\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass\n",
        "\n",
        "        model.zero_grad()\n",
        "        \n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        loss, logits = model(\n",
        "                            b_input_ids,\n",
        "                            attention_mask = b_input_mask,\n",
        "                            labels = b_labels,\n",
        "                            token_type_ids = None\n",
        "                          )\n",
        "        \n",
        "        # accumulate the training loss over all batches\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # perform backward pass to calculate the gradients\n",
        "        loss.backward()\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        # update learning rate        \n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss across all batches\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)\n",
        "\n",
        "    # measure how long this epoch took\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epoch took: {:}\".format(training_time))\n",
        "\n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # put the model in evalaution mode\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # evaluate validation set for each epoch\n",
        "\n",
        "    for batch in validation_dataloader:\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "        # the `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels\n",
        "\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_attention_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Tell pytorch not to bother with constructing the compute graph during\n",
        "        # the forward pass, since this is only needed for backprop (training).\n",
        "        with torch.no_grad():\n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            # The documentation for this `model` function is here: \n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "            # values prior to applying an activation function like the softmax.\n",
        "\n",
        "            (loss, logits) = model(\n",
        "                                  b_input_ids,\n",
        "                                  attention_mask = b_attention_mask,\n",
        "                                  labels = b_labels,\n",
        "                                  token_type_ids = None\n",
        "                                )\n",
        "            \n",
        "        # accumulate the validation loss\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        # move the logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids =  b_labels.to('cpu').numpy()\n",
        "\n",
        "        # calaculate the  accuracy for this batch and accumulate over all batches\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "\n",
        "    # report the final accuracy for this validation run\n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    print('Average Accuracy for this validation run is {:.2f}'.format(avg_val_accuracy))\n",
        "\n",
        "    # calculate the average loss across all batches\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "\n",
        "    # measure time taken\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "\n",
        "    print('Average validation loss: {:.2f}'.format(avg_val_loss))\n",
        "    print('Time taken for validation {}'.format(validation_time))\n",
        "\n",
        "    training_stats.append(\n",
        "                {\n",
        "                'epoch': epoch_i + 1,\n",
        "                'Training Loss': avg_train_loss,\n",
        "                'Valid. Loss': avg_val_loss,\n",
        "                'Valid. Accur.': avg_val_accuracy,\n",
        "                'Training Time': training_time,\n",
        "                'Validation Time': validation_time   \n",
        "               }\n",
        "                )\n",
        "    \n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Batch: 40 of 241.. Elaped time: 0:00:08\n",
            "Batch: 80 of 241.. Elaped time: 0:00:16\n",
            "Batch: 120 of 241.. Elaped time: 0:00:24\n",
            "Batch: 160 of 241.. Elaped time: 0:00:32\n",
            "Batch: 200 of 241.. Elaped time: 0:00:40\n",
            "Batch: 240 of 241.. Elaped time: 0:00:48\n",
            "\n",
            "  Average training loss: 0.50\n",
            "  Training epoch took: 0:00:48\n",
            "\n",
            "Running Validation...\n",
            "Average Accuracy for this validation run is 0.82\n",
            "Average validation loss: 0.41\n",
            "Time taken for validation 0:00:02\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "Batch: 40 of 241.. Elaped time: 0:00:08\n",
            "Batch: 80 of 241.. Elaped time: 0:00:16\n",
            "Batch: 120 of 241.. Elaped time: 0:00:24\n",
            "Batch: 160 of 241.. Elaped time: 0:00:32\n",
            "Batch: 200 of 241.. Elaped time: 0:00:39\n",
            "Batch: 240 of 241.. Elaped time: 0:00:47\n",
            "\n",
            "  Average training loss: 0.31\n",
            "  Training epoch took: 0:00:47\n",
            "\n",
            "Running Validation...\n",
            "Average Accuracy for this validation run is 0.84\n",
            "Average validation loss: 0.39\n",
            "Time taken for validation 0:00:02\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "Batch: 40 of 241.. Elaped time: 0:00:08\n",
            "Batch: 80 of 241.. Elaped time: 0:00:16\n",
            "Batch: 120 of 241.. Elaped time: 0:00:24\n",
            "Batch: 160 of 241.. Elaped time: 0:00:32\n",
            "Batch: 200 of 241.. Elaped time: 0:00:40\n",
            "Batch: 240 of 241.. Elaped time: 0:00:47\n",
            "\n",
            "  Average training loss: 0.18\n",
            "  Training epoch took: 0:00:48\n",
            "\n",
            "Running Validation...\n",
            "Average Accuracy for this validation run is 0.82\n",
            "Average validation loss: 0.51\n",
            "Time taken for validation 0:00:02\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "Batch: 40 of 241.. Elaped time: 0:00:08\n",
            "Batch: 80 of 241.. Elaped time: 0:00:16\n",
            "Batch: 120 of 241.. Elaped time: 0:00:24\n",
            "Batch: 160 of 241.. Elaped time: 0:00:32\n",
            "Batch: 200 of 241.. Elaped time: 0:00:39\n",
            "Batch: 240 of 241.. Elaped time: 0:00:47\n",
            "\n",
            "  Average training loss: 0.12\n",
            "  Training epoch took: 0:00:48\n",
            "\n",
            "Running Validation...\n",
            "Average Accuracy for this validation run is 0.84\n",
            "Average validation loss: 0.54\n",
            "Time taken for validation 0:00:02\n",
            "\n",
            "Training complete!\n",
            "Total training took 0:03:17 (h:mm:ss)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KifeD2WuoZRh",
        "colab_type": "text"
      },
      "source": [
        "## Summary of the training process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4PaWboXmAtk",
        "colab_type": "code",
        "outputId": "5858bf0c-d619-49d0-ea97-7611ee90ab8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        }
      },
      "source": [
        "import pandas as pd\n",
        "pd.set_option('precision', 2)\n",
        "\n",
        "# create a dataframe from the training stats\n",
        "df_stats =  pd.DataFrame(data = training_stats)\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "\n",
        "df_stats"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Valid. Loss</th>\n",
              "      <th>Valid. Accur.</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Validation Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.50</td>\n",
              "      <td>0.41</td>\n",
              "      <td>0.82</td>\n",
              "      <td>0:00:48</td>\n",
              "      <td>0:00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.31</td>\n",
              "      <td>0.39</td>\n",
              "      <td>0.84</td>\n",
              "      <td>0:00:47</td>\n",
              "      <td>0:00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.18</td>\n",
              "      <td>0.51</td>\n",
              "      <td>0.82</td>\n",
              "      <td>0:00:48</td>\n",
              "      <td>0:00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.12</td>\n",
              "      <td>0.54</td>\n",
              "      <td>0.84</td>\n",
              "      <td>0:00:48</td>\n",
              "      <td>0:00:02</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n",
              "epoch                                                                         \n",
              "1               0.50         0.41           0.82       0:00:48         0:00:02\n",
              "2               0.31         0.39           0.84       0:00:47         0:00:02\n",
              "3               0.18         0.51           0.82       0:00:48         0:00:02\n",
              "4               0.12         0.54           0.84       0:00:48         0:00:02"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K4CQiE6PbAML",
        "colab_type": "text"
      },
      "source": [
        "Training loss is decreasing with every epoch whereas validation loss is increasing. So this means we are training our model too long and is over-fitting\n",
        "* `Validation loss` is more precise than accuracy because with accuracy, we do not care about exact output value, but just which sides of the threshold it falls on\n",
        "* If we are predicting the correct answer with lesser confidence, then the `validation loss` will catch thisy, while accuracy will not"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oyEH56V3mXhR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "outputId": "2422a679-0663-45be-9f0a-26ccfbf581d2"
      },
      "source": [
        "# plot the losses over epochs\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "#plt.rcParams['figure.figsize'] = (12,6)\n",
        "plt.figure(figsize=(12,5))\n",
        "plt.plot(df_stats['Training Loss'], 'b-o', label='Training')\n",
        "plt.plot(df_stats['Valid. Loss'], 'g-o', label='Validation')\n",
        "\n",
        "plt.title('Loss over epochs')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.legend(loc='lower left')\n",
        "plt.show()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XD7DNatYfsei",
        "colab_type": "text"
      },
      "source": [
        "## Performance on the Test set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v2kQ6Y4If-jO",
        "colab_type": "text"
      },
      "source": [
        "* Evaluate prediction using [Matthew's Correlation Coefficient](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.matthews_corrcoef.html), since this is a metrci wdiely used for COLAB\n",
        "  * Best score: +1, Worst score: -1\n",
        "\n",
        "* Repeat the same steps as done for training\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EMSEoEuMgcdX",
        "colab_type": "text"
      },
      "source": [
        "### Data preparation for test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8M7idMpcoTR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "outputId": "8cdc40d1-3855-49ca-e141-fa66b93d8e11"
      },
      "source": [
        "# check for the test data\n",
        "for dirname, _, filenames in os.walk('./cola_public/'):\n",
        "  for filename in filenames:\n",
        "    print(os.path.join(dirname, filename))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "./cola_public/README\n",
            "./cola_public/tokenized/out_of_domain_dev.tsv\n",
            "./cola_public/tokenized/in_domain_train.tsv\n",
            "./cola_public/tokenized/in_domain_dev.tsv\n",
            "./cola_public/raw/out_of_domain_dev.tsv\n",
            "./cola_public/raw/in_domain_train.tsv\n",
            "./cola_public/raw/in_domain_dev.tsv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_HUQz2Pg89a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "99e667dc-86b1-47ea-e91d-749d272093e5"
      },
      "source": [
        "# load the raw version of the test data, as we need to tokenize using Bert tokenizer as we did for training\n",
        "\n",
        "df_test = pd.read_csv('./cola_public/raw/in_domain_dev.tsv', delimiter='\\t', header = None, \n",
        "                      names = ['sentence_source', 'label', 'label_notes', 'sentence'])\n",
        "\n",
        "print('Number of sentences', df_test.shape[0])\n",
        "print('target label distributions\\n', df_test['label'].value_counts())\n",
        "\n",
        "# create list for sentence and labels\n",
        "sentences = df_test.sentence.values\n",
        "labels = df_test.label.values\n",
        "\n",
        "# Tokenize all sentences and map the tokens to their IDs\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "for sent in sentences:\n",
        "    # using 'encode_plus' on the BERT tokenizer\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                                         sent,\n",
        "                                         add_special_tokens = True,\n",
        "                                         max_length = 64,\n",
        "                                         pad_to_max_length = True,\n",
        "                                         return_tensors = 'pt',\n",
        "                                         return_token_type_ids = False,\n",
        "                                         return_attention_mask = True\n",
        "                                         )\n",
        "    \n",
        "    # add the encoded sentences to the list\n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "\n",
        "    # add the attention masks\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# convert the list into tensors\n",
        "\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.as_tensor(labels)\n",
        "\n",
        "# set the batch_size\n",
        "batch_size = 32\n",
        "\n",
        "# Create the Tensor Dataset and then feed that in batches to the DataLoader\n",
        "prediction_data = TensorDataset(input_ids, attention_masks, labels)\n",
        "\n",
        "# use a sequential sampler to sample from the TensorDatset\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "\n",
        "# use the DataLoader\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler =prediction_sampler, batch_size = batch_size)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of sentences 527\n",
            "target label distributions\n",
            " 1    365\n",
            "0    162\n",
            "Name: label, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKRKhDqwvN7s",
        "colab_type": "text"
      },
      "source": [
        "### Evaluation on the test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7eqmi68hT8T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "5ab01f9c-8217-4046-f316-341bf548a753"
      },
      "source": [
        "# prediction on the test data\n",
        "print('Predicting labels for {} test sentences'.format(len(input_ids)))\n",
        "\n",
        "# put the model in eval mode\n",
        "model.eval()\n",
        "\n",
        "# tracking variables\n",
        "predictions, true_labels = [], []\n",
        "\n",
        "t0 = time.time()\n",
        "\n",
        "# predict\n",
        "for batch in prediction_dataloader:\n",
        "    # add batch to gpu\n",
        "    # `batch` contains three pytorch tensors:\n",
        "    #   [0]: input ids \n",
        "    #   [1]: attention masks\n",
        "    #   [2]: labels\n",
        "\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "    # unpack the inputs from the data loader\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "    # Telling the model not to compute or store gradients, saving memory and \n",
        "    # speeding up prediction\n",
        "\n",
        "    with torch.no_grad():\n",
        "      # forward pass and logit prediction\n",
        "      (loss, logits) = model(\n",
        "                            b_input_ids,\n",
        "                            attention_mask = b_input_mask,\n",
        "                            labels = b_labels,\n",
        "                            token_type_ids = None\n",
        "                            )\n",
        "      \n",
        "    # move the logits and labels to CPU\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    labels_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "    # store the predictions and true labels\n",
        "    predictions.append(logits)\n",
        "    true_labels.append(labels_ids)\n",
        "\n",
        "    \n",
        "\n",
        "print('prediction done for the test dataset')\n",
        "print('Time elapsed: {}'.format(format_time(time.time() - t0)))"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting labels for 527 test sentences\n",
            "prediction done for the test dataset\n",
            "Time elapsed: 0:00:01\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZO24z_OKFgv",
        "colab_type": "text"
      },
      "source": [
        "Accuracy on the CoLA benchmark is measured using the \"[Matthews correlation coefficient](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.matthews_corrcoef.html)\" (MCC).\n",
        "\n",
        "We use MCC here because the classes are imbalanced:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwY_1-ouvfUV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "09981e5b-d471-493d-fe7f-57aaf4fa40c8"
      },
      "source": [
        "print('Positive sample: {} of {}, percent: {:.2f}%'.format(df_test.label.sum(), len(df_test), df_test.label.sum()/ len(df_test) *100))"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Positive sample: 365 of 527, percent: 69.26%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CK1kIuMsMRTe",
        "colab_type": "text"
      },
      "source": [
        "`predictions` has 2 columns for the target variable: `0` and `1`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOCJ2LO7wNKp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b60d249b-5daf-446b-abb8-48c1c7f5e917"
      },
      "source": [
        "predictions[0].shape"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64EuKRM1N7u6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 579
        },
        "outputId": "3b198072-8654-4292-85b7-edc540d0e6d2"
      },
      "source": [
        "# for first batch\n",
        "predictions[0]"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-2.8889222 ,  2.474354  ],\n",
              "       [-3.0595424 ,  2.186653  ],\n",
              "       [-2.7811334 ,  2.1930258 ],\n",
              "       [-2.9911351 ,  2.3691454 ],\n",
              "       [-1.5605103 ,  1.3465897 ],\n",
              "       [-2.406904  ,  2.184461  ],\n",
              "       [-1.718813  ,  0.91929144],\n",
              "       [-1.662456  ,  0.9477272 ],\n",
              "       [-2.714778  ,  1.9349779 ],\n",
              "       [-2.8371122 ,  2.0363214 ],\n",
              "       [-2.5710945 ,  1.6252381 ],\n",
              "       [-2.6217153 ,  1.709917  ],\n",
              "       [-2.8546689 ,  1.8920379 ],\n",
              "       [-1.7358351 ,  1.0410931 ],\n",
              "       [-2.6591558 ,  1.838917  ],\n",
              "       [-2.7687232 ,  1.720714  ],\n",
              "       [-1.141209  ,  0.45763227],\n",
              "       [-2.6364357 ,  1.8507507 ],\n",
              "       [-2.5240486 ,  1.8860533 ],\n",
              "       [-2.470266  ,  1.7901187 ],\n",
              "       [-3.108459  ,  2.304896  ],\n",
              "       [-2.813622  ,  1.9850817 ],\n",
              "       [-2.6531312 ,  1.9192628 ],\n",
              "       [-2.456566  ,  2.0414546 ],\n",
              "       [-2.8342369 ,  2.3708696 ],\n",
              "       [-3.0742104 ,  2.206515  ],\n",
              "       [-3.0685074 ,  2.404764  ],\n",
              "       [-3.1499765 ,  2.3629422 ],\n",
              "       [ 0.28986952, -0.12060783],\n",
              "       [-2.651118  ,  1.9048076 ],\n",
              "       [-2.962783  ,  2.034059  ],\n",
              "       [-3.1123617 ,  2.457011  ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mlaftLPL9EX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "8401577b-72bf-4f03-d09f-c40c75578ce4"
      },
      "source": [
        "# true labels for first batch, there are 17 such batches\n",
        "true_labels[0]"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1,\n",
              "       1, 0, 1, 1, 1, 1, 0, 0, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxJxGmZOMoRv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        },
        "outputId": "75f4b79e-bc15-41bb-d270-c240b51230a3"
      },
      "source": [
        "from sklearn.metrics import matthews_corrcoef\n",
        "\n",
        "matthews_set =[]\n",
        "\n",
        "# Evaluate each test batch using Matthew's correlation coefficient\n",
        "print('Calculating Matthews Corr. Coef. for each batch...')\n",
        "\n",
        "# for each batch\n",
        "# len(true_labels) is the number of batches\n",
        "\n",
        "for i in range(len(true_labels)):\n",
        "    \n",
        "    # The predictions for this batch are a 2-column ndarray (one column for \"0\" \n",
        "    # and one column for \"1\"). Pick the label with the highest value and turn this\n",
        "    # in to a list of 0s and 1s.\n",
        "\n",
        "    pred_labels_batch_i = np.argmax(predictions[i], axis=1).flatten()\n",
        "\n",
        "    # calculate and store the corrcoef for this batch\n",
        "    matthews  = matthews_corrcoef(true_labels[i], pred_labels_batch_i)\n",
        "    matthews_set.append(matthews)\n",
        "\n",
        "print('\\nMatthews correlation coefficient for the entire test set')\n",
        "matthews_set"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Calculating Matthews Corr. Coef. for each batch...\n",
            "\n",
            "Matthews correlation coefficient for the entire test set\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3110855084191276,\n",
              " 0.37084202772044256,\n",
              " 0.41184152944810126,\n",
              " 0.539791896359413,\n",
              " 0.6777749493656265,\n",
              " 0.4732058754737091,\n",
              " 0.49382916465843113,\n",
              " 0.777878154009821,\n",
              " 0.5691908489504616,\n",
              " 0.20672455764868078,\n",
              " 0.5465943944999485,\n",
              " 0.6695340634119862,\n",
              " 0.3578300267477955,\n",
              " 0.8958064164776167,\n",
              " 0.746031746031746,\n",
              " 0.6457765999379483,\n",
              " 0.7071067811865475]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2q19MOCOOru",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 579
        },
        "outputId": "79060d55-0d8c-49b0-a6ca-144ba8466bff"
      },
      "source": [
        "predictions[0]"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-2.8889222 ,  2.474354  ],\n",
              "       [-3.0595424 ,  2.186653  ],\n",
              "       [-2.7811334 ,  2.1930258 ],\n",
              "       [-2.9911351 ,  2.3691454 ],\n",
              "       [-1.5605103 ,  1.3465897 ],\n",
              "       [-2.406904  ,  2.184461  ],\n",
              "       [-1.718813  ,  0.91929144],\n",
              "       [-1.662456  ,  0.9477272 ],\n",
              "       [-2.714778  ,  1.9349779 ],\n",
              "       [-2.8371122 ,  2.0363214 ],\n",
              "       [-2.5710945 ,  1.6252381 ],\n",
              "       [-2.6217153 ,  1.709917  ],\n",
              "       [-2.8546689 ,  1.8920379 ],\n",
              "       [-1.7358351 ,  1.0410931 ],\n",
              "       [-2.6591558 ,  1.838917  ],\n",
              "       [-2.7687232 ,  1.720714  ],\n",
              "       [-1.141209  ,  0.45763227],\n",
              "       [-2.6364357 ,  1.8507507 ],\n",
              "       [-2.5240486 ,  1.8860533 ],\n",
              "       [-2.470266  ,  1.7901187 ],\n",
              "       [-3.108459  ,  2.304896  ],\n",
              "       [-2.813622  ,  1.9850817 ],\n",
              "       [-2.6531312 ,  1.9192628 ],\n",
              "       [-2.456566  ,  2.0414546 ],\n",
              "       [-2.8342369 ,  2.3708696 ],\n",
              "       [-3.0742104 ,  2.206515  ],\n",
              "       [-3.0685074 ,  2.404764  ],\n",
              "       [-3.1499765 ,  2.3629422 ],\n",
              "       [ 0.28986952, -0.12060783],\n",
              "       [-2.651118  ,  1.9048076 ],\n",
              "       [-2.962783  ,  2.034059  ],\n",
              "       [-3.1123617 ,  2.457011  ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1AgCw6zOPYQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "985d640d-87e4-4f44-8143-4a56541788c5"
      },
      "source": [
        "np.argmax(predictions[0], axis=1)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYlZhmpyOdat",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "outputId": "8402f1dd-3e05-4598-e49e-3eaffa4f7217"
      },
      "source": [
        "# Create a bar plot showing the MCC scores for each batch of the test samples\n",
        "\n",
        "plt.figure(figsize=(12,6))\n",
        "sns.barplot(x = np.arange(len(matthews_set)), y = matthews_set)\n",
        "plt.title('MCC score per batch', fontsize=20)\n",
        "plt.xlabel('batch', fontsize=15)\n",
        "plt.ylabel('MCC scores', fontsize=15)\n",
        "plt.show()"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSAutKP9RoiC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e2628177-19e5-467a-c6b2-cdb164987574"
      },
      "source": [
        "print('Mean MCC score is : {:.2f}'.format(np.mean(matthews_set)))"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean MCC score is : 0.55\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQFhi9kbTbQb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}