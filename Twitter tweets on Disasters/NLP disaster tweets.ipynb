{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\n\nimport re # regex\n\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":1,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":2,"outputs":[{"output_type":"stream","text":"/kaggle/input/nlp-getting-started/test.csv\n/kaggle/input/nlp-getting-started/sample_submission.csv\n/kaggle/input/nlp-getting-started/train.csv\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"## 1. Load the data"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data_train = pd.read_csv('/kaggle/input/nlp-getting-started/train.csv')\ndata_test = pd.read_csv('/kaggle/input/nlp-getting-started/test.csv')\ndata_train.head()","execution_count":3,"outputs":[{"output_type":"execute_result","execution_count":3,"data":{"text/plain":"   id keyword location                                               text  \\\n0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n\n   target  \n0       1  \n1       1  \n2       1  \n3       1  \n4       1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>keyword</th>\n      <th>location</th>\n      <th>text</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Our Deeds are the Reason of this #earthquake M...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Forest fire near La Ronge Sask. Canada</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>All residents asked to 'shelter in place' are ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>6</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>13,000 people receive #wildfires evacuation or...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"## 2.Check for missing values"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Size of train data', data_train.shape)\ndata_train.isnull().sum()","execution_count":4,"outputs":[{"output_type":"stream","text":"Size of train data (7613, 5)\n","name":"stdout"},{"output_type":"execute_result","execution_count":4,"data":{"text/plain":"id             0\nkeyword       61\nlocation    2533\ntext           0\ntarget         0\ndtype: int64"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# drop columns: 'keyword', 'location', 'id'\ndata_train.drop(['keyword', 'location', 'id'], axis=1, inplace=True)\nprint('Columns {}, {} and {} have been dropped'.format('keyword', 'location', 'id'))","execution_count":5,"outputs":[{"output_type":"stream","text":"Columns keyword, location and id have been dropped\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train","execution_count":6,"outputs":[{"output_type":"execute_result","execution_count":6,"data":{"text/plain":"                                                   text  target\n0     Our Deeds are the Reason of this #earthquake M...       1\n1                Forest fire near La Ronge Sask. Canada       1\n2     All residents asked to 'shelter in place' are ...       1\n3     13,000 people receive #wildfires evacuation or...       1\n4     Just got sent this photo from Ruby #Alaska as ...       1\n...                                                 ...     ...\n7608  Two giant cranes holding a bridge collapse int...       1\n7609  @aria_ahrary @TheTawniest The out of control w...       1\n7610  M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...       1\n7611  Police investigating after an e-bike collided ...       1\n7612  The Latest: More Homes Razed by Northern Calif...       1\n\n[7613 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Our Deeds are the Reason of this #earthquake M...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Forest fire near La Ronge Sask. Canada</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>All residents asked to 'shelter in place' are ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>13,000 people receive #wildfires evacuation or...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7608</th>\n      <td>Two giant cranes holding a bridge collapse int...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7609</th>\n      <td>@aria_ahrary @TheTawniest The out of control w...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7610</th>\n      <td>M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7611</th>\n      <td>Police investigating after an e-bike collided ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7612</th>\n      <td>The Latest: More Homes Razed by Northern Calif...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>7613 rows Ã— 2 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"## 3. Preprocessing of text data"},{"metadata":{"trusted":true},"cell_type":"code","source":"import nltk\nfrom nltk.corpus import stopwords\n# to stem derived words from the root word\nfrom nltk.stem.porter import PorterStemmer\nimport re","execution_count":7,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Preprocessing text: Stage 1"},{"metadata":{"trusted":true},"cell_type":"code","source":"stop = set(stopwords.words('english'))\npstem = PorterStemmer()\n\n\ndef stop_stem_lower(tweet):\n    try:\n        regex = re.compile('[^a-zA-Z]')\n        tweet = regex.sub(\" \", tweet)\n        tweet = tweet.lower()\n\n        # check for stop words and then stem\n        #tweet = [pstem.stem(word) for word in tweet.split() if word not in stop and len(word)>2]\n        tweet = [pstem.stem(word) for word in tweet.split() if word not in stop]\n        # join the words back\n        tweet = ' '.join(tweet)\n        return tweet\n    except:\n        return 0","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# try on a sample\nsample = data_train.sample(frac=0.01, random_state=1)\nsample['Cleaned text'] = sample['text'].apply(lambda x: stop_stem_lower(x))\nsample","execution_count":9,"outputs":[{"output_type":"execute_result","execution_count":9,"data":{"text/plain":"                                                   text  target  \\\n3228  Goulburn man Henry Van Bilsen missing: Emergen...       1   \n3706  The things we fear most in organizations--fluc...       0   \n6957                            @tsunami_esh ?? hey Esh       0   \n2887  @POTUS you until you drown by water entering t...       0   \n7464  Crawling in my skin\\nThese wounds they will no...       1   \n...                                                 ...     ...   \n299   The latest from @BryanSinger reveals #Storm is...       1   \n1873      sevenfigz has a crush: http://t.co/20B3PnQxMD       1   \n1660  Look: #I have collapsed #after attempting to m...       0   \n6929  why is it trouble@niallhariss / @simply_vain l...       0   \n4493      @eggalie haha I love hurricane because of you       0   \n\n                                           Cleaned text  \n3228  goulburn man henri van bilsen miss emerg servi...  \n3706  thing fear organ fluctuat disturb imbal primar...  \n6957                                tsunami esh hey esh  \n2887  potu drown water enter lung aliv caus great co...  \n7464                               crawl skin wound hea  \n...                                                 ...  \n299   latest bryansing reveal storm queen apocalyps ...  \n1873                   sevenfigz crush http co b pnqxmd  \n1660            look collaps attempt munch endang speci  \n6929  troubl niallhariss simpli vain live http co ia...  \n4493                          eggali haha love hurrican  \n\n[76 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>target</th>\n      <th>Cleaned text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3228</th>\n      <td>Goulburn man Henry Van Bilsen missing: Emergen...</td>\n      <td>1</td>\n      <td>goulburn man henri van bilsen miss emerg servi...</td>\n    </tr>\n    <tr>\n      <th>3706</th>\n      <td>The things we fear most in organizations--fluc...</td>\n      <td>0</td>\n      <td>thing fear organ fluctuat disturb imbal primar...</td>\n    </tr>\n    <tr>\n      <th>6957</th>\n      <td>@tsunami_esh ?? hey Esh</td>\n      <td>0</td>\n      <td>tsunami esh hey esh</td>\n    </tr>\n    <tr>\n      <th>2887</th>\n      <td>@POTUS you until you drown by water entering t...</td>\n      <td>0</td>\n      <td>potu drown water enter lung aliv caus great co...</td>\n    </tr>\n    <tr>\n      <th>7464</th>\n      <td>Crawling in my skin\\nThese wounds they will no...</td>\n      <td>1</td>\n      <td>crawl skin wound hea</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>299</th>\n      <td>The latest from @BryanSinger reveals #Storm is...</td>\n      <td>1</td>\n      <td>latest bryansing reveal storm queen apocalyps ...</td>\n    </tr>\n    <tr>\n      <th>1873</th>\n      <td>sevenfigz has a crush: http://t.co/20B3PnQxMD</td>\n      <td>1</td>\n      <td>sevenfigz crush http co b pnqxmd</td>\n    </tr>\n    <tr>\n      <th>1660</th>\n      <td>Look: #I have collapsed #after attempting to m...</td>\n      <td>0</td>\n      <td>look collaps attempt munch endang speci</td>\n    </tr>\n    <tr>\n      <th>6929</th>\n      <td>why is it trouble@niallhariss / @simply_vain l...</td>\n      <td>0</td>\n      <td>troubl niallhariss simpli vain live http co ia...</td>\n    </tr>\n    <tr>\n      <th>4493</th>\n      <td>@eggalie haha I love hurricane because of you</td>\n      <td>0</td>\n      <td>eggali haha love hurrican</td>\n    </tr>\n  </tbody>\n</table>\n<p>76 rows Ã— 3 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# apply stop_stem_lower(tweet) on the entire train\ntemp = pd.DataFrame()\n\n# changing the width of the column\npd.set_option('display.max_colwidth', 100)\n\nimport time\nstart= time.time()\ntemp['original text'] = data_train['text'].copy()\ntemp['cleaned_text'] = data_train['text'].apply(lambda x: stop_stem_lower(x))\nprint('time taken: ', time.time() - start)\ntemp.head(10)","execution_count":10,"outputs":[{"output_type":"stream","text":"time taken:  3.455626964569092\n","name":"stdout"},{"output_type":"execute_result","execution_count":10,"data":{"text/plain":"                                                                                         original text  \\\n0                                Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all   \n1                                                               Forest fire near La Ronge Sask. Canada   \n2  All residents asked to 'shelter in place' are being notified by officers. No other evacuation or...   \n3                                    13,000 people receive #wildfires evacuation orders in California    \n4             Just got sent this photo from Ruby #Alaska as smoke from #wildfires pours into a school    \n5  #RockyFire Update => California Hwy. 20 closed in both directions due to Lake County fire - #CAf...   \n6      #flood #disaster Heavy rain causes flash flooding of streets in Manitou, Colorado Springs areas   \n7                                          I'm on top of the hill and I can see a fire in the woods...   \n8                      There's an emergency evacuation happening now in the building across the street   \n9                                                 I'm afraid that the tornado is coming to our area...   \n\n                                                                    cleaned_text  \n0                                      deed reason earthquak may allah forgiv us  \n1                                           forest fire near la rong sask canada  \n2          resid ask shelter place notifi offic evacu shelter place order expect  \n3                                    peopl receiv wildfir evacu order california  \n4                           got sent photo rubi alaska smoke wildfir pour school  \n5  rockyfir updat california hwi close direct due lake counti fire cafir wildfir  \n6     flood disast heavi rain caus flash flood street manit colorado spring area  \n7                                                         top hill see fire wood  \n8                                         emerg evacu happen build across street  \n9                                                       afraid tornado come area  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>original text</th>\n      <th>cleaned_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all</td>\n      <td>deed reason earthquak may allah forgiv us</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Forest fire near La Ronge Sask. Canada</td>\n      <td>forest fire near la rong sask canada</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>All residents asked to 'shelter in place' are being notified by officers. No other evacuation or...</td>\n      <td>resid ask shelter place notifi offic evacu shelter place order expect</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>13,000 people receive #wildfires evacuation orders in California</td>\n      <td>peopl receiv wildfir evacu order california</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Just got sent this photo from Ruby #Alaska as smoke from #wildfires pours into a school</td>\n      <td>got sent photo rubi alaska smoke wildfir pour school</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>#RockyFire Update =&gt; California Hwy. 20 closed in both directions due to Lake County fire - #CAf...</td>\n      <td>rockyfir updat california hwi close direct due lake counti fire cafir wildfir</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>#flood #disaster Heavy rain causes flash flooding of streets in Manitou, Colorado Springs areas</td>\n      <td>flood disast heavi rain caus flash flood street manit colorado spring area</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>I'm on top of the hill and I can see a fire in the woods...</td>\n      <td>top hill see fire wood</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>There's an emergency evacuation happening now in the building across the street</td>\n      <td>emerg evacu happen build across street</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>I'm afraid that the tornado is coming to our area...</td>\n      <td>afraid tornado come area</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# to store the cleaned text\n# to use in the next stage for data preprocessing\n\ncorpus = temp['cleaned_text'].values.tolist()\nprint(corpus[:10])\ndel temp","execution_count":11,"outputs":[{"output_type":"stream","text":"['deed reason earthquak may allah forgiv us', 'forest fire near la rong sask canada', 'resid ask shelter place notifi offic evacu shelter place order expect', 'peopl receiv wildfir evacu order california', 'got sent photo rubi alaska smoke wildfir pour school', 'rockyfir updat california hwi close direct due lake counti fire cafir wildfir', 'flood disast heavi rain caus flash flood street manit colorado spring area', 'top hill see fire wood', 'emerg evacu happen build across street', 'afraid tornado come area']\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"### Preprocessing text: Stage 2\n* **Check for words that are occur very less in our tweets**\n* **They should be removed from our Bag of words to reduce dimensionality**\n"},{"metadata":{},"cell_type":"markdown","source":"### 2.1 Using CountVectorizer"},{"metadata":{},"cell_type":"markdown","source":"### CountVectorizer does the following by default:\n- lowercases your text (set lowercase=false if you donâ€™t want lowercasing)\n- uses utf-8 encoding\n- performs tokenization (converts raw text to smaller units of text)\n- uses word level tokenization (meaning each word is treated as a separate token)\n- ignores single characters during tokenization (say goodbye to words like â€˜aâ€™ and â€˜Iâ€™)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# CountVectorizer\nfrom sklearn.feature_extraction.text import CountVectorizer\ncvect = CountVectorizer(stop_words='english') # the stop words were already removed, but i am just adding the paramater here\n\nstart = time.time()\ncvect_fit = cvect.fit_transform(corpus) # this return a 'scipy.sparse.csr.csr_matrix' (Compressed Sparsed row matrix)\nprint(type(cvect_fit))\nprint('Shape of the CSR matrix after the fit and transform method: ', cvect_fit.shape)\nprint('Number of documents in the train corpus: ', data_train.shape[0])\nprint('time taken for CountVectorizer on the cleaned corpus is', time.time() - start)","execution_count":12,"outputs":[{"output_type":"stream","text":"<class 'scipy.sparse.csr.csr_matrix'>\nShape of the CSR matrix after the fit and transform method:  (7613, 18739)\nNumber of documents in the train corpus:  7613\ntime taken for CountVectorizer on the cleaned corpus is 0.2507059574127197\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"### Each row in the CSR matrix represents a document and each column is a feature or a word\n- **Each column entry is the count for that feature in that document**\n\n### CountVectorizer methods:\n- After CountVectorizer has been fit on the corpus:\n    - CountVectorizer().vocabulary_ : returns the unique words and their positions in the sparse CSR matrix\n    - CountVectorizer().get_feature_names() : will list all the features or unique words\n    - CountVectorizer().fit_transform(corpus).toarray(): converts the sparse matrix into an array, where each row is a document in the corpus and each column entry is the occurence of the word in the document\n    - CountVectorizer().fit_transform(corpus).sum(axis=0): returns the frequency of the words/features in the entire corpus. Shape: (1 X number of features)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# the numbers are not 'counts', but the positions in the sparse vector\ndisplay(cvect.vocabulary_)\n\nword_freq_csr = cvect_fit.sum(axis=0) # get the row wise sum of the frequencies of each feature/words across all the documents","execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":"{'deed': 3525,\n 'reason': 13115,\n 'earthquak': 4284,\n 'allah': 389,\n 'forgiv': 5410,\n 'forest': 5404,\n 'near': 10686,\n 'la': 8797,\n 'rong': 13605,\n 'sask': 13938,\n 'canada': 2118,\n 'resid': 13296,\n 'ask': 788,\n 'shelter': 14290,\n 'place': 12132,\n 'notifi': 10995,\n 'offic': 11267,\n 'evacu': 4783,\n 'order': 11512,\n 'expect': 4858,\n 'peopl': 11917,\n 'receiv': 13131,\n 'wildfir': 17530,\n 'california': 2085,\n 'got': 6117,\n 'sent': 14157,\n 'photo': 12026,\n 'rubi': 13728,\n 'alaska': 343,\n 'smoke': 14606,\n 'pour': 12310,\n 'school': 14011,\n 'rockyfir': 13560,\n 'updat': 16649,\n 'hwi': 7111,\n 'close': 2674,\n 'direct': 3774,\n 'lake': 8824,\n 'counti': 3011,\n 'cafir': 2058,\n 'flood': 5308,\n 'disast': 3789,\n 'heavi': 6621,\n 'rain': 12983,\n 'caus': 2250,\n 'flash': 5274,\n 'street': 15093,\n 'manit': 9623,\n 'colorado': 2800,\n 'spring': 14863,\n 'area': 686,\n 'hill': 6754,\n 'wood': 17669,\n 'emerg': 4520,\n 'happen': 6476,\n 'build': 1919,\n 'afraid': 201,\n 'tornado': 16002,\n 'come': 2817,\n 'die': 3739,\n 'heat': 6617,\n 'wave': 17319,\n 'far': 4995,\n 'haha': 6416,\n 'south': 14762,\n 'tampa': 15426,\n 'hah': 6415,\n 'wait': 17239,\n 'second': 14100,\n 'live': 9184,\n 'gonna': 6088,\n 'fvck': 5647,\n 'florida': 5315,\n 'tampabay': 15427,\n 'day': 3434,\n 'lost': 9342,\n 'count': 3007,\n 'bago': 1059,\n 'myanmar': 10519,\n 'arriv': 733,\n 'damag': 3338,\n 'bu': 1892,\n 'multi': 10440,\n 'car': 2164,\n 'crash': 3071,\n 'break': 1762,\n 'man': 9608,\n 'love': 9353,\n 'fruit': 5566,\n 'summer': 15192,\n 'fast': 5011,\n 'goooooooaaaaaal': 6103,\n 'ridicul': 13433,\n 'london': 9299,\n 'cool': 2951,\n 'ski': 14491,\n 'wonder': 17664,\n 'looooool': 9317,\n 'way': 17321,\n 'eat': 4299,\n 'shit': 14314,\n 'nyc': 11137,\n 'week': 17390,\n 'girlfriend': 5960,\n 'cooool': 2954,\n 'like': 9126,\n 'pasta': 11798,\n 'end': 4575,\n 'bbcmtd': 1176,\n 'wholesal': 17502,\n 'market': 9673,\n 'ablaz': 41,\n 'http': 7019,\n 'lhyxeohi': 9079,\n 'alway': 436,\n 'tri': 16147,\n 'bring': 1807,\n 'metal': 9909,\n 'rt': 13706,\n 'yao': 18157,\n 'xngw': 17993,\n 'africanbaz': 205,\n 'news': 10753,\n 'nigeria': 10817,\n 'flag': 5269,\n 'set': 14190,\n 'aba': 18,\n 'nndbgwyei': 10911,\n 'cri': 3109,\n 'plu': 12184,\n 'look': 9313,\n 'sky': 14507,\n 'night': 10822,\n 'qqsmshaj': 12814,\n 'phdsquar': 12004,\n 'mufc': 10427,\n 'built': 1922,\n 'hype': 7137,\n 'new': 10740,\n 'acquisit': 105,\n 'doubt': 4001,\n 'epl': 4660,\n 'season': 14088,\n 'inec': 7452,\n 'abia': 37,\n 'imaomknna': 7349,\n 'barbado': 1112,\n 'bridgetown': 1794,\n 'jamaica': 7791,\n 'santa': 13921,\n 'cruz': 3150,\n 'head': 6588,\n 'st': 14928,\n 'elizabeth': 4485,\n 'polic': 12245,\n 'superintend': 15226,\n 'wdueaj': 17358,\n 'lord': 9326,\n 'check': 2431,\n 'roi': 13575,\n 'nsmejj': 11063,\n 'tj': 15882,\n 'zjin': 18574,\n 'yduixefip': 18197,\n 'lxtjc': 9491,\n 'kl': 8582,\n 'nsfw': 11056,\n 'outsid': 11600,\n 'aliv': 387,\n 'dead': 3477,\n 'insid': 7509,\n 'awesom': 962,\n 'time': 15850,\n 'visit': 17029,\n 'cfc': 2346,\n 'ancop': 510,\n 'site': 14451,\n 'thank': 15660,\n 'tita': 15872,\n 'vida': 16978,\n 'care': 2175,\n 'soooo': 14732,\n 'pump': 12577,\n 'southridgelif': 14770,\n 'want': 17262,\n 'chicago': 2460,\n 'preach': 12367,\n 'hotel': 6944,\n 'qknbfofx': 12755,\n 'gain': 5719,\n 'follow': 5370,\n 'know': 8627,\n 'stat': 14972,\n 'grow': 6250,\n 'tiyulif': 15881,\n 'west': 17419,\n 'burn': 1954,\n 'thousand': 15783,\n 'alon': 416,\n 'vl': 17061,\n 'tbr': 15486,\n 'wbr': 17336,\n 'perfect': 11923,\n 'tracklist': 16071,\n 'life': 9103,\n 'leav': 8961,\n 'retain': 13327,\n 'quit': 12875,\n 'weird': 17401,\n 'better': 1347,\n 'use': 16712,\n 'wear': 17370,\n 'everi': 4796,\n 'singl': 14425,\n 'year': 18202,\n 'deputi': 3615,\n 'shot': 14336,\n 'brighton': 1803,\n 'home': 6876,\n 'gwnrhmso': 6370,\n 'wife': 17523,\n 'jail': 7783,\n 'niec': 10814,\n 'ev': 4778,\n 'ahoucza': 260,\n 'lanford': 8851,\n 'salmon': 13872,\n 'vplr': 17119,\n 'hka': 6796,\n 'sxhw': 15339,\n 'tnnlf': 15930,\n 'arsonist': 738,\n 'deliber': 3562,\n 'black': 1507,\n 'church': 2548,\n 'north': 10966,\n 'carolina': 2199,\n 'pcxarbh': 11865,\n 'noch': 10928,\n 'el': 4448,\n 'bestia': 1337,\n 'alexi': 369,\n 'sanchez': 13899,\n 'happi': 6477,\n 'teammat': 15529,\n 'train': 16089,\n 'hard': 6485,\n 'goodnight': 6094,\n 'gunner': 6333,\n 'uc': 16398,\n 'jhvgr': 7966,\n 'kurd': 8731,\n 'trampl': 16095,\n 'turkmen': 16266,\n 'later': 8879,\n 'vandal': 16830,\n 'diyala': 3860,\n 'izfdyc': 7747,\n 'cg': 2353,\n 'truck': 16202,\n 'voortrekk': 17105,\n 'ave': 935,\n 'tambo': 15423,\n 'intl': 7562,\n 'cargo': 2181,\n 'section': 14104,\n 'kscqkfkkf': 8708,\n 'heart': 6607,\n 'citi': 2584,\n 'gift': 5935,\n 'skylin': 14512,\n 'kiss': 8552,\n 'lip': 9157,\n 'cyompz': 3287,\n 'tonight': 15976,\n 'lo': 9262,\n 'angel': 522,\n 'ig': 7255,\n 'fb': 5032,\n 'sunset': 15218,\n 'peep': 11899,\n 'icsjgz': 7202,\n 'te': 15518,\n 'climat': 2659,\n 'energi': 4587,\n 'fxmn': 5680,\n 'bd': 1209,\n 'revel': 13347,\n 'wmv': 17630,\n 'video': 16979,\n 'mean': 9816,\n 'mac': 9529,\n 'farewel': 4997,\n 'en': 4563,\n 'rout': 13644,\n 'dvd': 4204,\n 'gtxrwm': 6291,\n 'progress': 12464,\n 'greet': 6209,\n 'month': 10271,\n 'student': 15126,\n 'pen': 11906,\n 'torch': 15998,\n 'public': 12555,\n 'fxpixqujt': 5681,\n 'rene': 13250,\n 'amp': 485,\n 'jacinta': 7760,\n 'secret': 14102,\n 'fallen': 4966,\n 'edit': 4344,\n 'mar': 9644,\n 'mlmsuzv': 10166,\n 'navista': 10628,\n 'steve': 15012,\n 'someth': 14706,\n 'els': 4499,\n 'tinderbox': 15860,\n 'clown': 2684,\n 'hood': 6909,\n 'nowplay': 11013,\n 'ian': 7161,\n 'buff': 1912,\n 'magnitud': 9569,\n 'av': 930,\n 'jsjfftc': 8154,\n 'edm': 4349,\n 'nxwestmidland': 11132,\n 'huge': 7036,\n 'rwzbfvnxer': 13795,\n 'talk': 15416,\n 'make': 9590,\n 'work': 17680,\n 'kid': 8501,\n 'cuz': 3238,\n 'bicycl': 1402,\n 'accid': 72,\n 'split': 14840,\n 'testicl': 15616,\n 'imposs': 7383,\n 'michael': 9975,\n 'father': 5019,\n 'nashvilletraff': 10601,\n 'traffic': 16080,\n 'slower': 14568,\n 'usual': 16726,\n 'ghk': 5910,\n 'egj': 4397,\n 'center': 2322,\n 'lane': 8850,\n 'block': 1555,\n 'santaclara': 13922,\n 'nb': 10635,\n 'great': 6192,\n 'america': 465,\n 'pkwi': 12129,\n 'bayarea': 1167,\n 'pmlohzurwr': 12207,\n 'gkye': 5994,\n 'gjtk': 5980,\n 'personalinjuri': 11946,\n 'read': 13092,\n 'advic': 167,\n 'solicitor': 14695,\n 'help': 6653,\n 'otleyhour': 11563,\n 'stloui': 15039,\n 'caraccidentlawy': 2166,\n 'speed': 14812,\n 'teen': 15554,\n 'zomof': 18618,\n 'kxvm': 8774,\n 'cba': 2260,\n 'tee': 15551,\n 'report': 13270,\n 'motor': 10326,\n 'vehicl': 16900,\n 'curri': 3223,\n 'herman': 6668,\n 'rd': 13073,\n 'stephenson': 15005,\n 'involv': 7581,\n 'overturn': 11631,\n 'pleas': 12162,\n 'ybjezkurw': 18173,\n 'bigrigradio': 1419,\n 'awar': 957,\n 'mile': 10016,\n 'marker': 9672,\n 'mooresvil': 10284,\n 'iredel': 7625,\n 'ramp': 13001,\n 'pm': 12194,\n 'sleepjunki': 14542,\n 'sleep': 14540,\n 'pill': 12065,\n 'doubl': 3998,\n 'risk': 13462,\n 'nm': 10895,\n 'fict': 5171,\n 'knew': 8613,\n 'gon': 6085,\n 'ysxun': 18370,\n 'vceh': 16864,\n 'cabrillo': 2043,\n 'magellan': 9560,\n 'mir': 10071,\n 'congest': 2891,\n 'pastor': 11800,\n 'scene': 14001,\n 'owner': 11650,\n 'rang': 13012,\n 'rover': 13649,\n 'mom': 10244,\n 'wish': 17576,\n 'spilt': 14828,\n 'mayonnais': 9754,\n 'horribl': 6931,\n 'past': 11797,\n 'sunday': 15209,\n 'final': 5201,\n 'abl': 40,\n 'god': 6061,\n 'piss': 12092,\n 'donni': 3969,\n 'tell': 15568,\n 'anoth': 559,\n 'truckcrash': 16203,\n 'fortworth': 5428,\n 'interst': 7556,\n 'rs': 13689,\n 'lj': 9205,\n 'qfp': 12721,\n 'click': 2655,\n 'gt': 6279,\n 'ld': 8937,\n 'uniyw': 16591,\n 'ashvil': 781,\n 'sb': 13973,\n 'sr': 14903,\n 'hylmo': 7136,\n 'wgfi': 17451,\n 'motorcyclist': 10329,\n 'cross': 3130,\n 'median': 9831,\n 'motorcycl': 10328,\n 'rider': 13430,\n 'travel': 16115,\n 'lzrlmi': 9521,\n 'fyi': 5688,\n 'cad': 2048,\n 'properti': 12486,\n 'nh': 10790,\n 'piner': 12072,\n 'horndal': 6924,\n 'dr': 4034,\n 'naayf': 10556,\n 'turn': 16267,\n 'chandane': 2385,\n 'magu': 9572,\n 'mma': 10171,\n 'taxi': 15467,\n 'ram': 12998,\n 'halfway': 6435,\n 'everyon': 4803,\n 'conf': 2882,\n 'left': 8976,\n 'manchest': 9610,\n 'eddi': 4335,\n 'stop': 15056,\n 'delay': 3558,\n 'min': 10037,\n 'oia': 11317,\n 'fxi': 5678,\n 'gm': 6036,\n 'wpd': 17721,\n 'th': 15655,\n 'injuri': 7492,\n 'willi': 17535,\n 'foreman': 5402,\n 'vckit': 16870,\n 'edev': 4338,\n 'aashiqui': 13,\n 'actress': 121,\n 'anu': 578,\n 'aggarw': 229,\n 'fatal': 5016,\n 'otfp': 11557,\n 'lqw': 9389,\n 'suffield': 15179,\n 'alberta': 349,\n 'bptmlf': 1720,\n 'backup': 1035,\n 'right': 13438,\n 'exit': 4850,\n 'langtre': 8854,\n 'consid': 2908,\n 'nc': 10653,\n 'altern': 430,\n 'chang': 2389,\n 'determin': 3650,\n 'option': 11482,\n 'financi': 5204,\n 'support': 15237,\n 'plan': 12135,\n 'treatment': 16125,\n 'deadli': 3480,\n 'hagerstown': 6414,\n 'today': 15939,\n 'state': 14973,\n 'whag': 17466,\n 'flowri': 5321,\n 'marinad': 9668,\n 'fuck': 5599,\n 'mf': 9935,\n 'drive': 4078,\n 'norwaymfa': 10979,\n 'bahrain': 1061,\n 'previous': 12418,\n 'road': 13524,\n 'kill': 8522,\n 'explos': 4874,\n 'gfjfgtodad': 5881,\n 'heard': 6604,\n 'leader': 8949,\n 'kenya': 8429,\n 'forward': 5429,\n 'comment': 2829,\n 'issu': 7668,\n 'disciplinari': 3791,\n 'measur': 9821,\n 'arrestpastornganga': 732,\n 'aftershock': 216,\n 'delo': 3568,\n 'scuf': 14055,\n 'ps': 12516,\n 'game': 5735,\n 'cya': 3271,\n 'effort': 4383,\n 'pain': 11696,\n 'win': 17545,\n 'roger': 13568,\n 'bannist': 1100,\n 'ir': 7618,\n 'icemoon': 7187,\n 'ynxnvvkcda': 18300,\n 'djicemoon': 3866,\n 'dubstep': 4153,\n 'trapmus': 16111,\n 'dnb': 3921,\n 'danc': 3354,\n 'ice': 7184,\n 'weqpesenku': 17415,\n 'victori': 16972,\n 'bargain': 1123,\n 'basement': 1142,\n 'price': 12420,\n 'dwight': 4219,\n 'david': 3419,\n 'eisenhow': 4428,\n 'vam': 16825,\n 'podgyw': 12231,\n 'zevakjapcz': 18514,\n 'nobodi': 10927,\n 'rememb': 13236,\n 'came': 2097,\n 'charl': 2406,\n 'schulz': 14014,\n 'im': 7342,\n 'speak': 14794,\n 'someon': 14705,\n 'xb': 17884,\n 'harder': 6491,\n 'conflict': 2888,\n 'gloriou': 6026,\n 'triumph': 16174,\n 'thoma': 15773,\n 'growingupspoil': 6253,\n 'clay': 2634,\n 'pigeon': 12056,\n 'shoot': 14327,\n 'guess': 6307,\n 'actual': 122,\n 'free': 5507,\n 'tc': 15491,\n 'terrifi': 15605,\n 'best': 1333,\n 'roller': 13584,\n 'coaster': 2732,\n 'disclaim': 3792,\n 'xmwodfmtui': 17989,\n 'jdzmgjow': 7885,\n 'uhasfkbv': 16462,\n 'epzhoth': 4665,\n 'kjforday': 8566,\n 'thyzomvwu': 15823,\n 'joo': 8097,\n 'xk': 17960,\n 'wisdomw': 17573,\n 'bonu': 1655,\n 'minut': 10063,\n 'daili': 3322,\n 'habit': 6409,\n 'realli': 13109,\n 'improv': 7386,\n 'mani': 9620,\n 'alreadi': 423,\n 'lifehack': 9106,\n 'tbm': 15483,\n 'fqb': 5469,\n 'cw': 3248,\n 'protect': 12496,\n 'profit': 12460,\n 'global': 6017,\n 'meltdown': 9868,\n 'wiedem': 17521,\n 'wztz': 17872,\n 'hgmvq': 6699,\n 'moment': 10245,\n 'scari': 13993,\n 'guy': 6350,\n 'scream': 14043,\n 'bloodi': 1565,\n 'murder': 10456,\n 'silverwood': 14407,\n 'stream': 15090,\n 'youtub': 18333,\n 'vve': 17176,\n 'usesgf': 16715,\n 'book': 1657,\n 'ntuc': 11070,\n 'esquireattir': 4724,\n 'sometim': 14708,\n 'face': 4934,\n 'difficulti': 3749,\n 'wrong': 17767,\n 'joel': 8059,\n 'osteen': 11551,\n 'thing': 15752,\n 'stand': 14948,\n 'dream': 4057,\n 'belief': 1283,\n 'possibl': 12295,\n 'brown': 1851,\n 'prais': 12356,\n 'ministri': 10055,\n 'wdyouth': 17362,\n 'biblestudi': 1396,\n 'ujk': 16483,\n 'gbcc': 5789,\n 'avoid': 945,\n 'trap': 16109,\n 'think': 15754,\n 'lose': 9338,\n 'job': 8051,\n 'orang': 11500,\n 'onfireand': 11416,\n 'bb': 1170,\n 'jv': 8224,\n 'ppkhji': 12331,\n 'kick': 8500,\n 'say': 13969,\n 'interrupt': 7552,\n 'georg': 5847,\n 'bernard': 1327,\n 'shaw': 14273,\n 'oyster': 11667,\n 'shell': 14288,\n 'andrew': 516,\n 'carnegi': 2196,\n 'anyon': 586,\n 'need': 10695,\n 'play': 12149,\n 'hybrid': 7132,\n 'slayer': 14536,\n 'eu': 4761,\n 'hmu': 6827,\n 'cod': 2748,\n 'sandscrim': 13907,\n 'empirikgam': 4546,\n 'codawscrim': 2749,\n 'tp': 16044,\n 'kotc': 8663,\n 'tpfa': 16047,\n 'org': 11516,\n 'expert': 4863,\n 'franc': 5489,\n 'begin': 1264,\n 'examin': 4830,\n 'airplan': 288,\n 'debri': 3498,\n 'reunion': 13339,\n 'island': 7661,\n 'french': 5531,\n 'air': 280,\n 'yvvpznzmxg': 18411,\n 'strict': 15102,\n 'liabil': 9081,\n 'context': 2929,\n 'pilot': 12068,\n 'error': 4696,\n 'common': 2836,\n 'compon': 2859,\n 'aviat': 942,\n 'cr': 3054,\n 'cz': 3296,\n 'bohrd': 1631,\n 'crobscarla': 3125,\n 'lifetim': 9112,\n 'odd': 11233,\n 'wedn': 17382,\n 'bkpfpogysi': 1498,\n 'alexalltimelow': 363,\n 'awwww': 979,\n 'cuti': 3232,\n 'good': 6089,\n 'famili': 4973,\n 'member': 9869,\n 'osama': 11539,\n 'bin': 1442,\n 'laden': 8808,\n 'iron': 7637,\n 'mhmmm': 9966,\n 'gov': 6126,\n 'suspect': 15269,\n 'goe': 6068,\n 'engin': 4590,\n 'tyjxrfd': 16349,\n 'wing': 17557,\n 'kztevb': 8796,\n 'cessna': 2340,\n 'ocampo': 11217,\n 'coahuila': 2726,\n 'mexico': 9930,\n 'juli': 8186,\n 'men': 9876,\n 'includ': 7407,\n 'govern': 6128,\n 'offici': 11269,\n 'watchthevideo': 17303,\n 'xrvgjik': 18048,\n 'lsmx': 9401,\n 'vwr': 17188,\n 'wednesday': 17384,\n 'began': 1262,\n 'kca': 8374,\n 'votejkt': 17109,\n 'id': 7208,\n 'mbataweel': 9763,\n 'rip': 13456,\n 'binladen': 1446,\n 'cowork': 3030,\n 'nude': 11077,\n 'mode': 10210,\n 'mickinyman': 9983,\n 'theatlant': 15676,\n 'wreck': 17750,\n 'polit': 12250,\n 'tagzbcxfj': 15396,\n 'mlb': 10156,\n 'unbeliev': 16535,\n 'insan': 7505,\n 'airport': 289,\n 'aircraft': 282,\n 'aeroplan': 178,\n 'runway': 13752,\n 'freaki': 5501,\n 'cezhq': 2343,\n 'czll': 3301,\n 'wq': 17731,\n 'wjsgphl': 17597,\n 'tfcdronra': 15630,\n 'usama': 16703,\n 'ladin': 8810,\n 'natur': 10618,\n 'plane': 12136,\n 'festiv': 5126,\n 'kq': 8681,\n 'ae': 174,\n 'ap': 603,\n 'death': 3491,\n 'carfest': 2180,\n 'gibyqhhkpk': 5927,\n 'dtn': 4138,\n 'brazil': 1751,\n 'exp': 4855,\n 'lq': 9383,\n 'smaeslk': 14581,\n 'wtf': 17795,\n 'believ': 1284,\n 'eye': 4902,\n 'ffylajwp': 5145,\n 'nicol': 10811,\n 'fletcher': 5295,\n 'victim': 16970,\n 'ago': 237,\n 'littl': 9179,\n 'bit': 1463,\n 'trauma': 16113,\n 'omg': 11401,\n 'xdxdprcpn': 17910,\n 'bro': 1824,\n 'jetengin': 7924,\n 'turbojet': 16262,\n 'bo': 1619,\n 'kxxnszp': 8776,\n 'nk': 10869,\n 'phone': 12025,\n 'ship': 14308,\n 'terribl': 15603,\n 'statist': 14978,\n 'cop': 2957,\n 'hous': 6952,\n 'colombia': 2795,\n 'zhjlflbhzl': 18545,\n 'iecc': 7236,\n 'jdoub': 7880,\n 'drone': 4090,\n 'worri': 17698,\n 'esp': 4719,\n 'vicin': 16965,\n 'kz': 8790,\n 'rgngjf': 13386,\n 'earli': 4277,\n 'wake': 17241,\n 'sister': 14449,\n 'beg': 1261,\n 'ride': 13428,\n 'ambul': 454,\n 'hospit': 6938,\n 'rodkiai': 13565,\n 'ay': 993,\n 'zzcupnz': 18729,\n 'twelv': 16298,\n 'fear': 5079,\n 'pakistani': 11705,\n 'helicopt': 6641,\n 'sc': 13984,\n 'dn': 3919,\n 'mc': 9770,\n 'seriou': 14180,\n 'lorri': 9333,\n 'pfeaqeski': 11972,\n 'fntg': 5354,\n 'rnkx': 13520,\n 'emsn': 4554,\n 'reuter': 13343,\n 'mdnugvubwn': 9808,\n 'yugvani': 18386,\n 'lead': 8948,\n 'servic': 14185,\n 'boss': 1683,\n 'welcom': 17403,\n 'chariti': 2405,\n 'mj': 10127,\n 'jq': 8131,\n 'psv': 12531,\n 'aberystwyth': 33,\n 'shrewsburi': 14348,\n 'incid': 7402,\n 'halt': 6441,\n 'shrew': 14347,\n 'xum': 18076,\n 'ylcb': 18281,\n 'sprinter': 14866,\n 'automat': 925,\n 'frontlin': 5557,\n 'choic': 2499,\n 'lez': 9046,\n 'compliant': 2857,\n 'ebay': 4306,\n 'evttqpeia': 4814,\n 'nanotech': 10582,\n 'devic': 3667,\n 'target': 15448,\n 'destroy': 3644,\n 'blood': 1562,\n 'clot': 2679,\n 'hfi': 6686,\n 'slbb': 14537,\n 'skyhawkmm': 14509,\n 'traplord': 16110,\n 'fredosantana': 5506,\n 'lilrees': 9135,\n 'hella': 6644,\n 'crazi': 3078,\n 'fight': 5188,\n 'coupl': 3015,\n 'mosh': 10313,\n 'pit': 12093,\n 'run': 13745,\n 'lucki': 9430,\n 'justsay': 8217,\n 'randomthought': 13009,\n 'bfe': 1361,\n 'twbzt': 16288,\n 'til': 15844,\n 'dna': 3920,\n 'xglah': 17934,\n 'zl': 18584,\n 'thmblaatzp': 15769,\n 'tanslash': 15435,\n 'fouseytub': 5442,\n 'ok': 11345,\n 'hahahah': 6419,\n 'zsberqnn': 18658,\n 'ivrzojzv': 7710,\n 'pakistan': 11704,\n 'ry': 13799,\n 'ebmf': 4311,\n 'thenissonian': 15719,\n 'rejectdcartoon': 13210,\n 'nissan': 10841,\n 'medic': 9832,\n 'assist': 812,\n 'em': 4510,\n 'ny': 11133,\n 'emt': 4555,\n 'petit': 11965,\n 'hour': 6950,\n 'minimum': 10052,\n 'wage': 17233,\n 'oa': 11170,\n 'swlxmr': 15321,\n 'paramed': 11759,\n 'fcqmkffflw': 5057,\n 'vayaymbngu': 16851,\n 'brme': 1823,\n 'sn': 14618,\n 'ujrx': 16487,\n 'kgawp': 8468,\n 'kp': 8670,\n 'lf': 9047,\n 'aut': 912,\n 'kiwi': 8559,\n 'karyn': 8334,\n 'park': 11771,\n 'lot': 9343,\n 'said': 13851,\n 'john': 8069,\n 'hpvodud': 6971,\n 'ip': 7596,\n 'lt': 9408,\n 'shzpyiqok': 14361,\n 'pwwpum': 12636,\n 'rbj': 13053,\n 'yspon': 18366,\n 'qo': 12787,\n 'leoblakecart': 9019,\n 'dog': 3949,\n 'mg': 9946,\n 'lpgr': 9379,\n 'rm': 13511,\n 'natasha': 10607,\n 'rideout': 13429,\n 'hatzolah': 6534,\n 'respond': 13311,\n 'dual': 4146,\n 'siren': 14439,\n 'sek': 14127,\n 'mq': 10360,\n 'njf': 10855,\n 'fuerk': 5609,\n 'gwui': 6372,\n 'mv': 10488,\n 'ggglmvc': 5893,\n 'yeuylt': 18227,\n 'ugrmd': 16456,\n 'ywbbeet': 18415,\n 'worldnew': 17690,\n 'qsjod': 12830,\n 'number': 11089,\n 'lesotho': 9031,\n 'bodi': 1629,\n 'aac': 5,\n 'surpris': 15256,\n 'standardis': 14950,\n 'clinic': 2662,\n 'practic': 12351,\n 'trust': 16213,\n 'tyt': 16363,\n 'xrrk': 18045,\n 'nazoi': 10634,\n 'walk': 17248,\n 'pass': 11792,\n 'hate': 6530,\n 'episod': 4655,\n 'trunk': 16212,\n 'annihil': 548,\n 'freiza': 5529,\n 'cleanest': 2639,\n 'nigga': 10819,\n 'merci': 9889,\n 'shall': 14248,\n 'petebest': 11957,\n 'dessic': 3638,\n 'laid': 8820,\n 'bare': 1121,\n 'kneel': 8609,\n 'urib': 16688,\n ...}"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# word frequency\n# the number here indicates the actual frequency of the word in the entire corpus of documents\nword_freq = [(word, word_freq_csr[0, indx]) for word, indx in cvect.vocabulary_.items()]","execution_count":14,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Finding the most frequent words"},{"metadata":{"trusted":true},"cell_type":"code","source":"word_freq_sorted = sorted(word_freq, key = lambda x: x[1], reverse=True)\n# the 10 most frequent words\nword_freq_sorted[:10]","execution_count":15,"outputs":[{"output_type":"execute_result","execution_count":15,"data":{"text/plain":"[('http', 4721),\n ('like', 411),\n ('amp', 344),\n ('bomb', 239),\n ('new', 228),\n ('news', 213),\n ('peopl', 201),\n ('time', 183),\n ('kill', 181),\n ('burn', 180)]"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"### 2.2 Using Counter to count the number of frequent words\n- Ref: https://stackoverflow.com/questions/27488446/how-do-i-get-word-frequency-in-a-corpus-using-scikit-learn-countvectorizer"},{"metadata":{"trusted":true},"cell_type":"code","source":"corpus[:10]","execution_count":16,"outputs":[{"output_type":"execute_result","execution_count":16,"data":{"text/plain":"['deed reason earthquak may allah forgiv us',\n 'forest fire near la rong sask canada',\n 'resid ask shelter place notifi offic evacu shelter place order expect',\n 'peopl receiv wildfir evacu order california',\n 'got sent photo rubi alaska smoke wildfir pour school',\n 'rockyfir updat california hwi close direct due lake counti fire cafir wildfir',\n 'flood disast heavi rain caus flash flood street manit colorado spring area',\n 'top hill see fire wood',\n 'emerg evacu happen build across street',\n 'afraid tornado come area']"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"### Split the words in seach sentence and add them to a list, so that we can apply the Counter()"},{"metadata":{"trusted":true},"cell_type":"code","source":"## Sample\n\ntemp=[]\nfor sent in corpus[:10]:\n    [temp.append(w) for w in sent.split()]\n    \nprint(temp)","execution_count":17,"outputs":[{"output_type":"stream","text":"['deed', 'reason', 'earthquak', 'may', 'allah', 'forgiv', 'us', 'forest', 'fire', 'near', 'la', 'rong', 'sask', 'canada', 'resid', 'ask', 'shelter', 'place', 'notifi', 'offic', 'evacu', 'shelter', 'place', 'order', 'expect', 'peopl', 'receiv', 'wildfir', 'evacu', 'order', 'california', 'got', 'sent', 'photo', 'rubi', 'alaska', 'smoke', 'wildfir', 'pour', 'school', 'rockyfir', 'updat', 'california', 'hwi', 'close', 'direct', 'due', 'lake', 'counti', 'fire', 'cafir', 'wildfir', 'flood', 'disast', 'heavi', 'rain', 'caus', 'flash', 'flood', 'street', 'manit', 'colorado', 'spring', 'area', 'top', 'hill', 'see', 'fire', 'wood', 'emerg', 'evacu', 'happen', 'build', 'across', 'street', 'afraid', 'tornado', 'come', 'area']\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# for the entire train corpus\ntemp_counter= []\n\nfor sent in corpus:\n    [temp_counter.append(w) for w in sent.split()]\n    \n#print(temp_counter)\nprint('Number of words in the corpus is :', len(temp_counter))","execution_count":18,"outputs":[{"output_type":"stream","text":"Number of words in the corpus is : 88103\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"### Using the Counter function"},{"metadata":{},"cell_type":"markdown","source":"### Using the Counter function: Method 1"},{"metadata":{"trusted":true},"cell_type":"code","source":"# On a sample\n\nfrom collections import Counter\nCounter(temp).most_common(10)","execution_count":19,"outputs":[{"output_type":"execute_result","execution_count":19,"data":{"text/plain":"[('fire', 3),\n ('evacu', 3),\n ('wildfir', 3),\n ('shelter', 2),\n ('place', 2),\n ('order', 2),\n ('california', 2),\n ('flood', 2),\n ('street', 2),\n ('area', 2)]"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# on the complete train\n# temp_counter has the complete list\n\nCounter(temp_counter).most_common(10)","execution_count":20,"outputs":[{"output_type":"execute_result","execution_count":20,"data":{"text/plain":"[('co', 4746),\n ('http', 4721),\n ('like', 411),\n ('fire', 363),\n ('amp', 344),\n ('get', 311),\n ('bomb', 239),\n ('new', 228),\n ('via', 220),\n ('u', 216)]"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"### Using the Counter function: Method 2"},{"metadata":{"trusted":true},"cell_type":"code","source":"# On a sample\n\ncounter = Counter()\ncounter.update(temp)\ncounter.most_common(10)","execution_count":21,"outputs":[{"output_type":"execute_result","execution_count":21,"data":{"text/plain":"[('fire', 3),\n ('evacu', 3),\n ('wildfir', 3),\n ('shelter', 2),\n ('place', 2),\n ('order', 2),\n ('california', 2),\n ('flood', 2),\n ('street', 2),\n ('area', 2)]"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# on the complete train\n# temp_counter has the complete list\n\ncounter.update(temp_counter)\ncounter.most_common(10)","execution_count":22,"outputs":[{"output_type":"execute_result","execution_count":22,"data":{"text/plain":"[('co', 4746),\n ('http', 4721),\n ('like', 411),\n ('fire', 366),\n ('amp', 344),\n ('get', 311),\n ('bomb', 239),\n ('new', 228),\n ('via', 220),\n ('u', 216)]"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"### 2.3 Word frequency using custom code or function"},{"metadata":{"trusted":true},"cell_type":"code","source":"WordFrequency=dict()\nfor sent in corpus:\n    for word in sent.split():\n        if word in WordFrequency.keys():\n            WordFrequency[word]+=1\n        else:\n            WordFrequency[word]=1\n            \n\n# convert dictionary to DataFrame\nWordFrequency_df = pd.DataFrame(WordFrequency.items(), columns=['word', 'frequency'])\nWordFrequency_df.sort_values('frequency', ascending=False).head(10)","execution_count":29,"outputs":[{"output_type":"execute_result","execution_count":29,"data":{"text/plain":"      word  frequency\n123     co       4746\n122   http       4721\n115   like        411\n8     fire        363\n341    amp        344\n74     get        311\n2089  bomb        239\n155    new        228\n784    via        220\n256      u        216","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>word</th>\n      <th>frequency</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>123</th>\n      <td>co</td>\n      <td>4746</td>\n    </tr>\n    <tr>\n      <th>122</th>\n      <td>http</td>\n      <td>4721</td>\n    </tr>\n    <tr>\n      <th>115</th>\n      <td>like</td>\n      <td>411</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>fire</td>\n      <td>363</td>\n    </tr>\n    <tr>\n      <th>341</th>\n      <td>amp</td>\n      <td>344</td>\n    </tr>\n    <tr>\n      <th>74</th>\n      <td>get</td>\n      <td>311</td>\n    </tr>\n    <tr>\n      <th>2089</th>\n      <td>bomb</td>\n      <td>239</td>\n    </tr>\n    <tr>\n      <th>155</th>\n      <td>new</td>\n      <td>228</td>\n    </tr>\n    <tr>\n      <th>784</th>\n      <td>via</td>\n      <td>220</td>\n    </tr>\n    <tr>\n      <th>256</th>\n      <td>u</td>\n      <td>216</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"### 2.3.1 From the list of words, consider removing some words or features to reduce dimensions:\n    - There are some words like 'co' and 'http' which doesn not add any valuable information\n    - There are also other words like 'via', 'u, which could also have been removed in the intial regex compilaton for selecting words that have a minimal length of 3\n    - Also we should consider removing words that are very rare as they do not add any value"},{"metadata":{"trusted":true},"cell_type":"code","source":"WordFrequency_df.sort_values('frequency', ascending=True)","execution_count":31,"outputs":[{"output_type":"execute_result","execution_count":31,"data":{"text/plain":"             word  frequency\n18888        rskq          1\n8913   gbvdnczjou          1\n8914         hise          1\n8915           dy          1\n8916      ersdcrh          1\n8917     cpmxmurk          1\n8918       delphi          1\n8919   lmrkgporcf          1\n8920    wadnmstov          1\n8921         bsmj          1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>word</th>\n      <th>frequency</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>18888</th>\n      <td>rskq</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>8913</th>\n      <td>gbvdnczjou</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>8914</th>\n      <td>hise</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>8915</th>\n      <td>dy</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>8916</th>\n      <td>ersdcrh</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>8917</th>\n      <td>cpmxmurk</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>8918</th>\n      <td>delphi</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>8919</th>\n      <td>lmrkgporcf</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>8920</th>\n      <td>wadnmstov</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>8921</th>\n      <td>bsmj</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"### 2.3.2 ** from the histogram plot, there are more than 13K words which have a frequency of 1 **"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.hist(WordFrequency_df['frequency'], range=(0,10))","execution_count":36,"outputs":[{"output_type":"execute_result","execution_count":36,"data":{"text/plain":"(array([    0., 13094.,  1754.,   835.,   550.,   419.,   291.,   212.,\n          186.,   222.]),\n array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.]),\n <a list of 10 Patch objects>)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"?plt.hist","execution_count":33,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### ** More than 69% of the words in the entire train corpus have a word frequency of only 1 **"},{"metadata":{"trusted":true},"cell_type":"code","source":"# verifying the results\ndisplay(WordFrequency_df['frequency'].value_counts()[:10])\n\n# to see the results in percentages\ndisplay(WordFrequency_df['frequency'].value_counts(normalize=True)[:10])","execution_count":40,"outputs":[{"output_type":"display_data","data":{"text/plain":"1     13094\n2      1754\n3       835\n4       550\n5       419\n6       291\n7       212\n8       186\n9       138\n11       86\nName: frequency, dtype: int64"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"1     0.693208\n2     0.092858\n3     0.044206\n4     0.029117\n5     0.022182\n6     0.015406\n7     0.011223\n8     0.009847\n9     0.007306\n11    0.004553\nName: frequency, dtype: float64"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"WordFrequency_df[WordFrequency_df['frequency'] == 1]['word'][:100]","execution_count":42,"outputs":[{"output_type":"execute_result","execution_count":42,"data":{"text/plain":"11          rong\n12          sask\n18        notifi\n51         manit\n80          fvck\n         ...    \n445          mir\n446      congest\n447       pastor\n454        spilt\n455    mayonnais\nName: word, Length: 100, dtype: object"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from nltk.corpus import words as nltk_words","execution_count":44,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nltk_words.words()[:10]","execution_count":50,"outputs":[{"output_type":"execute_result","execution_count":50,"data":{"text/plain":"['A',\n 'a',\n 'aa',\n 'aal',\n 'aalii',\n 'aam',\n 'Aani',\n 'aardvark',\n 'aardwolf',\n 'Aaron']"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"### Check if words with frequency: 1 are valid English words as per English dictionary and if they can be found from the NLTK corpus"},{"metadata":{"trusted":true},"cell_type":"code","source":"start = time.time()\nfreq1 = WordFrequency_df[WordFrequency_df['frequency'] == 1]['word'].values.tolist()\nvalid_words_freq1 = [w for w in freq1 if w in nltk_words.words()]\nprint('time taken to find valid words with a frequency of 1 is', time.time() - start)\nprint('Number of valid words with a frequency of 1 is', len(valid_words_freq1))","execution_count":55,"outputs":[{"output_type":"stream","text":"time taken to find valid words with a frequency of 1 is 1677.8927783966064\nNumber of valid words with a frequency of 1 is 1623\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"valid_words_freq1","execution_count":56,"outputs":[{"output_type":"execute_result","execution_count":56,"data":{"text/plain":"['preach',\n 'retain',\n 'gunner',\n 'tambo',\n 'pen',\n 'tinderbox',\n 'ramp',\n 'mir',\n 'congest',\n 'pastor',\n 'spilt',\n 'median',\n 'halfway',\n 'foreman',\n 'harder',\n 'clay',\n 'pigeon',\n 'disclaim',\n 'silverwood',\n 'interrupt',\n 'oyster',\n 'fletcher',\n 'statist',\n 'shrew',\n 'clot',\n 'minimum',\n 'wage',\n 'kiwi',\n 'clinic',\n 'tyt',\n 'kneel',\n 'sundown',\n 'careen',\n 'toenail',\n 'symbol',\n 'peninsula',\n 'astonish',\n 'fant',\n 'grind',\n 'forthright',\n 'coma',\n 'kebab',\n 'simmon',\n 'quarterstaff',\n 'contributor',\n 'nova',\n 'adapt',\n 'interpret',\n 'geek',\n 'coif',\n 'faction',\n 'hao',\n 'goof',\n 'guild',\n 'doomsday',\n 'gog',\n 'patron',\n 'prove',\n 'begun',\n 'reconnect',\n 'dial',\n 'hep',\n 'mop',\n 'felon',\n 'brig',\n 'gen',\n 'kaiser',\n 'mattress',\n 'sought',\n 'spotlight',\n 'cube',\n 'zodiac',\n 'trey',\n 'chuck',\n 'ust',\n 'mink',\n 'earl',\n 'plead',\n 'relay',\n 'tact',\n 'assail',\n 'secondhand',\n 'vita',\n 'frail',\n 'scholar',\n 'rival',\n 'looser',\n 'wynn',\n 'wrote',\n 'mint',\n 'gyp',\n 'preseason',\n 'ordain',\n 'saver',\n 'blazer',\n 'neal',\n 'draft',\n 'flex',\n 'colonel',\n 'mild',\n 'manner',\n 'baseman',\n 'metropolitan',\n 'phantasm',\n 'cummerbund',\n 'sigh',\n 'span',\n 'oversight',\n 'repress',\n 'biz',\n 'gan',\n 'lithium',\n 'pox',\n 'creation',\n 'frat',\n 'chi',\n 'heiress',\n 'agreement',\n 'allay',\n 'equestrian',\n 'crave',\n 'soh',\n 'virtual',\n 'mim',\n 'jackass',\n 'vela',\n 'whopper',\n 'slogan',\n 'transcend',\n 'stealth',\n 'reddish',\n 'bekah',\n 'escort',\n 'yee',\n 'haw',\n 'satin',\n 'slap',\n 'showdown',\n 'unpack',\n 'slit',\n 'realest',\n 'gunk',\n 'instinct',\n 'grego',\n 'rave',\n 'airhead',\n 'misstep',\n 'receipt',\n 'clue',\n 'arent',\n 'carl',\n 'frost',\n 'someday',\n 'pik',\n 'bridgework',\n 'dotish',\n 'slumber',\n 'taint',\n 'jackman',\n 'flavor',\n 'hump',\n 'worship',\n 'overwatch',\n 'gamin',\n 'dough',\n 'bard',\n 'lure',\n 'wizard',\n 'tora',\n 'reset',\n 'knockout',\n 'gastric',\n 'carcinoma',\n 'gene',\n 'hem',\n 'tight',\n 'lobo',\n 'para',\n 'chapter',\n 'muse',\n 'pone',\n 'cantar',\n 'wasnt',\n 'crayon',\n 'elm',\n 'ghoul',\n 'amend',\n 'beet',\n 'python',\n 'luna',\n 'smirk',\n 'remorseless',\n 'boast',\n 'panther',\n 'legend',\n 'underground',\n 'creeper',\n 'truckload',\n 'manor',\n 'bitten',\n 'lisp',\n 'kennel',\n 'beaten',\n 'metaphor',\n 'anarch',\n 'teapot',\n 'nitroglycerin',\n 'ditto',\n 'drank',\n 'vodka',\n 'lin',\n 'khaki',\n 'copper',\n 'floral',\n 'strap',\n 'lac',\n 'beef',\n 'caption',\n 'ach',\n 'bowknot',\n 'coffin',\n 'stud',\n 'takin',\n 'hamper',\n 'quadrillion',\n 'bye',\n 'disarm',\n 'ratio',\n 'vocalist',\n 'slept',\n 'off',\n 'dap',\n 'therein',\n 'nickle',\n 'loo',\n 'nowt',\n 'drinker',\n 'wraith',\n 'pearl',\n 'compass',\n 'bice',\n 'redskin',\n 'lax',\n 'yard',\n 'wasp',\n 'misfit',\n 'amin',\n 'humanitarian',\n 'narr',\n 'gurt',\n 'cote',\n 'kosher',\n 'xyla',\n 'blower',\n 'den',\n 'kou',\n 'weep',\n 'ransack',\n 'auburn',\n 'detector',\n 'gansey',\n 'prohibit',\n 'char',\n 'rebel',\n 'tore',\n 'straighten',\n 'swoop',\n 'glue',\n 'popcorn',\n 'couch',\n 'pepperoni',\n 'sandwich',\n 'oven',\n 'cocoa',\n 'sip',\n 'ting',\n 'dere',\n 'weightless',\n 'bulletproof',\n 'steep',\n 'terrain',\n 'neon',\n 'modest',\n 'sniff',\n 'web',\n 'lighter',\n 'down',\n 'disrespect',\n 'meteor',\n 'understood',\n 'spout',\n 'slash',\n 'moonbeam',\n 'toke',\n 'plea',\n 'wolter',\n 'rural',\n 'triumphant',\n 'yolk',\n 'aga',\n 'spectrum',\n 'poignant',\n 'rein',\n 'stool',\n 'pine',\n 'coronet',\n 'scenario',\n 'branch',\n 'unpredict',\n 'disconnect',\n 'shine',\n 'portfolio',\n 'lich',\n 'albeit',\n 'unsuccess',\n 'borrow',\n 'puppet',\n 'deb',\n 'twist',\n 'stylist',\n 'chucker',\n 'council',\n 'vanilla',\n 'her',\n 'amino',\n 'glove',\n 'volcan',\n 'pamper',\n 'sig',\n 'ricin',\n 'cartel',\n 'liquid',\n 'rework',\n 'plumb',\n 'glitter',\n 'biller',\n 'regress',\n 'gore',\n 'runaway',\n 'pont',\n 'spike',\n 'goddess',\n 'reaction',\n 'gut',\n 'alley',\n 'panama',\n 'closet',\n 'munch',\n 'piano',\n 'jogger',\n 'until',\n 'touchdown',\n 'veil',\n 'bracelet',\n 'wristband',\n 'gamma',\n 'align',\n 'tiara',\n 'gemma',\n 'finer',\n 'subatom',\n 'yilt',\n 'assault',\n 'useless',\n 'skull',\n 'vermilion',\n 'slither',\n 'shotgun',\n 'peto',\n 'junction',\n 'cern',\n 'southwest',\n 'pole',\n 'florin',\n 'creek',\n 'intertwin',\n 'vale',\n 'outbound',\n 'blair',\n 'jenna',\n 'aft',\n 'helmet',\n 'insert',\n 'stripe',\n 'reader',\n 'yday',\n 'strength',\n 'nightmarish',\n 'husband',\n 'tantrum',\n 'playa',\n 'mortar',\n 'mango',\n 'charcoal',\n 'cor',\n 'bunt',\n 'ouch',\n 'brasswork',\n 'shaken',\n 'crow',\n 'trope',\n 'croze',\n 'violet',\n 'ara',\n 'kodak',\n 'bloke',\n 'damp',\n 'rite',\n 'lim',\n 'vincent',\n 'peal',\n 'vall',\n 'misdirect',\n 'passion',\n 'overblown',\n 'trim',\n 'blend',\n 'hamlet',\n 'ascend',\n 'complain',\n 'emblem',\n 'wha',\n 'champaign',\n 'indigo',\n 'out',\n 'mage',\n 'tail',\n 'contractor',\n 'remand',\n 'sectarian',\n 'militia',\n 'boob',\n 'roadway',\n 'glaucoma',\n 'distract',\n 'poison',\n 'wheat',\n 'trespass',\n 'lest',\n 'nonprofit',\n 'ham',\n 'grave',\n 'wasteland',\n 'grandma',\n 'koi',\n 'nobleman',\n 'thereof',\n 'awaken',\n 'slain',\n 'sedan',\n 'nye',\n 'snippet',\n 'nephew',\n 'airlift',\n 'fraud',\n 'breast',\n 'stall',\n 'warrant',\n 'sander',\n 'beluga',\n 'plud',\n 'awash',\n 'abstract',\n 'towboat',\n 'torment',\n 'fundament',\n 'torrent',\n 'dynast',\n 'me',\n 'unload',\n 'slew',\n 'montana',\n 'ing',\n 'tampon',\n 'decay',\n 'hough',\n 'increment',\n 'exhibitor',\n 'downright',\n 'turner',\n 'shade',\n 'susi',\n 'fiction',\n 'tarp',\n 'outfield',\n 'infield',\n 'afterward',\n 'savour',\n 'prolong',\n 'insect',\n 'rand',\n 'doon',\n 'hater',\n 'precisionist',\n 'vestment',\n 'carbon',\n 'preset',\n 'manhood',\n 'postal',\n 'android',\n 'businessman',\n 'foil',\n 'racial',\n 'tapa',\n 'jar',\n 'colt',\n 'whine',\n 'sounder',\n 'meerkat',\n 'stallion',\n 'youd',\n 'burton',\n 'flint',\n 'onion',\n 'pleb',\n 'fairground',\n 'alec',\n 'tort',\n 'tone',\n 'coe',\n 'willow',\n 'glen',\n 'pisco',\n 'motley',\n 'crook',\n 'establish',\n 'worthless',\n 'depot',\n 'ser',\n 'eve',\n 'nigh',\n 'chipper',\n 'fault',\n 'withstand',\n 'sputter',\n 'vast',\n 'glacier',\n 'liken',\n 'thrive',\n 'hub',\n 'honda',\n 'mason',\n 'violin',\n 'pilgrim',\n 'antichrist',\n 'alt',\n 'scatter',\n 'gin',\n 'redo',\n 'lamb',\n 'abject',\n 'agalloch',\n 'backlash',\n 'fandom',\n 'drago',\n 'institution',\n 'slander',\n 'grub',\n 'kike',\n 'casino',\n 'reg',\n 'gist',\n 'compel',\n 'preschool',\n 'ate',\n 'ambit',\n 'gambia',\n 'lifeguard',\n 'factual',\n 'hitter',\n 'slice',\n 'singh',\n 'greed',\n 'hue',\n 'spec',\n 'lore',\n 'planner',\n 'doom',\n 'tux',\n 'politic',\n 'boulder',\n 'heavyweight',\n 'ventil',\n 'succeed',\n 'transcript',\n 'realist',\n 'asset',\n 'waterproof',\n 'trivium',\n 'myth',\n 'salon',\n 'buffet',\n 'lad',\n 'astrakhan',\n 'locust',\n 'rope',\n 'rebuild',\n 'erd',\n 'breach',\n 'thorium',\n 'propaganda',\n 'nana',\n 'restless',\n 'stain',\n 'photogen',\n 'gosh',\n 'outburst',\n 'circular',\n 'sri',\n 'diplomat',\n 'dampen',\n 'worsen',\n 'neat',\n 'bud',\n 'chore',\n 'activist',\n 'mane',\n 'tambourin',\n 'gecko',\n 'cob',\n 'mustard',\n 'pride',\n 'retroact',\n 'whiskey',\n 'cheer',\n 'labor',\n 'fetch',\n 'pyjama',\n 'swam',\n 'uplift',\n 'alameda',\n 'coke',\n 'scrape',\n 'sketchbook',\n 'mask',\n 'swollen',\n 'acryl',\n 'blank',\n 'cheek',\n 'brunt',\n 'sod',\n 'amman',\n 'morocco',\n 'strait',\n 'tay',\n 'smack',\n 'colin',\n 'unreal',\n 'crescent',\n 'paratroop',\n 'ka',\n 'mag',\n 'humor',\n 'jinx',\n 'eral',\n 'unplug',\n 'oer',\n 'loco',\n 'crucial',\n 'psychic',\n 'stung',\n 'queer',\n 'skeleton',\n 'alchemist',\n 'boon',\n 'extinct',\n 'heartbeat',\n 'familiar',\n 'ace',\n 'amber',\n 'canal',\n 'wart',\n 'appeal',\n 'tuna',\n 'builder',\n 'blackmail',\n 'autism',\n 'underpass',\n 'undon',\n 'brilliant',\n 'about',\n 'circa',\n 'gip',\n 'wat',\n 'helm',\n 'disdain',\n 'nothing',\n 'nep',\n 'epoch',\n 'tweak',\n 'childish',\n 'disregard',\n 'dungeon',\n 'hook',\n 'highland',\n 'dissert',\n 'dismay',\n 'zoo',\n 'roofer',\n 'bulak',\n 'ultimatum',\n 'campground',\n 'minutia',\n 'vei',\n 'can',\n 'puff',\n 'alpha',\n 'twitch',\n 'leaf',\n 'sera',\n 'sidewalk',\n 'kai',\n 'shay',\n 'sailor',\n 'liver',\n 'brewer',\n 'aluminum',\n 'orchard',\n 'vill',\n 'bluff',\n 'blossom',\n 'brass',\n 'hangout',\n 'snuck',\n 'gusto',\n 'pate',\n 'powder',\n 'glean',\n 'hoist',\n 'obit',\n 'schoolboy',\n 'psychologist',\n 'kern',\n 'harvest',\n 'dealer',\n 'freed',\n 'soar',\n 'farmer',\n 'perish',\n 'erect',\n 'export',\n 'lue',\n 'rot',\n 'potato',\n 'peasant',\n 'scorch',\n 'blubber',\n 'pee',\n 'remast',\n 'frame',\n 'flaw',\n 'stump',\n 'possess',\n 'motorist',\n 'interlock',\n 'skinless',\n 'gross',\n 'slay',\n 'motordom',\n 'yield',\n 'neglect',\n 'sting',\n 'corps',\n 'jitter',\n 'basket',\n 'pleasant',\n 'paw',\n 'loser',\n 'sole',\n 'behold',\n 'endless',\n 'recoil',\n 'keeper',\n 'disturb',\n 'loath',\n 'forfeit',\n 'ought',\n 'foolish',\n 'wisdom',\n 'polar',\n 'reed',\n 'opal',\n 'cypress',\n 'header',\n 'rum',\n 'rent',\n 'catalina',\n 'ling',\n 'rainbow',\n 'bon',\n 'more',\n 'brant',\n 'pat',\n 'trident',\n 'pumper',\n 'sticker',\n 'decal',\n 'jo',\n 'racer',\n 'clog',\n 'jade',\n 'award',\n 'dart',\n 'technic',\n 'lender',\n 'fever',\n 'yoga',\n 'silo',\n 'bod',\n 'optimist',\n 'pardon',\n 'mindless',\n 'slaughter',\n 'graph',\n 'papa',\n 'wrestler',\n 'outright',\n 'sam',\n 'rabbit',\n 'lag',\n 'hay',\n 'puck',\n 'implicit',\n 'bald',\n 'heartland',\n 'atheist',\n 'tractor',\n 'pir',\n 'areal',\n 'peek',\n 'deafen',\n 'urban',\n 'elk',\n 'thrust',\n 'womb',\n 'trekker',\n 'mold',\n 'unscreen',\n 'superb',\n 'nester',\n 'dew',\n 'reckon',\n 'sentient',\n 'chieftain',\n 'anew',\n 'voltaic',\n 'petroleum',\n 'bacteria',\n 'bind',\n 'warden',\n 'manzanita',\n 'timber',\n 'column',\n 'dao',\n 'reassign',\n 'acronym',\n 'alga',\n 'bloom',\n 'dump',\n 'pub',\n 'sevenfold',\n 'dak',\n 'stoke',\n 'cereal',\n 'sugar',\n 'thou',\n 'faze',\n 'zel',\n 'overhead',\n 'chef',\n 'holm',\n 're',\n 'mead',\n 'pummel',\n 'sworn',\n 'proven',\n 'hung',\n 'concur',\n 'wayward',\n 'prosper',\n 'miller',\n 'ideal',\n 'guardrail',\n 'politician',\n 'deem',\n 'harden',\n 'flop',\n 'hector',\n 'talisman',\n 'keen',\n 'dreamer',\n 'dean',\n 'tipster',\n 'winger',\n 'assess',\n 'strive',\n 'inject',\n 'vein',\n 'forehead',\n 'flare',\n 'extract',\n 'lightman',\n 'heir',\n 'frighten',\n 'cork',\n 'aal',\n 'lipstick',\n 'hotter',\n 'vol',\n 'orchid',\n 'rude',\n 'hunchback',\n 'cocktail',\n 'verd',\n 'mezcal',\n 'bitter',\n 'hoof',\n 'scam',\n 'sarcast',\n 'fide',\n 'incident',\n 'fiat',\n 'harman',\n 'vuln',\n 'pedro',\n 'jab',\n 'testa',\n 'tam',\n 'maud',\n 'jag',\n 'hitch',\n 'ultra',\n 'earnest',\n 'waiver',\n 'snort',\n 'purport',\n 'rumor',\n 'wut',\n 'ditch',\n 'stood',\n 'superior',\n 'ssu',\n 'meaningless',\n 'damsel',\n 'distress',\n 'peer',\n 'carolin',\n 'supermarket',\n 'languish',\n 'florid',\n 'behaviour',\n 'div',\n 'fought',\n 'grape',\n 'burner',\n 'margarita',\n 'holt',\n 'sunburn',\n 'watermelon',\n 'fecal',\n 'mesh',\n 'yelp',\n 'yeat',\n 'barcelona',\n 'alba',\n 'bilic',\n 'cwm',\n 'ironman',\n 'creep',\n 'derma',\n 'bracket',\n 'cramp',\n 'wreak',\n 'chandler',\n 'railroad',\n 'shad',\n 'groin',\n 'sprain',\n 'termin',\n 'costa',\n 'copa',\n 'dal',\n 'stern',\n 'ala',\n 'champ',\n 'gio',\n 'quirk',\n 'woe',\n 'hawk',\n 'reign',\n 'coco',\n 'dent',\n 'deduct',\n 'moist',\n 'palmer',\n 'mistress',\n 'trader',\n 'banana',\n 'malt',\n 'loaf',\n ...]"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# save the contents of this list for later use\n# since the search is extensive from the previous cell: output as below\n# time taken to find valid words with a frequency of 1 is 1677.8927783966064 seconds\n# Number of valid words with a frequency of 1 is 1623\n\nimport pickle\npickle.dump(valid_words_freq1, open('valid_words_freq1.pkl', 'wb'))","execution_count":57,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2.3.3  For the below code, I will consider only those words that have frequency of > 20"},{"metadata":{"trusted":true},"cell_type":"code","source":"WordFrequency_df20 = WordFrequency_df[WordFrequency_df['frequency'] >= 20]\nprint(WordFrequency_df20.shape)","execution_count":77,"outputs":[{"output_type":"stream","text":"(787, 2)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"WordFrequency_df20.sort_values('frequency', inplace=True, ascending=False)\nWordFrequency_df20.set_index('word', inplace=True)\nWordFrequency_df20","execution_count":78,"outputs":[{"output_type":"execute_result","execution_count":78,"data":{"text/plain":"       frequency\nword            \nco          4746\nhttp        4721\nlike         411\nfire         363\namp          344\n...          ...\nbeach         20\narriv         20\npilot         20\nvs            20\ncarri         20\n\n[787 rows x 1 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>frequency</th>\n    </tr>\n    <tr>\n      <th>word</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>co</th>\n      <td>4746</td>\n    </tr>\n    <tr>\n      <th>http</th>\n      <td>4721</td>\n    </tr>\n    <tr>\n      <th>like</th>\n      <td>411</td>\n    </tr>\n    <tr>\n      <th>fire</th>\n      <td>363</td>\n    </tr>\n    <tr>\n      <th>amp</th>\n      <td>344</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>beach</th>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>arriv</th>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>pilot</th>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>vs</th>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>carri</th>\n      <td>20</td>\n    </tr>\n  </tbody>\n</table>\n<p>787 rows Ã— 1 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"## 3. Create a Bag of words, using a sparse matrix\n- Use a CountVectorizer, with max_features = number of unique words"},{"metadata":{"trusted":true},"cell_type":"code","source":"countVec = CountVectorizer(max_features=WordFrequency_df20.shape[0])\nstart = time.time()\ncountVec_fit = countVec.fit_transform(corpus)\nprint('time taken:', time.time() - start)","execution_count":81,"outputs":[{"output_type":"stream","text":"time taken: 0.24408268928527832\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"countVec_fit","execution_count":85,"outputs":[{"output_type":"execute_result","execution_count":85,"data":{"text/plain":"<7613x787 sparse matrix of type '<class 'numpy.int64'>'\n\twith 45346 stored elements in Compressed Sparse Row format>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"### To view the contents of the CSR matrix, use either:\n - ** toarray() method **\n - ** todense() method **"},{"metadata":{"trusted":true},"cell_type":"code","source":"display(countVec_fit.toarray()), display(countVec_fit.todense())\nbagOfwords = countVec_fit.toarray()","execution_count":95,"outputs":[{"output_type":"display_data","data":{"text/plain":"array([[0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0],\n       ...,\n       [0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0],\n       [1, 0, 0, ..., 0, 0, 0]])"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"matrix([[0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0],\n        ...,\n        [0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0],\n        [1, 0, 0, ..., 0, 0, 0]])"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"## 4. Machine Models"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = bagOfwords\ny = data_train['target']","execution_count":96,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score","execution_count":98,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 4.1 Decision Tree Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\n\n#dt = DecisionTreeClassifier(max_depth= 10, min_samples_split=10)\nstart = time.time()\ndt = DecisionTreeClassifier()\ndt_f1_scores = cross_val_score(dt, X, y, cv=5, scoring='f1')\ndt_roc_auc_scores = cross_val_score(dt, X, y, cv=5, scoring='roc_auc')\nprint('Time take for DecisionTreeClassifier is: ', time.time() - start)\nprint('Mean f1 score for DecisionTreeClassifier is: ', dt_f1_scores.mean())\nprint('Mean roc_auc_score for DecisionTreeClassifier is: ', dt_roc_auc_scores.mean())","execution_count":109,"outputs":[{"output_type":"stream","text":"Time take for DecisionTreeClassifier is:  30.27559757232666\nMean f1 score is:  0.5376555931910773\nMean roc_auc_score is:  0.5979259157708822\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# to view the parameters\n?DecisionTreeClassifier","execution_count":92,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 4.2 Gradient Boosting model"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingClassifier\ngbc = GradientBoostingClassifier()\ngbc_f1_scores = cross_val_score(gbc, X, y, cv=5, scoring='f1')\ngbc_roc_auc_scores = cross_val_score(gbc, X, y, cv=5, scoring='roc_auc')\nprint('Time take for GradientBoostingClassifier is: ', time.time() - start)\nprint('Mean f1 score for GradientBoostingClassifier is: ', gbc_f1_scores.mean())\nprint('Mean roc_auc_score for GradientBoostingClassifier is: ', gbc_roc_auc_scores.mean())","execution_count":110,"outputs":[{"output_type":"stream","text":"Time take for GradientBoostingClassifier is:  72.46379160881042\nMean f1 score is:  0.53584878296336\nMean roc_auc_score is:  0.6060133970861922\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"?GradientBoostingClassifier","execution_count":108,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 4.3 K-Nearest Neighbors Classifier(KNN)"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier()\nknn_f1_scores = cross_val_score(knn, X, y, cv=5, scoring='f1')\nknn_roc_auc_scores = cross_val_score(knn, X, y, cv=5, scoring='roc_auc')\nprint('Time take for KNeighborsClassifier is: ', time.time() - start)\nprint('Mean f1 score for KNeighborsClassifier is: ', knn_f1_scores.mean())\nprint('Mean roc_auc_score for KNeighborsClassifier is: ', knn_roc_auc_scores.mean())","execution_count":111,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"?KNeighborsClassifier","execution_count":112,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}