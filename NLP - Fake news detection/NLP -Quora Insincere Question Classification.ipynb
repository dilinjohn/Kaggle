{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":83,"outputs":[{"output_type":"stream","text":"/kaggle/input/paragram-300-sl999/paragram_300_sl999.txt\n/kaggle/input/quora-insincere-questions-classification/train.csv\n/kaggle/input/quora-insincere-questions-classification/embeddings.zip\n/kaggle/input/quora-insincere-questions-classification/test.csv\n/kaggle/input/quora-insincere-questions-classification/sample_submission.csv\n/kaggle/input/glove840b300dtxt/glove.840B.300d.txt\n/kaggle/input/wikinews300d1mvec/wiki-news-300d-1M.vec\n","name":"stdout"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport time\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\n\nfrom tqdm import tqdm\nimport math\n\nimport seaborn as sns\n%matplotlib inline\n\nimport gc\ngc.collect()\ntime.sleep(5)","execution_count":84,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv('../input/quora-insincere-questions-classification/train.csv')\ntest_df = pd.read_csv('../input/quora-insincere-questions-classification/test.csv')\nprint(train_df.shape)\nprint(test_df.shape)\ndisplay(train_df.head())","execution_count":85,"outputs":[{"output_type":"stream","text":"(1306122, 3)\n(375806, 2)\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"                    qid                                      question_text  \\\n0  00002165364db923c7e6  How did Quebec nationalists see their province...   \n1  000032939017120e6e44  Do you have an adopted dog, how would you enco...   \n2  0000412ca6e4628ce2cf  Why does velocity affect time? Does velocity a...   \n3  000042bf85aa498cd78e  How did Otto von Guericke used the Magdeburg h...   \n4  0000455dfa3e01eae3af  Can I convert montra helicon D to a mountain b...   \n\n   target  \n0       0  \n1       0  \n2       0  \n3       0  \n4       0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>qid</th>\n      <th>question_text</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>00002165364db923c7e6</td>\n      <td>How did Quebec nationalists see their province...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>000032939017120e6e44</td>\n      <td>Do you have an adopted dog, how would you enco...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0000412ca6e4628ce2cf</td>\n      <td>Why does velocity affect time? Does velocity a...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>000042bf85aa498cd78e</td>\n      <td>How did Otto von Guericke used the Magdeburg h...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0000455dfa3e01eae3af</td>\n      <td>Can I convert montra helicon D to a mountain b...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Check for data imbalance"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(train_df.target)","execution_count":86,"outputs":[{"output_type":"execute_result","execution_count":86,"data":{"text/plain":"<matplotlib.axes._subplots.AxesSubplot at 0x7feb3e6e8150>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"metadata":{},"cell_type":"markdown","source":"Check for missing values"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.isnull().sum()","execution_count":87,"outputs":[{"output_type":"execute_result","execution_count":87,"data":{"text/plain":"qid              0\nquestion_text    0\ntarget           0\ndtype: int64"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.isna().sum()","execution_count":88,"outputs":[{"output_type":"execute_result","execution_count":88,"data":{"text/plain":"qid              0\nquestion_text    0\ndtype: int64"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Do the following in the next steps:\n\n* Split the train into train and validation sets. We will not do cross valdiation as it is time consuming\n* No missing values identified, if any, replace them with 'na'\n* Tokenize the `text` column and convert them to vector sequences\n* Pad or truncate the sequences as required - truncation happens when sequence length exceeds `max_len` and if less, they will be padded"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n# split into train and validation sets\n\ntrain_df, valid_df = train_test_split(train_df, test_size=0.1, random_state=2020)\n\n# some config values for tokenization and vector sequences\n\nmax_len = 100        # max number of words in the question that will be used\nmax_features = 50000 # max number of features or unique words we will use from the entire corpus (the same as number of rows in the embedding matrix)\nembed_size = 300     # size of each embedding or word vector","execution_count":89,"outputs":[{"output_type":"stream","text":"CPU times: user 328 ms, sys: 2.23 ms, total: 330 ms\nWall time: 420 ms\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n# substitute missing values in text\ntrain_X = train_df['question_text'].fillna(\"_na_\")\nvalid_X = valid_df['question_text'].fillna(\"_na_\")\ntest_X = test_df['question_text'].fillna(\"_na_\")\n\n# tokenize the sentences\nfrom keras.preprocessing.text import Tokenizer\n\ntokenizer = Tokenizer(num_words = max_features)\n\n# fit on train_X. fit_on_texts() expects a list of text as input\ntokenizer.fit_on_texts(train_X.values.tolist())\n\n# use fit_to_sequences method to encode the tokens or words into interger sequences\ntrain_X = tokenizer.texts_to_sequences(train_X.values)\nvalid_X = tokenizer.texts_to_sequences(valid_X.values)\ntest_X = tokenizer.texts_to_sequences(test_X.values)\n\n# pad the sentences, according to the max_len\nfrom keras.preprocessing.sequence import pad_sequences\n\ntrain_X = pad_sequences(train_X, maxlen = max_len)\nvalid_X = pad_sequences(valid_X, maxlen = max_len)\ntest_X = pad_sequences(test_X, maxlen = max_len)\n\n# store the target values\ntrain_y = train_df['target'].values\nvalid_y = valid_df['target'].values","execution_count":90,"outputs":[{"output_type":"stream","text":"CPU times: user 1min 16s, sys: 140 ms, total: 1min 17s\nWall time: 1min 17s\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"### Without using any of the trained embeddings provided:\nWe will learn the embeddings from scratch without using any of the trained embeddings as the first step. For this we will train a Bidirectional GRU model. We will use the CUDA based NN model from Nvidia known as th CuDNNGRU, which is GPU based."},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Model, Sequential\nfrom keras.layers import Input, Embedding, CuDNNGRU, Dense, Dropout, LSTM, Conv1D, Activation, GRU\nfrom keras.layers import Bidirectional, GlobalMaxPool1D\n\nfrom keras import initializers, regularizers, constraints, optimizers, layers","execution_count":91,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# tensorflow version check\nimport tensorflow as tf\nprint('tensor flow version in use: ', tf.__version__)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Using the CuDNNGRU is not importable as it seems to have been deprecated in recent versions of TF and I keep getting error 'ModuleNotFoundError: No module named 'tensorflow.contrib'', this is because this model is removed in the current version.\n\nThe better way is to simply use the GRU and or LSTM as it is, which will default to `CuDNNGRU` and `CuDNNLSTM`, if certain conditions are met. Refer [here](https://stackoverflow.com/questions/60468385/is-there-cudnnlstm-or-cudnngru-alternative-in-tensorflow-2-0)\n\nRefer to other links on how to import a `GRU` model:\n1. https://www.tensorflow.org/api_docs/python/tf/compat/v1/keras/layers/CuDNNGRU\n2. https://www.tensorflow.org/api_docs/python/tf/keras/layers/GRU"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\nmodel.add(Embedding(input_dim = max_features, output_dim = embed_size, input_length = max_len)) # input_shape is optional\nmodel.add(Bidirectional(GRU(64, return_sequences=True)))\nmodel.add(GlobalMaxPool1D())\nmodel.add(Dense(16, activation='relu'))\nmodel.add(Dropout(rate=0.1))\nmodel.add(Dense(1, activation='sigmoid'))\n\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n\nprint(model.summary())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Train the model on the given train split and monitor the metric on the validation set. Run for 1 epochs for now. Changing the epochs, batch_size, model parameters could give a better model"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n# train the model\nmodel.fit(train_X, train_y, batch_size=512, epochs =1 , validation_data = (valid_X, valid_y))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pickle\npickle.dump(model, open('bidirectional_gru_keras_no_pretrain_embed.pkl', 'wb'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*let's looks at the validation sample predictions and decide the best threshold for `F1` score. The actual values are `0` and `1`. Based on threshold, the predictions will vary.*\n\nHere we are learning embeddings and we don't use any of the pretrained embeddings that have been provided along with the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction_noembed_val_y = model.predict([valid_X], batch_size=1024, verbose=1)\n\nfor thresh in np.arange(0.1, 0.5, 0.01):\n    thresh = np.round(thresh, 2)\n    score = round(metrics.f1_score(valid_y, (prediction_noembed_val_y > thresh).astype(int)),4)\n    print('F1 score at threshold {} is {}'.format(thresh, score))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# predictions on test(no pretrained embedding in use)\npred_noembed_y = model.predict([test_X], batch_size=1024, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del model\ngc.collect()\n\n# pause execution for 10s after gc to allow gc to complete\ntime.sleep(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Imported Glove840b300d embedding file from kaggle"},{"metadata":{},"cell_type":"markdown","source":"Examine the contents of the embedding file. Each `line` represents a `token` and the correspoding `300D vector embedding`"},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"EMBEDDING_FILE = '../input/glove840b300dtxt/glove.840B.300d.txt'\n\nwith open(EMBEDDING_FILE, 'r', encoding='utf8') as fp:\n    for i in range(3):\n        print(fp.readline())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For details on how what the `*` operator means, refer [here](https://stackoverflow.com/questions/11315010/what-do-and-before-a-variable-name-mean-in-a-function-signature)\n\nInside a function header:\n\n* `*` unpacks a list or tuple into position arguments.\n\n* `**` unpacks a dictionary into keyword arguments."},{"metadata":{},"cell_type":"markdown","source":"**I got infinity when computing the `standard deviation` after stacking the embedding values when using dtype as 'float16', but if using 'float32', this does not happen, in the below function**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# extract the embeddings and the token from the text file\ndef get_coefs(word, *arr):\n    return word, np.asarray(arr, dtype='float32')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"# explore how we can use the * operator to unpack the list into a tuple\n# do the same for the rest of tokens in each line of the file\n\nwith open(EMBEDDING_FILE, 'r', encoding='utf8') as fp:\n    firstline = fp.readline()\n    secondline = fp.readline()\n    print(secondline)\n    print(get_coefs(*secondline.split(\" \")))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"%%time\nEMBEDDING_FILE = '../input/glove840b300dtxt/glove.840B.300d.txt'\n\nwith open(EMBEDDING_FILE, 'r', encoding='utf8') as fp:\n    for o in fp:\n        print(get_coefs(*o.split()))\n        break","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Glove embeddings"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nEMBEDDING_FILE = '../input/glove840b300dtxt/glove.840B.300d.txt'\nwith open(EMBEDDING_FILE, 'r') as fp:\n    embedding_index = dict(get_coefs(*o.split(\" \")) for o in fp)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" Since all_embeds.std() is coming to 'inf' or Infinity, I hard code the values. \n \n For mean, there is no issue  emb_mean,emb_std = -0.005838499,0.48782197"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nprint('Size of the embedding index: ', len(embedding_index))\n\n# stack the embedding values to calculate the mean and std for a normal distribution\nall_embeds = np.stack(list(embedding_index.values()))\nembed_mean, embed_std = np.mean(all_embeds), np.std(all_embeds) # or all_embeds.mean(), all_embeds.std() will do\nembed_size = all_embeds.shape[1]\nprint(embed_mean, embed_std)\nprint('embedding matrix shape', all_embeds.shape)\nif embed_std == 'inf':\n    embed_std = 0.48782197\nprint('new value for embed_std is: ', embed_std)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lets look at the tokens from our training data and use the learned glove embeddings to extract the embeddings for those tokens only.\nBefore extracting, the embeddings are normalized. This is because, in the glove embeddings, there are some tokens in lower and upper case, which has different embeddings, though there are quite similar, while others don't have this. So it is better to normalize them before using the learned embeddings for the training data"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n# get the tokens from our training data. Remember the Keras tokenizer has already beeen fit on the train text.\n\nword_index = tokenizer.word_index\n# vocab length should be 1 more to account for tokens which has embeddings missing\nprint('Number of unique words in the vocabulary is :', len(word_index) +1)\n\nvocab_length = len(word_index)+1\n\n# select minimum of tokens tokenized words from train and max_features we want to learn\nnb_words = min(len(word_index), max_features)\n\n''' Use the below when not going to normalize the distribution'''\nembedding_matrix = np.zeros((len(word_index)+1, embed_size))\n\n# normalize the distribution fo embeddings and store them in a matrix, the tokens will be added as keys in the next step\nembedding_matrix = np.random.normal(embed_mean, embed_std, (nb_words+1, embed_size))\n\ncount_found = nb_words\nmissing_tokens =[]\n\n\nfor word, index in word_index.items():\n    if index >= max_features:\n        continue\n    embedding_vector = embedding_index.get(word) # get the embedding vector for the word\n    if embedding_vector is not None:\n        embedding_matrix[i] = embedding_vector\n    else:\n        count_found -=1\n        missing_tokens.append(word)\n\nprint('Found embedding for {} words from the embeddings, from a total of {}'.format(count_found, nb_words))\n       \nprint('Number of missing tokens are: ', len(missing_tokens))        \nprint('Size of the embedding matrix is: ', embedding_matrix.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"Now lets define a Neural network model to use the above as inputs.\n\nThe embedding layer can be seeded with the GloVe word embedding weights. Finally, we do not want to update the `learned word weights` in this model, therefore we will set the `trainable` attribute for the model to be `False`\n\nThe number of rows in the `embedding_matrix` should be the same as the `input_dim` for the `Embedding layer`"},{"metadata":{"trusted":true},"cell_type":"code","source":"del all_embeds, embedding_index, embedding_vector, missing_tokens\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\n#model.add(Embedding(input_dim = max_features, output_dim = embed_size, input_length = max_len, weights=[embedding_matrix], trainable=False))\nmodel.add(Embedding(input_dim = max_features+1, output_dim = embed_size, input_length = max_len, weights=[embedding_matrix], trainable=False))\nmodel.add(Bidirectional(GRU(64, return_sequences=True)))\nmodel.add(GlobalMaxPool1D())\nmodel.add(Dense(16, activation='relu'))\nmodel.add(Dropout(rate=0.1))\nmodel.add(Dense(1, activation='sigmoid'))\n\nmodel.compile(loss ='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\nprint(model.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nmodel.fit(train_X, train_y, batch_size=512, epochs=1, validation_data=[valid_X, valid_y])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Prediction using Glove embedding trained NN model**"},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_glove_val_y = model.predict([valid_X], batch_size=1024, verbose=1)\n\n# check the F1_score at different thresholds\nfor thresh in np.arange(0.1, 0.5, 0.01):\n    score = metrics.f1_score(valid_y, (pred_glove_val_y > thresh).astype(int))\n    print('F1_score at threshold {} is {}'.format(thresh, round(score, 3)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_glove_test_y = model.predict([test_X], batch_size=1024, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del embedding_matrix\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **Try with FastText Embeddings - wikinews300d1m**"},{"metadata":{"trusted":true},"cell_type":"code","source":"os.listdir('../input/wikinews300d1mvec')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Examine file content\n\nEMBEDDING_FILE = '../input/wikinews300d1mvec/wiki-news-300d-1M.vec'\n\nwith open(EMBEDDING_FILE) as fp:\n    next(fp)  # skip header\n    print(fp.readline())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There was a problem when reading from the embedding file and converting it into a dictionary. The dict() method was not able to understand the inputs as token as vectors and hence used the `setdefault()` method of the dictionary, where we explicity mention what is the key and value pairs. More details on how to use it can be referred [here](https://www.geeksforgeeks.org/python-convert-list-tuples-dictionary/)"},{"metadata":{"trusted":true},"cell_type":"code","source":"dict_1 = dict()\n\ni=1\nwith open(EMBEDDING_FILE, 'r', encoding='utf8') as fp:\n    next(fp)\n    for o in fp:\n        temp = o.rstrip().split(\" \", 1)\n        print(temp)\n        dict_1.setdefault(temp[0], temp[1])\n        i-=1\n        if i==0:\n            break\nprint(dict_1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"dict_1 = dict()\n\ni=3\nwith open(EMBEDDING_FILE, 'r', encoding='utf8') as fp:\n    next(fp)\n    for o in fp:\n        temp = get_coefs(*o.rstrip().split(\" \"))\n        #print(temp)\n        dict_1.setdefault(temp[0], temp[1])\n            \n#         print(temp[0])\n#         print(temp[1])\n\n#         print(dict(temp))\n        i-=1\n        if i==0:\n            break\nprint(dict_1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\nEMBEDDING_FILE = '../input/wikinews300d1mvec/wiki-news-300d-1M.vec'\n\nembedding_index = dict()\n\nwith open(EMBEDDING_FILE, 'r', encoding='utf8') as fp:\n    next(fp)                                          # skip header\n    for o in fp:\n        temp = get_coefs(*o.rstrip().split(\" \"))\n        #print(temp)\n        embedding_index.setdefault(temp[0], temp[1])\n        \n# stack all the values\nall_embed = np.stack(list(embedding_index.values()))\nembed_mean, embed_std = all_embed.mean(), all_embed.std()\nembed_size = all_embed.shape[1]\n\nprint('Embed mean : {} and std: {}'.format(embed_mean, embed_std))\nprint('Emebdding index size', all_embed.shape)\n\nif embed_std == 'inf': # I got infinity when using dtype as 'float16', but if using 'float32', this does not happen\n    embed_std = 0.48782197\nprint('new value for embed_std is: ', embed_std)\n\n# get the tokens from our training data. Remember the Keras tokenizer has already beeen fit on the train text.\n\nword_index = tokenizer.word_index\n# vocab length should be 1 more to account for tokens which has embeddings missing\nprint('Number of unique words in the vocabulary is :', len(word_index) +1)\n\nvocab_length = len(word_index)+1\n\n# select minimum of tokens tokenized words from train and max_features we want to learn\nnb_words = min(len(word_index), max_features)\n\n''' Use the below when not going to normalize the distribution'''\nembedding_matrix = np.zeros((len(word_index)+1, embed_size))\n\n# normalize the distribution fo embeddings and store them in a matrix, the tokens will be added as keys in the next step\nembedding_matrix = np.random.normal(embed_mean, embed_std, (nb_words+1, embed_size))\n\ncount_found = nb_words\nmissing_tokens =[]\n\n\nfor word, index in word_index.items():\n    if index >= max_features:\n        continue\n    embedding_vector = embedding_index.get(word) # get the embedding vector for the word\n    if embedding_vector is not None:\n        embedding_matrix[i] = embedding_vector\n    else:\n        count_found -=1\n        missing_tokens.append(word)\n\nprint('Found embedding for {} words from the embeddings, from a total of {}'.format(count_found, nb_words))\n       \nprint('Number of missing tokens are: ', len(missing_tokens))        \nprint('Size of the embedding matrix is: ', embedding_matrix.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del word_index, embedding_index, missing_tokens, all_embed\ngc.collect()\ntime.sleep(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model=Sequential()\nmodel.add(Embedding(input_dim =nb_words+1, output_dim = embed_size, input_length = max_len, weights = [embedding_matrix], trainable=False))\nmodel.add(Bidirectional(GRU(64, return_sequences=True)))\nmodel.add(GlobalMaxPool1D())\nmodel.add(Dense(16, activation='relu'))\nmodel.add(Dropout(rate=0.1))\nmodel.add(Dense(1, activation='sigmoid'))\n\nmodel.compile(loss ='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n\nprint(model.summary())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Running for only 1 epoch as each epoch takes time"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nmodel.fit(train_X, train_y, epochs=1, batch_size=512, validation_data=[valid_X, valid_y])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_fasttext_val_y = model.predict([valid_X], batch_size=1024, verbose=1)\n\nfor thresh in np.arange(0.1, 0.5, 0.01): \n    score = metrics.f1_score(valid_y, (pred_glove_val_y > thresh).astype(int))\n    print('F1_score at threshold {} is {}'.format(thresh, round(score, 3)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_fasttext_test_y = model.predict([test_X], batch_size=1024, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del embedding_matrix, model\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **Using Paragram embeddings**"},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"# experiment with file read\nEMBEDDING_FILE = '../input/paragram-300-sl999/paragram_300_sl999.txt'\nembedding_index = dict()\ni=3\nwith open(EMBEDDING_FILE, 'r') as fp:\n    for o in fp:\n        temp = get_coefs(*o.split(\" \"))\n        #print(temp[0], temp[1])\n        embedding_index.setdefault(temp[0], temp[1])\n        i-=1\n        if i ==0:\n            break\n\nprint(embedding_index)","execution_count":113,"outputs":[{"output_type":"stream","text":"{',': array([-2.57125795e-01,  8.09895635e-01,  3.52934725e-03, -2.61192143e-01,\n        4.75149117e-02,  3.14476728e-01,  2.82113045e-01, -3.08695018e-01,\n       -3.07101041e-01,  1.92263556e+00, -2.22033486e-01,  2.48930290e-01,\n        2.38734439e-01, -1.71986103e-01, -5.13283551e-01,  6.16461970e-03,\n       -1.09530471e-01,  1.55904317e+00, -6.22845329e-02,  5.42424917e-02,\n       -5.87660596e-02,  5.11817969e-02, -4.36753384e-04, -3.93734515e-01,\n        1.13699988e-01, -2.06368506e-01,  1.11778513e-01,  9.43049863e-02,\n        5.27331889e-01, -1.84620008e-01,  2.28430703e-01,  4.16477844e-02,\n       -1.15934730e-01,  2.82809436e-01,  5.84579766e-01, -4.75815423e-02,\n        2.18655720e-01, -1.59711149e-02, -1.84448272e-01,  2.91061491e-01,\n       -6.23817332e-02, -3.31140310e-01,  8.33015218e-02,  6.00650813e-03,\n       -1.18001312e-01,  1.14101283e-02, -3.01397681e-01,  1.55064821e-01,\n        2.47375429e-01,  1.04703279e-02,  1.17448777e-01,  2.93554544e-01,\n       -8.49206299e-02,  6.28167391e-02, -4.84696448e-01,  5.73283620e-03,\n        2.35655442e-01, -1.68853298e-01,  2.69412309e-01,  1.29659712e-01,\n       -9.23916847e-02,  9.12989900e-02,  2.74665833e-01,  1.61878809e-01,\n        1.26215937e-02, -2.61250824e-01,  4.01077196e-02, -9.85990986e-02,\n       -1.70548216e-01,  5.01676440e-01,  1.58649627e-02,  1.53560430e-01,\n        7.23533183e-02, -1.11088723e-01, -2.21821833e-02, -2.33006794e-02,\n       -1.82922274e-01, -2.81393766e-01, -2.06720084e-02,  5.52844763e-01,\n       -5.05420327e-01,  1.17939733e-01,  4.02824849e-01,  8.61706510e-02,\n        2.87466086e-02, -5.62466562e-01,  6.15370512e-01, -9.62910950e-02,\n        5.97365558e-01,  3.70516628e-01,  3.16369534e-01, -4.92592808e-03,\n        2.84990698e-01,  2.23917365e-01, -6.05854429e-02, -3.74979109e-01,\n       -6.03199959e-01, -1.30521566e-01, -4.54154223e-01, -1.05947323e-01,\n       -1.39568031e-01,  3.15564364e-01, -4.78238434e-01, -1.85250223e-01,\n       -1.47022292e-01,  7.39198625e-01, -3.95243436e-01, -2.92153866e-03,\n        1.57927066e-01,  1.98375314e-01,  2.02339310e-02, -1.11572243e-01,\n        2.14093447e-01, -4.67021555e-01, -2.79860288e-01, -3.06741297e-02,\n        1.15464158e-01, -7.95712411e-01, -3.04413121e-02, -3.98879915e-01,\n        1.46741003e-01,  2.78129250e-01,  1.40431270e-01,  2.57860035e-01,\n       -2.85826653e-01,  1.52656436e-01,  1.51505709e-01,  1.34732097e-01,\n        2.48444170e-01, -1.17136516e-01,  1.77648246e-01, -4.33827847e-01,\n       -7.43784010e-03, -1.47656381e-01, -1.18499644e-01,  3.22664291e-01,\n       -2.25593090e-01, -1.84992567e-01, -1.53535649e-01,  8.78499970e-02,\n       -5.16256392e-01,  8.61399472e-01,  7.33572662e-01,  9.30007081e-03,\n       -2.61377335e-01,  3.19702715e-01,  2.87338436e-01, -1.49302065e-01,\n       -2.79114574e-01, -1.83404852e-02, -8.67057592e-02,  3.03699374e-02,\n        5.66069424e-01,  3.03689599e-01,  3.16642344e-01,  1.53821215e-01,\n        2.87508905e-01, -1.91798449e-01,  1.17286474e-01, -8.52014963e-03,\n        7.91468471e-02,  1.27255976e-01, -8.59855339e-02, -1.07645124e-01,\n       -2.10657343e-01,  2.07046285e-01, -7.39137977e-02, -8.61972347e-02,\n        2.10717499e-01,  4.52347100e-01, -1.13193825e-01,  8.35543647e-02,\n       -6.61283076e-01,  2.81016827e-01, -1.75844952e-01, -8.96361843e-02,\n       -1.63406014e-01, -3.70537460e-01,  1.43802119e-02, -6.81347191e-01,\n        1.86705310e-02, -2.50426948e-01, -2.53757834e-01, -2.23165393e-01,\n        2.49482080e-01, -4.06552732e-01,  2.11726353e-01,  1.00451738e-01,\n        1.71530664e-01,  1.82964548e-01,  7.67005607e-02,  1.17695056e-01,\n        4.07552421e-01, -1.57414675e-01, -3.52671832e-01, -3.57697964e-01,\n       -6.32567555e-02, -5.02070367e-01,  7.48574287e-02,  3.72752964e-01,\n       -2.55725622e-01,  7.55656660e-02, -1.97395697e-01, -2.00460210e-01,\n        2.56995648e-01, -4.34121996e-01,  1.24909990e-01, -5.92614934e-02,\n        2.25615595e-02, -1.81063533e-01, -4.73740220e-01, -2.64733940e-01,\n        6.03373908e-02,  5.87557517e-02,  3.25305611e-01, -2.02013925e-01,\n        2.06839919e-01, -7.62498705e-03,  8.26275162e-03,  7.39805028e-02,\n       -4.65018228e-02,  2.61489868e-01, -8.91087651e-02,  2.49249339e-01,\n        3.29827428e-01,  1.68509558e-01, -2.59331286e-01,  2.36015379e-01,\n       -4.84940074e-02, -6.35391707e-03, -5.34992516e-02,  1.35479569e-01,\n        1.62377581e-01,  2.53484994e-01, -4.73191589e-01,  2.27742329e-01,\n       -2.47795999e-01, -1.29868671e-01, -2.14547031e-02,  3.99298817e-02,\n        8.08735192e-02, -1.92016855e-01,  2.07209006e-01, -4.17103082e-01,\n        2.73412287e-01,  4.78071831e-02, -3.08101028e-01, -2.06720173e-01,\n       -7.24969152e-03,  6.83252513e-01,  2.26906583e-01,  8.13156739e-03,\n       -3.80268365e-01, -5.06003164e-02, -2.60247476e-02,  1.88281432e-01,\n        4.88237431e-03, -2.30988935e-01, -2.79773623e-01,  2.00696886e-01,\n       -9.19539854e-02, -7.03264400e-03,  2.71720767e-01,  4.63453561e-01,\n       -1.36245266e-01, -2.46522024e-01, -1.32801190e-01, -3.21483344e-01,\n        3.42869669e-01,  1.62904158e-01, -8.19709957e-01, -2.94458240e-01,\n        6.08258620e-02,  2.32246220e-02, -6.88628733e-01,  1.02211125e-02,\n       -3.66000384e-02,  1.34315938e-01, -8.37789103e-02,  4.35700804e-01,\n        9.02601838e-01, -4.44801927e-01,  4.45655346e-01, -4.09887791e-01,\n       -9.34736207e-02,  3.60555910e-02,  1.82083771e-01, -2.25611970e-01,\n        3.78065318e-01, -2.98776239e-01, -2.16396555e-01, -2.49021068e-01,\n       -1.84113681e-01, -6.51995391e-02, -2.50193834e-01, -2.57118773e-02,\n        9.87512320e-02, -3.63280475e-02, -2.55567729e-01,  8.68508741e-02],\n      dtype=float32), '.': array([-1.08199976e-01,  5.14792800e-01, -3.14560230e-03, -5.21876335e-01,\n        9.85066593e-02,  2.74737597e-01,  4.22257036e-01, -2.96034753e-01,\n       -2.43487373e-01,  1.46654010e+00, -5.06000161e-01,  5.75832129e-01,\n        2.45367765e-01, -4.77039814e-02, -2.29290411e-01,  4.97925393e-02,\n       -4.46200110e-02,  1.76948202e+00, -1.12913720e-01, -6.13961406e-02,\n        1.76702976e-01, -1.97725371e-01,  2.48176828e-02, -2.25409657e-01,\n        4.43594158e-01,  4.01803525e-03, -1.82415500e-01,  1.98106393e-01,\n        2.00784504e-01, -2.68981773e-02, -6.91939294e-02, -2.13975281e-01,\n        5.48766628e-02,  1.69985905e-01,  4.74046856e-01, -4.35117595e-02,\n        4.31587458e-01,  1.25622556e-01, -7.57912640e-03,  5.77629060e-02,\n        9.92805138e-02, -2.74782926e-01,  3.65043759e-01, -3.60351861e-01,\n        1.39232641e-02, -1.55861065e-01, -4.50102150e-01,  2.51060903e-01,\n       -1.21972263e-01,  1.11146003e-01,  1.15427166e-01,  4.87353513e-03,\n        2.77003735e-01, -2.44322851e-01, -4.66067821e-01, -1.40654564e-01,\n        5.71941808e-02,  5.09050749e-02,  7.93575570e-02,  7.60844164e-03,\n       -2.66542703e-01,  2.45806366e-01,  4.09061849e-01,  3.29848588e-01,\n       -1.18756384e-01, -1.21724240e-01,  1.94623306e-01,  2.11212654e-02,\n       -3.91831666e-01,  4.80097085e-01,  6.97897822e-02, -6.93299621e-02,\n        3.45198363e-01,  1.10027827e-02,  6.42097741e-02, -2.56439477e-01,\n       -2.26635382e-01, -1.26071766e-01, -3.28789115e-01,  4.26840186e-01,\n       -5.08432925e-01,  9.09600034e-02,  4.99139540e-02,  2.26192906e-01,\n       -1.08755641e-01, -3.40976238e-01,  5.94368398e-01, -3.14459741e-01,\n        3.09069782e-01,  4.28758651e-01, -1.14076352e-02,  3.53660248e-02,\n        4.18665111e-02,  1.86806008e-01, -9.60356966e-02, -3.86008561e-01,\n       -6.01276219e-01, -3.23542207e-01, -4.52775478e-01, -3.01268816e-01,\n       -1.31414026e-01,  4.56856549e-01, -2.75131851e-01, -2.47110888e-01,\n        7.30857849e-02,  5.79679906e-01, -2.92155463e-02, -1.12648800e-01,\n        1.74392030e-01,  2.83467323e-01,  3.33966106e-01, -2.26406604e-01,\n        3.39830577e-01, -5.16298890e-01, -2.74569482e-01,  9.55007002e-02,\n        1.42399281e-01, -4.04717803e-01, -1.58372656e-01, -4.77498174e-01,\n       -5.94003685e-03,  2.78922588e-01,  2.70999789e-01,  2.77485430e-01,\n       -4.11515534e-01,  1.47436678e-01, -1.13321375e-02, -2.21019909e-02,\n        4.91371453e-01, -1.99281648e-01, -2.59624213e-01, -5.08471310e-01,\n       -3.80694330e-01,  6.58494756e-02, -9.70841721e-02,  4.58805948e-01,\n       -7.02239498e-02,  1.25254631e-01, -8.59306902e-02,  8.19069520e-02,\n       -1.16592002e+00,  5.97664237e-01,  5.61300397e-01,  5.88845387e-02,\n       -1.85910240e-01,  2.04237550e-01,  1.22126229e-02,  3.12164843e-01,\n       -3.33029717e-01, -3.02222967e-01, -7.31367394e-02,  3.28436613e-01,\n        2.13396549e-01,  1.35160282e-01,  2.07549930e-01, -1.84549034e-01,\n       -6.42929822e-02, -1.32965788e-01,  4.72807109e-01, -1.18665017e-01,\n        2.88580775e-01, -3.44682224e-02, -1.80631671e-02, -3.77160251e-01,\n       -9.65887029e-03,  9.17482525e-02, -1.17662095e-01, -2.91566104e-01,\n        4.15535212e-01,  4.03573662e-01, -1.45762727e-01,  1.08922906e-02,\n       -5.11622012e-01,  1.32847860e-01, -1.13313630e-01, -1.99098811e-01,\n       -4.54131700e-02, -3.24582040e-01, -1.94289342e-01, -4.00654942e-01,\n       -1.07674174e-01, -1.33992314e-01, -3.87601763e-01, -5.00924766e-01,\n       -8.30279291e-02, -2.77476341e-01,  2.26273954e-01, -8.09304789e-02,\n        2.66568422e-01,  1.08699724e-01, -9.59996656e-02, -9.66520980e-02,\n        5.34416974e-01,  2.14351043e-01, -6.93973228e-02, -5.57664223e-02,\n        1.29350960e-01, -5.15218616e-01,  2.97844648e-01,  5.04108787e-01,\n       -1.32728219e-01, -7.31108040e-02, -7.89096355e-02,  3.72725651e-02,\n        3.24532092e-02, -3.40323716e-01,  1.90030545e-01,  1.26629934e-01,\n       -1.10022493e-01, -2.65196413e-01, -2.00210810e-01, -8.77207518e-02,\n       -5.73257655e-02,  8.18290189e-03,  4.84912723e-01,  1.64712649e-02,\n        1.70802534e-01,  4.67330478e-02, -1.01451211e-01,  1.94942668e-01,\n       -1.28381345e-02,  1.56837821e-01, -9.04648826e-02,  5.07586718e-01,\n        3.53519946e-01,  1.13272235e-01, -4.82731611e-01,  1.56843126e-01,\n       -1.30441085e-01, -4.16141562e-02, -6.64866120e-02, -4.53756362e-01,\n        7.58711398e-02, -1.72108747e-02, -1.86284631e-01,  3.50293785e-01,\n       -2.13254899e-01,  1.88758120e-01, -5.16663902e-02, -1.46702290e-01,\n       -1.64214775e-01, -1.87305957e-01,  2.30012909e-01, -5.20587154e-02,\n        3.35590541e-01, -2.25577295e-01, -4.21351552e-01, -8.29178244e-02,\n        4.86035384e-02,  4.84097838e-01,  3.12441766e-01,  3.03199857e-01,\n       -4.40230042e-01,  2.36031488e-01,  6.11384138e-02,  1.61626622e-01,\n        1.54618084e-01, -1.90593004e-01, -3.95183235e-01, -1.40090749e-01,\n       -3.87002885e-01,  3.99599761e-01,  2.90053070e-01, -2.34548963e-04,\n       -2.32654393e-01, -3.91791970e-01, -1.66708395e-01, -2.39903610e-02,\n        6.52766228e-01,  1.89309448e-01, -5.92090607e-01,  5.08999676e-02,\n       -5.22376038e-03, -2.10036948e-01, -7.25096166e-01,  9.18846875e-02,\n        9.07683671e-02, -2.17783940e-03, -1.91495717e-02,  4.69401062e-01,\n        8.66919518e-01, -3.70408356e-01,  1.07837267e-01, -4.42950547e-01,\n       -1.66303977e-01, -1.36508107e-01,  1.15773395e-01, -1.02446154e-01,\n        5.77672601e-01, -7.94590563e-02, -6.61133677e-02, -1.47927508e-01,\n       -2.37177715e-01, -4.15030792e-02, -1.29535481e-01,  7.58646801e-02,\n        2.33247727e-01,  1.33113816e-01, -1.81757614e-01,  5.78336865e-02],\n      dtype=float32), 'the': array([ 2.49915466e-01, -1.12669170e-01, -1.75746799e-01, -1.41901985e-01,\n        4.14641052e-02,  3.49641740e-01,  5.76852322e-01, -8.69857222e-02,\n        3.32831353e-01,  1.87939739e+00, -6.94813311e-01,  1.44522756e-01,\n        7.10852623e-01, -7.72599339e-01,  5.48628986e-01,  5.92769742e-01,\n       -8.40233490e-02,  1.10436177e+00, -5.27610958e-01, -7.12453723e-01,\n        1.93836614e-01, -1.16054028e-01, -3.11651468e-01, -1.73923761e-01,\n       -5.57321589e-04, -6.86451867e-02, -1.05996525e+00,  3.78565520e-01,\n        6.22425020e-01,  5.17876334e-02,  8.32265392e-02, -4.24527116e-02,\n        4.99945208e-02,  8.09962571e-01,  3.35674018e-01, -2.05139026e-01,\n       -1.66426063e-01, -1.57357961e-01, -3.50601822e-01, -1.30022720e-01,\n       -5.98689258e-01,  4.63923365e-01, -1.67771176e-01,  1.35032358e-02,\n        1.54381678e-01, -2.69392401e-01,  3.90799135e-01,  4.91074435e-02,\n        1.88878328e-01,  2.29749009e-01, -2.19324172e-01, -2.69701153e-01,\n        2.64721572e-01,  1.97188452e-01,  9.56704915e-02,  2.52529178e-02,\n        2.72513121e-01,  1.13746308e-01,  2.05231369e-01,  2.11658198e-02,\n        1.26773953e-01,  3.40377867e-01, -4.30643499e-01,  5.74611425e-01,\n       -1.82656776e-02, -8.79503936e-02,  3.24800700e-01, -7.19427168e-01,\n        3.44189793e-01,  8.54063854e-02, -3.92835706e-01, -5.11655249e-02,\n        6.80812448e-02, -1.10064618e-01, -3.93182188e-01, -2.68731155e-02,\n        1.83149725e-01, -9.03094858e-02,  4.30780768e-01,  8.89539495e-02,\n        3.87566358e-01,  2.37792090e-01, -2.76247948e-01, -3.31650645e-01,\n        5.76178372e-01, -6.17929041e-01, -1.38064492e+00, -6.28537297e-01,\n       -6.46551967e-01,  7.25378003e-03, -2.76057333e-01,  1.43621648e-02,\n        8.41481447e-01, -6.05253398e-01,  9.88613628e-03, -3.82674411e-02,\n        5.09209514e-01, -6.05429530e-01, -9.43076760e-02,  1.73917696e-01,\n        1.80435018e-03,  4.65874642e-01, -3.72283608e-01, -3.91152613e-02,\n        7.29561269e-01,  1.27125585e+00,  2.70198405e-01,  2.01410353e-01,\n        4.96663213e-01, -3.81907254e-01, -2.31519818e-01, -5.66445351e-01,\n        3.08666617e-01,  5.93235910e-01,  1.01944156e-01, -3.21016997e-01,\n       -6.03065550e-01,  3.96192074e-01, -3.28271650e-02, -2.11935222e-01,\n        4.20197248e-01, -2.71462321e-01, -2.79037654e-01, -5.26644409e-01,\n       -4.09789145e-01, -2.97036707e-01,  2.65913010e-01,  3.67442407e-02,\n        8.98582339e-01,  1.26925886e-01, -1.18735802e+00,  2.96414584e-01,\n       -2.68456452e-02, -1.02842286e-01,  1.47528484e-01,  3.33645642e-01,\n       -3.98705333e-01, -2.85370708e-01,  4.91982773e-02, -3.28472517e-02,\n       -1.14237523e+00, -3.36120605e-01,  1.99563026e-01, -5.19322790e-02,\n        3.70669272e-03,  1.79776430e-01,  2.34361485e-01,  3.30339819e-02,\n        2.73836702e-01, -3.56950730e-01,  2.92926699e-01, -3.64547148e-02,\n        3.29783320e-01, -8.70774984e-01,  1.41317680e-01,  3.14055353e-01,\n       -2.71086872e-01,  1.92631319e-01, -4.03548747e-01, -2.72950530e-01,\n       -2.01719701e-01, -3.84406373e-02, -7.43130669e-02,  2.09612235e-01,\n       -5.91008458e-03,  4.07082826e-01, -1.79248184e-01,  6.44063294e-01,\n        7.01079488e-01, -1.62382096e-01, -3.77512008e-01, -5.60205579e-01,\n       -3.53863925e-01, -1.06029198e-01,  1.86218247e-01, -1.13019280e-01,\n        1.40117392e-01, -2.12261789e-02,  3.65805000e-01, -4.53834295e-01,\n        8.39126930e-02, -6.57748505e-02, -4.18569833e-01, -1.00173354e+00,\n        3.10639143e-01,  1.56334951e-03, -1.04156613e-01,  1.98379770e-01,\n        6.11608922e-01, -2.91434020e-01,  3.91526282e-01,  1.88149214e-01,\n       -1.12901163e+00,  9.88596141e-01,  1.70135066e-01,  6.46003544e-01,\n       -1.65379986e-01, -5.99001884e-01, -8.86279702e-01,  6.06478631e-01,\n       -3.19331050e-01,  6.35755360e-01, -3.47353071e-01,  2.95676082e-01,\n        3.48278284e-01, -1.05189180e+00,  1.43202528e-01,  6.85693383e-01,\n       -4.96557653e-01, -2.18606010e-01,  8.43281373e-02, -3.59163314e-01,\n       -2.70482898e-01, -1.69747606e-01, -1.44277029e-02,  3.83216739e-01,\n       -4.97633696e-01,  4.31078613e-01,  7.07473531e-02,  2.03898519e-01,\n        2.45414767e-02, -1.02636062e-01, -3.98008525e-01, -6.48450032e-02,\n        2.76205502e-02,  7.46144652e-01,  4.38561663e-02,  5.24367511e-01,\n       -2.08967417e-01,  2.00079400e-02,  9.24744383e-02, -1.41351864e-01,\n       -2.54382998e-01, -3.47004890e-01, -3.09826225e-01,  1.53470516e-01,\n       -5.90239950e-02,  5.96313000e-01, -4.96642143e-01,  4.54615027e-01,\n        4.82947469e-01,  8.24023485e-01, -2.87134141e-01,  8.33757222e-01,\n        2.66374230e-01,  2.58811146e-01,  1.50434613e-01, -5.62351584e-01,\n       -4.59742099e-01,  5.67092970e-02, -1.95118949e-01, -1.15426607e-01,\n       -4.81593937e-01,  1.76332921e-01,  2.75866538e-01,  5.85953891e-01,\n       -1.85888633e-01,  2.64766127e-01,  8.11776161e-01,  1.23755738e-01,\n        8.42304528e-02,  6.89480603e-02, -2.81668872e-01, -1.09133311e-01,\n        3.81432831e-01, -6.81008458e-01,  1.14959158e-01, -3.19596529e-01,\n       -3.36615354e-01, -4.20074552e-01,  3.73243183e-01, -2.94549704e-01,\n        3.20896864e-01,  4.92262810e-01,  1.85153484e-01,  3.69780838e-01,\n        3.63160744e-02,  2.11345375e-01, -1.27782911e-01,  9.04749990e-01,\n       -2.51321107e-01, -1.18210040e-01,  4.67763662e-01, -5.39137721e-01,\n        3.03359866e-01, -4.52707946e-01,  8.88284445e-01, -1.14420094e-01,\n        3.82268459e-01,  1.89149946e-01,  3.54114532e-01,  1.25213131e-01,\n        3.64439011e-01, -4.53117818e-01,  8.96800935e-01,  4.93653454e-02,\n        5.37476242e-01, -2.19689697e-01,  3.61412317e-02,  3.14833075e-01],\n      dtype=float32)}\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\nEMBEDDING_FILE = '../input/paragram-300-sl999/paragram_300_sl999.txt'\n\nembedding_index = dict()\n\n# with open(EMBEDDING_FILE, 'r') as fp:\n#     embedding_index = dict(get_coefs(*o.split(\" \")) for o in fp)\n\nwith open(EMBEDDING_FILE, 'r') as fp:\n    for o in fp:\n        temp = get_coefs(*o.split(\" \"))\n        #print(temp[0], temp[1])\n        embedding_index.setdefault(temp[0], temp[1])","execution_count":126,"outputs":[{"output_type":"stream","text":"CPU times: user 8.73 s, sys: 97.8 ms, total: 8.82 s\nWall time: 8.77 s\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"I cannot stack the values for embeddings due to some difference in array size. So I check the array size for every token in the embedding and pop the one which doesn't have an embedding vector size of 300"},{"metadata":{"trusted":true},"cell_type":"code","source":"count=0\nfor k, v in embedding_index.items():\n    #print(len(v))\n    if len(v) != 300:\n        count+=1\n        print(k)\nprint(count)","execution_count":127,"outputs":[{"output_type":"stream","text":"raheem\n1\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# cross check\nembedding_index.get('raheem')","execution_count":128,"outputs":[{"output_type":"execute_result","execution_count":128,"data":{"text/plain":"array([-0.43258283,  0.09266366,  0.25799406,  0.8843603 ,  0.27901617,\n       -0.85909986, -0.17252979,  0.60357445,  0.5192926 ,  0.30764836,\n        1.1313126 , -0.09444306,  0.5114069 , -0.4533463 , -0.32634237,\n        0.42611784,  0.20467412, -1.5356295 ,  0.52981794,  0.23863493,\n       -0.38401672,  0.42267364, -0.5657015 , -0.05632737,  0.15524974,\n       -0.4972775 ,  0.2936109 , -0.17312671,  0.5867042 ,  0.3858083 ,\n       -0.96525776, -0.18743043, -0.49245378, -0.4399429 ,  0.7486791 ,\n       -0.40318578, -0.00849412, -0.22251162, -0.1376775 ,  0.09772917,\n       -0.24      ], dtype=float32)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# pop the token and its embedding vector from the embedding matrix\nembedding_index.pop('raheem')\n\n# now again check\ncount=0\nfor k, v in embedding_index.items():\n    #print(len(v))\n    if len(v) != 300:\n        count+=1\n        print(k)\nprint(count)","execution_count":130,"outputs":[{"output_type":"error","ename":"KeyError","evalue":"'raheem'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-130-033e4b96726d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0membedding_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'raheem'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# now again check\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0membedding_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'raheem'"]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# stack all the values\nall_embeds = np.stack(list(embedding_index.values()))\nembed_mean, embed_std = all_embeds.mean(), all_embeds.std()\nembed_size = all_embeds.shape[1]\n\nprint('Embed mean : {} and std: {}'.format(embed_mean, embed_std))\nprint('Emebdding index shape', all_embeds.shape)\n\nif embed_std == 'inf':\n    embed_std = 0.48782197\n    \nprint('new value for embed_std is: ', embed_std)\n\nword_index = tokenizer.word_index\nprint('Number of unique tokens in the training data identified', len(word_index))\n\nvocab_length = len(word_index) + 1\n\nnb_words = min(max_features, len(word_index))\n\n# normalize the distribution\nembedding_matrix = np.zeros((nb_words+1, embed_size))\n\nembedding_matrix = np.random.normal(embed_mean, embed_std, (nb_words+1, embed_size))\n\nmissing_tokens= []\n\nfor word, index in word_index.items():\n    if index > max_features:\n        continue\n    embedding_vector = embedding_index.get(word)\n    \n    if embedding_vector is not None:\n        embedding_matrix[index] = embedding_vector\n    else:\n        count_found -=1\n        missing_tokens.append(word)\n\nprint('Found embedding for {} words from the embeddings, from a total of {}'.format(count_found, nb_words))\n       \nprint('Number of missing tokens are: ', len(missing_tokens))        \nprint('Size of the embedding matrix is: ', embedding_matrix.shape)","execution_count":136,"outputs":[{"output_type":"stream","text":"Embed mean : -0.0004052692966070026 and std: 0.42649155855178833\nEmebdding index shape (66198, 300)\nnew value for embed_std is:  0.42649156\nNumber of unique tokens in the training data identified 209441\nFound embedding for 16441 words from the embeddings, from a total of 50000\nNumber of missing tokens are:  13153\nSize of the embedding matrix is:  (50001, 300)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model=Sequential()\nmodel.add(Embedding(input_dim =nb_words+1, output_dim = embed_size, input_length = max_len, trainable=False, weights=[embedding_matrix]))\nmodel.add(Bidirectional(GRU(64, return_sequences=True)))\nmodel.add(GlobalMaxPool1D())\nmodel.add(Dense(16, activation='relu'))\nmodel.add(Dropout(rate=0.1))\nmodel.add(Dense(1, activation='sigmoid'))\n\nmodel.compile(loss ='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n\nprint(model.summary())","execution_count":137,"outputs":[{"output_type":"stream","text":"Model: \"sequential_8\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding_7 (Embedding)      (None, 100, 300)          15000300  \n_________________________________________________________________\nbidirectional_4 (Bidirection (None, 100, 128)          140160    \n_________________________________________________________________\nglobal_max_pooling1d_4 (Glob (None, 128)               0         \n_________________________________________________________________\ndense_7 (Dense)              (None, 16)                2064      \n_________________________________________________________________\ndropout_4 (Dropout)          (None, 16)                0         \n_________________________________________________________________\ndense_8 (Dense)              (None, 1)                 17        \n=================================================================\nTotal params: 15,142,541\nTrainable params: 142,241\nNon-trainable params: 15,000,300\n_________________________________________________________________\nNone\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"**fit the model using Paragram embeddings**"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nmodel.fit(train_X, train_y, batch_size=512, epochs=1, validation_data=(valid_X, valid_y))","execution_count":139,"outputs":[{"output_type":"stream","text":"Train on 1175509 samples, validate on 130613 samples\nEpoch 1/1\n1175509/1175509 [==============================] - 1043s 887us/step - loss: 0.1216 - accuracy: 0.9532 - val_loss: 0.1105 - val_accuracy: 0.9559\nCPU times: user 25min 57s, sys: 3min 59s, total: 29min 57s\nWall time: 17min 24s\n","name":"stdout"},{"output_type":"execute_result","execution_count":139,"data":{"text/plain":"<keras.callbacks.callbacks.History at 0x7feb2f37d7d0>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_paragram_val_y = model.predict([valid_X], batch_size=1024, verbose=1)\n\nfor thresh in np.arange(0.1, 0.5, 0.01): \n    score = metrics.f1_score(valid_y, (pred_glove_val_y > thresh).astype(int))\n    print('F1_score at threshold {} is {}'.format(thresh, round(score, 3)))","execution_count":140,"outputs":[{"output_type":"stream","text":"130613/130613 [==============================] - 5s 39us/step\nF1_score at threshold 0.1 is 0.505\nF1_score at threshold 0.11 is 0.515\nF1_score at threshold 0.12 is 0.524\nF1_score at threshold 0.13 is 0.531\nF1_score at threshold 0.13999999999999999 is 0.539\nF1_score at threshold 0.14999999999999997 is 0.546\nF1_score at threshold 0.15999999999999998 is 0.553\nF1_score at threshold 0.16999999999999998 is 0.558\nF1_score at threshold 0.17999999999999997 is 0.563\nF1_score at threshold 0.18999999999999995 is 0.568\nF1_score at threshold 0.19999999999999996 is 0.571\nF1_score at threshold 0.20999999999999996 is 0.575\nF1_score at threshold 0.21999999999999995 is 0.579\nF1_score at threshold 0.22999999999999995 is 0.581\nF1_score at threshold 0.23999999999999994 is 0.584\nF1_score at threshold 0.24999999999999992 is 0.588\nF1_score at threshold 0.2599999999999999 is 0.589\nF1_score at threshold 0.2699999999999999 is 0.592\nF1_score at threshold 0.2799999999999999 is 0.594\nF1_score at threshold 0.2899999999999999 is 0.596\nF1_score at threshold 0.29999999999999993 is 0.598\nF1_score at threshold 0.30999999999999994 is 0.6\nF1_score at threshold 0.3199999999999999 is 0.601\nF1_score at threshold 0.32999999999999985 is 0.603\nF1_score at threshold 0.33999999999999986 is 0.604\nF1_score at threshold 0.34999999999999987 is 0.604\nF1_score at threshold 0.3599999999999999 is 0.604\nF1_score at threshold 0.3699999999999999 is 0.604\nF1_score at threshold 0.3799999999999999 is 0.605\nF1_score at threshold 0.3899999999999999 is 0.605\nF1_score at threshold 0.3999999999999998 is 0.605\nF1_score at threshold 0.4099999999999998 is 0.605\nF1_score at threshold 0.4199999999999998 is 0.605\nF1_score at threshold 0.4299999999999998 is 0.603\nF1_score at threshold 0.43999999999999984 is 0.603\nF1_score at threshold 0.44999999999999984 is 0.603\nF1_score at threshold 0.45999999999999985 is 0.602\nF1_score at threshold 0.46999999999999986 is 0.601\nF1_score at threshold 0.47999999999999976 is 0.599\nF1_score at threshold 0.48999999999999977 is 0.597\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_paragram_test_y = model.predict([test_X], batch_size=1024, verbose=1)","execution_count":141,"outputs":[{"output_type":"stream","text":"375806/375806 [==============================] - 14s 37us/step\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"del word_index, embedding_matrix, embedding_index, all_embeds, model\ngc.collect()","execution_count":142,"outputs":[{"output_type":"execute_result","execution_count":142,"data":{"text/plain":"1681"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"## **Blend the 3 models**\nExplored 3 models using 3 different sets of pre-trained embeddings. Though they are similar, it is possible they might capture different type of information from the data. So lets blend them in equal proportions"},{"metadata":{},"cell_type":"markdown","source":"**prediction on validation set**"},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_val_y_combined = 0.33*pred_glove_val_y + 0.33*pred_fasttext_val_y + 0.34*pred_paragram_val_y\nfor thresh in np.arange(0.1, 0.5, 0.01):\n    thresh = np.round(thresh, 2)\n    score = round(metrics.f1_score(valid_y, (pred_val_y_combined > thresh).astype(int)),4)\n    print('F1 score at threshold {} is {}, combining all 3 models'.format(thresh, score))","execution_count":144,"outputs":[{"output_type":"stream","text":"F1 score at threshold 0.1 is 0.5185, combining all 3 models\nF1 score at threshold 0.11 is 0.5316, combining all 3 models\nF1 score at threshold 0.12 is 0.5427, combining all 3 models\nF1 score at threshold 0.13 is 0.5519, combining all 3 models\nF1 score at threshold 0.14 is 0.5614, combining all 3 models\nF1 score at threshold 0.15 is 0.5689, combining all 3 models\nF1 score at threshold 0.16 is 0.5767, combining all 3 models\nF1 score at threshold 0.17 is 0.5837, combining all 3 models\nF1 score at threshold 0.18 is 0.5895, combining all 3 models\nF1 score at threshold 0.19 is 0.5959, combining all 3 models\nF1 score at threshold 0.2 is 0.6013, combining all 3 models\nF1 score at threshold 0.21 is 0.6053, combining all 3 models\nF1 score at threshold 0.22 is 0.61, combining all 3 models\nF1 score at threshold 0.23 is 0.6134, combining all 3 models\nF1 score at threshold 0.24 is 0.6169, combining all 3 models\nF1 score at threshold 0.25 is 0.6196, combining all 3 models\nF1 score at threshold 0.26 is 0.6237, combining all 3 models\nF1 score at threshold 0.27 is 0.6264, combining all 3 models\nF1 score at threshold 0.28 is 0.6278, combining all 3 models\nF1 score at threshold 0.29 is 0.6292, combining all 3 models\nF1 score at threshold 0.3 is 0.6304, combining all 3 models\nF1 score at threshold 0.31 is 0.632, combining all 3 models\nF1 score at threshold 0.32 is 0.6318, combining all 3 models\nF1 score at threshold 0.33 is 0.6317, combining all 3 models\nF1 score at threshold 0.34 is 0.6332, combining all 3 models\nF1 score at threshold 0.35 is 0.6338, combining all 3 models\nF1 score at threshold 0.36 is 0.6342, combining all 3 models\nF1 score at threshold 0.37 is 0.6347, combining all 3 models\nF1 score at threshold 0.38 is 0.6334, combining all 3 models\nF1 score at threshold 0.39 is 0.633, combining all 3 models\nF1 score at threshold 0.4 is 0.6298, combining all 3 models\nF1 score at threshold 0.41 is 0.6275, combining all 3 models\nF1 score at threshold 0.42 is 0.6254, combining all 3 models\nF1 score at threshold 0.43 is 0.6224, combining all 3 models\nF1 score at threshold 0.44 is 0.6195, combining all 3 models\nF1 score at threshold 0.45 is 0.6174, combining all 3 models\nF1 score at threshold 0.46 is 0.6146, combining all 3 models\nF1 score at threshold 0.47 is 0.6092, combining all 3 models\nF1 score at threshold 0.48 is 0.6065, combining all 3 models\nF1 score at threshold 0.49 is 0.6012, combining all 3 models\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"__prediction on test set, using a suitable threshold__"},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_test_y_combined = 0.33*pred_glove_test_y + 0.33*pred_fasttext_test_y + 0.34*pred_paragram_test_y\npred_test_y_combined = (pred_test_y_combined > 0.35).astype(int)\n\nsubmission = pd.DataFrame({'qid': test_df['qid'].values})\nsubmission['prediction'] = pred_test_y_combined\n\nsubmission.to_csv(\"submission.csv\", index=False)\ndisplay(submission.head(10))","execution_count":147,"outputs":[{"output_type":"error","ename":"KeyError","evalue":"'text'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2645\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2646\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2647\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'text'","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-147-7327bdc1f42d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpred_test_y_combined\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpred_test_y_combined\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.35\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0msubmission\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'qid'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0msubmission\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'prediction'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred_test_y_combined\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2798\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2799\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2800\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2801\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2802\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2646\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2647\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2648\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2649\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2650\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'text'"]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}