{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":1,"outputs":[{"output_type":"stream","text":"/kaggle/input/quora-insincere-questions-classification/test.csv\n/kaggle/input/quora-insincere-questions-classification/sample_submission.csv\n/kaggle/input/quora-insincere-questions-classification/train.csv\n/kaggle/input/quora-insincere-questions-classification/embeddings.zip\n/kaggle/input/glove840b300dtxt/glove.840B.300d.txt\n","name":"stdout"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport time\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\n\nfrom tqdm import tqdm\nimport math\n\nimport seaborn as sns\n%matplotlib inline\n\nimport gc","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv('../input/quora-insincere-questions-classification/train.csv')\ntest_df = pd.read_csv('../input/quora-insincere-questions-classification/test.csv')\nprint(train_df.shape)\nprint(test_df.shape)\ndisplay(train_df.head())","execution_count":3,"outputs":[{"output_type":"stream","text":"(1306122, 3)\n(375806, 2)\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"                    qid                                      question_text  \\\n0  00002165364db923c7e6  How did Quebec nationalists see their province...   \n1  000032939017120e6e44  Do you have an adopted dog, how would you enco...   \n2  0000412ca6e4628ce2cf  Why does velocity affect time? Does velocity a...   \n3  000042bf85aa498cd78e  How did Otto von Guericke used the Magdeburg h...   \n4  0000455dfa3e01eae3af  Can I convert montra helicon D to a mountain b...   \n\n   target  \n0       0  \n1       0  \n2       0  \n3       0  \n4       0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>qid</th>\n      <th>question_text</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>00002165364db923c7e6</td>\n      <td>How did Quebec nationalists see their province...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>000032939017120e6e44</td>\n      <td>Do you have an adopted dog, how would you enco...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0000412ca6e4628ce2cf</td>\n      <td>Why does velocity affect time? Does velocity a...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>000042bf85aa498cd78e</td>\n      <td>How did Otto von Guericke used the Magdeburg h...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0000455dfa3e01eae3af</td>\n      <td>Can I convert montra helicon D to a mountain b...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Check for data imbalance"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(train_df.target)","execution_count":4,"outputs":[{"output_type":"execute_result","execution_count":4,"data":{"text/plain":"<matplotlib.axes._subplots.AxesSubplot at 0x7efd3fd96e90>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"metadata":{},"cell_type":"markdown","source":"Check for missing values"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.isnull().sum()","execution_count":5,"outputs":[{"output_type":"execute_result","execution_count":5,"data":{"text/plain":"qid              0\nquestion_text    0\ntarget           0\ndtype: int64"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.isna().sum()","execution_count":6,"outputs":[{"output_type":"execute_result","execution_count":6,"data":{"text/plain":"qid              0\nquestion_text    0\ndtype: int64"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Do the following in the next steps:\n\n* Split the train into train and validation sets. We will not do cross valdiation as it is time consuming\n* No missing values identified, if any, replace them with 'na'\n* Tokenize the `text` column and convert them to vector sequences\n* Pad or truncate the sequences as required - truncation happens when sequence length exceeds `max_len` and if less, they will be padded"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n# split into train and validation sets\n\ntrain_df, valid_df = train_test_split(train_df, test_size=0.1, random_state=2020)\n\n# some config values for tokenization and vector sequences\n\nmax_len = 100        # max number of words in the question that will be used\nmax_features = 50000 # max number of features or unique words we will use from the entire corpus (the same as number of rows in the embedding matrix)\nembed_size = 300     # size of each embedding or word vector","execution_count":7,"outputs":[{"output_type":"stream","text":"CPU times: user 470 ms, sys: 32.1 ms, total: 502 ms\nWall time: 511 ms\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n# substitute missing values in text\ntrain_X = train_df['question_text'].fillna(\"_na_\")\nvalid_X = valid_df['question_text'].fillna(\"_na_\")\ntest_X = test_df['question_text'].fillna(\"_na_\")\n\n# tokenize the sentences\nfrom keras.preprocessing.text import Tokenizer\n\ntokenizer = Tokenizer(num_words = max_features)\n\n# fit on train_X. fit_on_texts() expects a list of text as input\ntokenizer.fit_on_texts(train_X.values.tolist())\n\n# use fit_to_sequences method to encode the tokens or words into interger sequences\ntrain_X = tokenizer.texts_to_sequences(train_X.values)\nvalid_X = tokenizer.texts_to_sequences(valid_X.values)\ntest_X = tokenizer.texts_to_sequences(test_X.values)\n\n# pad the sentences, according to the max_len\nfrom keras.preprocessing.sequence import pad_sequences\n\ntrain_X = pad_sequences(train_X, maxlen = max_len)\nvalid_X = pad_sequences(valid_X, maxlen = max_len)\ntest_X = pad_sequences(test_X, maxlen = max_len)\n\n# store the target values\ntrain_y = train_df['target'].values\nvalid_y = valid_df['target'].values","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Without using any of the trained embeddings provided:\nWe will learn the embeddings from scratch without using any of the trained embeddings as the first step. For this we will train a Bidirectional GRU model. We will use the CUDA based NN model from Nvidia known as th CuDNNGRU, which is GPU based."},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Model, Sequential\nfrom keras.layers import Input, Embedding, CuDNNGRU, Dense, Dropout, LSTM, Conv1D, Activation, GRU\nfrom keras.layers import Bidirectional, GlobalMaxPool1D\n\nfrom keras import initializers, regularizers, constraints, optimizers, layers","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# tensorflow version check\nimport tensorflow as tf\nprint('tensor flow version in use: ', tf.__version__)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Using the CuDNNGRU is not importable as it seems to have been deprecated in recent versions of TF and I keep getting error 'ModuleNotFoundError: No module named 'tensorflow.contrib'', this is because this model is removed in the current version.\n\nThe better way is to simply use the GRU and or LSTM as it is, which will default to `CuDNNGRU` and `CuDNNLSTM`, if certain conditions are met. Refer [here](https://stackoverflow.com/questions/60468385/is-there-cudnnlstm-or-cudnngru-alternative-in-tensorflow-2-0)\n\nRefer to other links on how to import a `GRU` model:\n1. https://www.tensorflow.org/api_docs/python/tf/compat/v1/keras/layers/CuDNNGRU\n2. https://www.tensorflow.org/api_docs/python/tf/keras/layers/GRU"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\nmodel.add(Embedding(input_dim = max_features, output_dim = embed_size, input_length = max_len)) # input_shape is optional\nmodel.add(Bidirectional(GRU(64, return_sequences=True)))\nmodel.add(GlobalMaxPool1D())\nmodel.add(Dense(16, activation='relu'))\nmodel.add(Dropout(rate=0.1))\nmodel.add(Dense(1, activation='sigmoid'))\n\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n\nprint(model.summary())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Train the model on the given train split and monitor the metric on the validation set. Run for 2 epochs for now. Changing the epochs, batch_size, model parameters could give a better model"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n# train the model\nmodel.fit(train_X, train_y, batch_size=512, epochs =2 , validation_data = (valid_X, valid_y))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pickle\npickle.dump(model, open('bidirectional_gru_keras_no_pretrain_embed.pkl', 'wb'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*let's looks at the validation sample predictions and decide the best threshold for `F1` score. The actual values are `0` and `1`. Based on threshold, the predictions will vary.*\n\nHere we are learning embeddings and we don't use any of the pretrained embeddings that have been provided along with the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction_noembed_val_y = model.predict([valid_X], batch_size=1024, verbose=1)\n\nfor thresh in np.arange(0.1, 0.5, 0.01):\n    thresh = np.round(thresh, 2)\n    score = round(metrics.f1_score(valid_y, (prediction_noembed_val_y > thresh).astype(int)),4)\n    print('F1 score at threshold {} is {}'.format(thresh, score))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# predictions on test(no pretrained embedding in use)\npred_noembed_y = model.predict([test_X], batch_size=1024, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Clear memory before going to next step**"},{"metadata":{"trusted":true},"cell_type":"code","source":"del model\ngc.collect()\n\n# pause execution for 10s after gc to allow gc to complete\ntime.sleep(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Imported Glove840b300d embeddin file from kaggle"},{"metadata":{"trusted":true},"cell_type":"code","source":"import tqdm\n\nEMBEDDING_FILE = '../input/glove840b300dtxt/glove.840B.300d.txt'\n\n# fp = open(EMBEDDING_FILE, 'r', encoding='utf8')\n\n# for line in fp:\n#     values = line.split()\n#     word= values[0]\n#     coeff = np.asarray(values[1:], dtype='float32')\n#     print(word)\n#     print(coeff)\n#     break\n\n# fp.close()  ","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with open(EMBEDDING_FILE, 'r', encoding='utf8') as fp:\n    print(fp.readline())","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}