{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":1,"outputs":[{"output_type":"stream","text":"/kaggle/input/spooky-author-identification/train.zip\n/kaggle/input/spooky-author-identification/sample_submission.zip\n/kaggle/input/spooky-author-identification/test.zip\n","name":"stdout"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"!unzip '/kaggle/input/spooky-author-identification/train.zip'\n!unzip '/kaggle/input/spooky-author-identification/test.zip'\n!unzip '/kaggle/input/spooky-author-identification/sample_submission.zip'","execution_count":2,"outputs":[{"output_type":"stream","text":"Archive:  /kaggle/input/spooky-author-identification/train.zip\n  inflating: train.csv               \nArchive:  /kaggle/input/spooky-author-identification/test.zip\n  inflating: test.csv                \nArchive:  /kaggle/input/spooky-author-identification/sample_submission.zip\n  inflating: sample_submission.csv   \n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"for dirname, _, filenames in os.walk(os.getcwd()):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":3,"outputs":[{"output_type":"stream","text":"/kaggle/working/train.csv\n/kaggle/working/sample_submission.csv\n/kaggle/working/test.csv\n/kaggle/working/__notebook_source__.ipynb\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport time\nimport gc\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom sklearn import preprocessing, model_selection, metrics, decomposition","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# read data\ntrain = pd.read_csv('/kaggle/working/train.csv')\ntest = pd.read_csv('/kaggle/working/test.csv')\n\ntrain.head(10)","execution_count":5,"outputs":[{"output_type":"execute_result","execution_count":5,"data":{"text/plain":"        id                                               text author\n0  id26305  This process, however, afforded me no means of...    EAP\n1  id17569  It never once occurred to me that the fumbling...    HPL\n2  id11008  In his left hand was a gold snuff box, from wh...    EAP\n3  id27763  How lovely is spring As we looked from Windsor...    MWS\n4  id12958  Finding nothing else, not even gold, the Super...    HPL\n5  id22965  A youth passed in solitude, my best years spen...    MWS\n6  id09674  The astronomer, perhaps, at this point, took r...    EAP\n7  id13515        The surcingle hung in ribands from my body.    EAP\n8  id19322  I knew that you could not say to yourself 'ste...    EAP\n9  id00912  I confess that neither the structure of langua...    MWS","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>text</th>\n      <th>author</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>id26305</td>\n      <td>This process, however, afforded me no means of...</td>\n      <td>EAP</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>id17569</td>\n      <td>It never once occurred to me that the fumbling...</td>\n      <td>HPL</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>id11008</td>\n      <td>In his left hand was a gold snuff box, from wh...</td>\n      <td>EAP</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>id27763</td>\n      <td>How lovely is spring As we looked from Windsor...</td>\n      <td>MWS</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>id12958</td>\n      <td>Finding nothing else, not even gold, the Super...</td>\n      <td>HPL</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>id22965</td>\n      <td>A youth passed in solitude, my best years spen...</td>\n      <td>MWS</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>id09674</td>\n      <td>The astronomer, perhaps, at this point, took r...</td>\n      <td>EAP</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>id13515</td>\n      <td>The surcingle hung in ribands from my body.</td>\n      <td>EAP</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>id19322</td>\n      <td>I knew that you could not say to yourself 'ste...</td>\n      <td>EAP</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>id00912</td>\n      <td>I confess that neither the structure of langua...</td>\n      <td>MWS</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head(5)","execution_count":6,"outputs":[{"output_type":"execute_result","execution_count":6,"data":{"text/plain":"        id                                               text\n0  id02310  Still, as I urged our leaving Ireland with suc...\n1  id24541  If a fire wanted fanning, it could readily be ...\n2  id00134  And when they had broken down the frail door t...\n3  id27757  While I was thinking how I should possibly man...\n4  id04081  I am not sure to what limit his knowledge may ...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>id02310</td>\n      <td>Still, as I urged our leaving Ireland with suc...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>id24541</td>\n      <td>If a fire wanted fanning, it could readily be ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>id00134</td>\n      <td>And when they had broken down the frail door t...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>id27757</td>\n      <td>While I was thinking how I should possibly man...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>id04081</td>\n      <td>I am not sure to what limit his knowledge may ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Use label encoder to encode the text labels to integers"},{"metadata":{"trusted":true},"cell_type":"code","source":"le = preprocessing.LabelEncoder()\ny = le.fit_transform(train['author'])","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = train['text']\nX_train, X_valid, y_train, y_valid = model_selection.train_test_split(X, y, test_size=0.1, random_state= 2020, shuffle=True, stratify = train['author'])\nprint(X_train.shape)\nprint(X_valid.shape)","execution_count":8,"outputs":[{"output_type":"stream","text":"(17621,)\n(1958,)\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"### Some base models first"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n\ntfidf_vec = TfidfVectorizer(min_df = 3, max_df = 0.8, analyzer='word', ngram_range =(1,3), token_pattern = r'\\w{1,}',\n                        use_idf=True, smooth_idf=True, sublinear_tf=True)\n\n# fit to both train and valid sets\ntfidf_vec.fit(X_train.values.tolist() + X_valid.values.tolist())\n\n# transformed\nX_train_tfv = tfidf_vec.transform(X_train.values.tolist())\nX_valid_tfv = tfidf_vec.transform(X_valid.values.tolist())","execution_count":9,"outputs":[{"output_type":"stream","text":"CPU times: user 7.16 s, sys: 225 ms, total: 7.39 s\nWall time: 7.41 s\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"Fit a Logisitic Regression model on tfidf"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nfrom sklearn.linear_model import LogisticRegression\nlogreg = LogisticRegression(C=0.9)\n\nlogreg.fit(X_train_tfv, y_train)\npredictions = logreg.predict_proba(X_valid_tfv)\n\nprint('Log loss using Logisitic Regression on Tfidf Vectorizer is : ', metrics.log_loss(y_valid, predictions))","execution_count":10,"outputs":[{"output_type":"stream","text":"Log loss using Logisitic Regression on Tfidf Vectorizer is :  0.5664506284140641\nCPU times: user 7.49 s, sys: 119 ms, total: 7.61 s\nWall time: 3.96 s\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"### Use `wordcount` as features  instead of TFIDF using CountVectorizer"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nfrom sklearn.feature_extraction.text import CountVectorizer\n\ncount_vec = CountVectorizer(min_df = 3, max_df = 0.8, ngram_range=(1,3), stop_words='english', analyzer='word', token_pattern = r'\\w{1,}')\n\ncount_vec.fit(X_train.values.tolist() + X_valid.values.tolist())\nX_train_cv = count_vec.transform(X_train.values.tolist())\nX_valid_cv = count_vec.transform(X_valid.values.tolist())","execution_count":11,"outputs":[{"output_type":"stream","text":"CPU times: user 4.04 s, sys: 68.6 ms, total: 4.11 s\nWall time: 3.93 s\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"Fit a simple Logisitc regression model on Count Vectorizer"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nlogreg.fit(X_train_cv, y_train)\nprediction = logreg.predict_proba(X_valid_cv)\nprint('Log loss using Logisitic Regression on Count Vectorizer is : ', metrics.log_loss(y_valid, prediction))","execution_count":12,"outputs":[{"output_type":"stream","text":"Log loss using Logisitic Regression on Count Vectorizer is :  0.47578347792652315\nCPU times: user 2.59 s, sys: 31.8 ms, total: 2.62 s\nWall time: 1.34 s\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"### Naive Bayes model on Count Vectorizer"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nfrom sklearn.naive_bayes import MultinomialNB\n\nmnb = MultinomialNB()\nmnb.fit(X_train_cv, y_train)\nprediction = mnb.predict_proba(X_valid_cv)\nprint('Log loss using Multinomial NB on Count Vectorizer is : ', metrics.log_loss(y_valid, prediction))","execution_count":13,"outputs":[{"output_type":"stream","text":"Log loss using Multinomial NB on Count Vectorizer is :  0.45400575892684447\nCPU times: user 25.7 ms, sys: 2.03 ms, total: 27.8 ms\nWall time: 13.8 ms\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"### Naive Bayes model on Tfidf Vectorizer"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nfrom sklearn.naive_bayes import MultinomialNB\n\nmnb = MultinomialNB()\nmnb.fit(X_train_tfv, y_train)\nprediction = mnb.predict_proba(X_valid_tfv)\nprint('Log loss using Multinomial NB on Tfidf Vectorizer is : ', metrics.log_loss(y_valid, prediction))","execution_count":14,"outputs":[{"output_type":"stream","text":"Log loss using Multinomial NB on Tfidf Vectorizer is :  0.565051212698791\nCPU times: user 40.1 ms, sys: 1.04 ms, total: 41.1 ms\nWall time: 20 ms\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"### SVM(Support Vector Machine) on TFIDF - using SVD\nSince SVM takes a lot of time to on this high dimensional dataset, we will reduce the dimension using SVD (Singular Value Decomposition) befor applying SVM\n\nAlso it is important to standardise the data prior to applying SVM"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\nfrom sklearn.decomposition import TruncatedSVD\n\nn_comp = 20\n\nsvd = TruncatedSVD(n_components = n_comp)\n# fit the SVD on tf-id vector\nsvd.fit(X_train_tfv)\nX_train_tf_svd = svd.transform(X_train_tfv)\nX_valid_tf_svd = svd.transform(X_valid_tfv)\n\n# scale the data prior to applying SVM\nscaler = preprocessing.StandardScaler()\nscaler.fit(X_train_tf_svd)\nX_train_tf_svd_scaled = scaler.transform(X_train_tf_svd)\nX_valid_tf_svd_scaled = scaler.transform(X_valid_tf_svd)","execution_count":15,"outputs":[{"output_type":"stream","text":"CPU times: user 1.19 s, sys: 40.1 ms, total: 1.23 s\nWall time: 657 ms\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"Apply a simple SVM classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nfrom sklearn.svm import SVC\n\nsvc = SVC(C=0.9, probability = True)\nsvc.fit(X_train_tf_svd_scaled, y_train)\nprediction = svc.predict_proba(X_valid_tf_svd_scaled)\nprint('Log loss using SVC on TF-IDF Vectorizer with SVD is : ', metrics.log_loss(y_valid, prediction))","execution_count":16,"outputs":[{"output_type":"stream","text":"Log loss using SVC on TF-IDF Vectorizer with SVD is :  0.8541441385552606\nCPU times: user 2min, sys: 2.18 s, total: 2min 2s\nWall time: 2min 2s\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"### Using XGboost on the data\n\nFit the model on the original high dimension tf-idf vector. The vector will be compressed into 'csc' or 'csr' format before applying the fit method of xgboost\n\nFor more details on sparse matrices, refer [here](https://rushter.com/blog/scipy-sparse-matrices/)\n * CSR - Compressed Sparse Row - usually used when the number of rows is less than the number of columns\n * CSC - Compressed Sparse Column - usually when there are lesser number of columns than rows"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\nimport xgboost as xgb\nfrom scipy.sparse import csr_matrix # to convert the input into \n\nxgb_clf = xgb.XGBClassifier(n_estimators = 200, max_depth =7, learning_rate = 0.1, verbose = 2, colsample_bytree = 0.8, subsample =0.8, n_jobs=-1, nthread=10)\n\n# convert the input into Compressed Sparse Column format\nxgb_clf.fit(X_train_tfv.tocsc(), y_train)\npredictions = xgb_clf.predict_proba(X_valid_tfv.tocsc())\n\nprint('Log loss using Xgboost on the original TF-IDF Vectorizer is : ', metrics.log_loss(y_valid, prediction))","execution_count":17,"outputs":[{"output_type":"stream","text":"Log loss using Xgboost on the original TF-IDF Vectorizer is :  0.8541441385552606\nCPU times: user 6min 17s, sys: 5min 30s, total: 11min 48s\nWall time: 3min 2s\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"### Using Xgboost on the CountVectorizer"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n# convert the input into Compressed Sparse Column format\n\nxgb_clf = xgb.XGBClassifier(n_estimators = 200, max_depth =7, learning_rate = 0.1, verbose = 2, colsample_bytree = 0.8, subsample =0.8, n_jobs=-1, nthread=10)\n\nxgb_clf.fit(X_train_cv.tocsc(), y_train)\npredictions = xgb_clf.predict_proba(X_valid_cv.tocsc())\n\nprint('Log loss using Xgboost on the original Count Vectorizer is : ', metrics.log_loss(y_valid, prediction))","execution_count":18,"outputs":[{"output_type":"stream","text":"Log loss using Xgboost on the original Count Vectorizer is :  0.8541441385552606\nCPU times: user 1min 27s, sys: 1min 56s, total: 3min 23s\nWall time: 52.1 s\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"### Using Xgboost on the Tf-idf SVD features"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n# convert the input into Compressed Sparse Column format\n\nxgb_clf.fit(X_train_tf_svd, y_train)\npredictions = xgb_clf.predict_proba(X_valid_tf_svd)\n\nprint('Log loss using Xgboost on the original Count Vectorizer is : %0.3f' % metrics.log_loss(y_valid, prediction))","execution_count":26,"outputs":[{"output_type":"stream","text":"Log loss using Xgboost on the original Count Vectorizer is : 0.854\nCPU times: user 3.72 ms, sys: 1.13 ms, total: 4.85 ms\nWall time: 3.34 ms\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"### Using GridSearch"},{"metadata":{"trusted":true},"cell_type":"code","source":"# create a scoring function if you using a custom scorer\n\nlogloss_scorer = metrics.make_scorer(metrics.log_loss, greater_is_better = False, needs_proba = True)","execution_count":29,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Create a pipeline"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.pipeline import Pipeline\n\n# intialize SVD\nsvd = TruncatedSVD()\n\n# initialize Standard Scaler\nscaler = preprocessing.StandardScaler()\n\n# logistic regression\nlogreg = LogisticRegression()\n\n# Create a pipeline with Logistic Regression as the final estimator\n\npipe1 = Pipeline([\n                    ('svd', svd),\n                    ('scaler', scaler),\n                    ('logreg', logreg)\n                ])","execution_count":21,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* To get a view of the steps in the pipeline, use **pipe.named_steps()**\n* To access the parameters in the pipelines, use **pipe.get_params()**"},{"metadata":{"trusted":true},"cell_type":"code","source":"pipe1.get_params()","execution_count":22,"outputs":[{"output_type":"execute_result","execution_count":22,"data":{"text/plain":"{'memory': None,\n 'steps': [('svd',\n   TruncatedSVD(algorithm='randomized', n_components=2, n_iter=5,\n                random_state=None, tol=0.0)),\n  ('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)),\n  ('logreg',\n   LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n                      intercept_scaling=1, l1_ratio=None, max_iter=100,\n                      multi_class='auto', n_jobs=None, penalty='l2',\n                      random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n                      warm_start=False))],\n 'verbose': False,\n 'svd': TruncatedSVD(algorithm='randomized', n_components=2, n_iter=5,\n              random_state=None, tol=0.0),\n 'scaler': StandardScaler(copy=True, with_mean=True, with_std=True),\n 'logreg': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n                    intercept_scaling=1, l1_ratio=None, max_iter=100,\n                    multi_class='auto', n_jobs=None, penalty='l2',\n                    random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n                    warm_start=False),\n 'svd__algorithm': 'randomized',\n 'svd__n_components': 2,\n 'svd__n_iter': 5,\n 'svd__random_state': None,\n 'svd__tol': 0.0,\n 'scaler__copy': True,\n 'scaler__with_mean': True,\n 'scaler__with_std': True,\n 'logreg__C': 1.0,\n 'logreg__class_weight': None,\n 'logreg__dual': False,\n 'logreg__fit_intercept': True,\n 'logreg__intercept_scaling': 1,\n 'logreg__l1_ratio': None,\n 'logreg__max_iter': 100,\n 'logreg__multi_class': 'auto',\n 'logreg__n_jobs': None,\n 'logreg__penalty': 'l2',\n 'logreg__random_state': None,\n 'logreg__solver': 'lbfgs',\n 'logreg__tol': 0.0001,\n 'logreg__verbose': 0,\n 'logreg__warm_start': False}"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Now set the values for the parameters in the grid. Define a dictionary for the same"},{"metadata":{"trusted":true},"cell_type":"code","source":"param_grid = {\n                'svd__n_components': [120, 180],\n                'logreg__C': [0.1, 1.0, 10],\n                'logreg__penalty': ['l2', 'l1']\n            }","execution_count":23,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"When using Grid Search,\n1. To find the best score based on the scoring function: ** model.best_score_**\n2. Best set of parameters: ** model.best_estimator_.get_params() **"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\n# Intialize GridSearch Model\n\nfrom sklearn.model_selection import GridSearchCV\n\n# setting refit = True, takes the best parameters when traininf from the folds and retrains the model on the entire data using those best parameters\nmodel = GridSearchCV(estimator = pipe1, param_grid = param_grid, scoring = logloss_scorer, cv = 2, refit= True, verbose=10)\n\n# fit the gridsearch model. We can fit on the entire train, but here I will use only X_train with tf idf\nmodel.fit(X_train_tfv, y_train)\n\nprint('Best score is : %0.3f' % model.best_score_)\nprint('Best parameters set:')\nbest_parameters = model.best_estimator_.get_params()\n\nfor param_name in sorted(param_grid.keys()):\n    print(\"\\t%s: %r\" %(param_name, best_parameters[param_name]))","execution_count":31,"outputs":[{"output_type":"stream","text":"Fitting 2 folds for each of 12 candidates, totalling 24 fits\n[CV] logreg__C=0.1, logreg__penalty=l2, svd__n_components=120 ........\n","name":"stdout"},{"output_type":"stream","text":"[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n","name":"stderr"},{"output_type":"stream","text":"[CV]  logreg__C=0.1, logreg__penalty=l2, svd__n_components=120, score=-0.733, total=   2.9s\n[CV] logreg__C=0.1, logreg__penalty=l2, svd__n_components=120 ........\n","name":"stdout"},{"output_type":"stream","text":"[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.9s remaining:    0.0s\n","name":"stderr"},{"output_type":"stream","text":"[CV]  logreg__C=0.1, logreg__penalty=l2, svd__n_components=120, score=-0.736, total=   3.0s\n[CV] logreg__C=0.1, logreg__penalty=l2, svd__n_components=180 ........\n","name":"stdout"},{"output_type":"stream","text":"[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    5.9s remaining:    0.0s\n","name":"stderr"},{"output_type":"stream","text":"[CV]  logreg__C=0.1, logreg__penalty=l2, svd__n_components=180, score=-0.694, total=   4.6s\n[CV] logreg__C=0.1, logreg__penalty=l2, svd__n_components=180 ........\n","name":"stdout"},{"output_type":"stream","text":"[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   10.5s remaining:    0.0s\n","name":"stderr"},{"output_type":"stream","text":"[CV]  logreg__C=0.1, logreg__penalty=l2, svd__n_components=180, score=-0.687, total=   4.5s\n[CV] logreg__C=0.1, logreg__penalty=l1, svd__n_components=120 ........\n","name":"stdout"},{"output_type":"stream","text":"[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   15.0s remaining:    0.0s\n","name":"stderr"},{"output_type":"stream","text":"[CV]  logreg__C=0.1, logreg__penalty=l1, svd__n_components=120, score=nan, total=   2.8s\n[CV] logreg__C=0.1, logreg__penalty=l1, svd__n_components=120 ........\n","name":"stdout"},{"output_type":"stream","text":"[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   17.8s remaining:    0.0s\n","name":"stderr"},{"output_type":"stream","text":"[CV]  logreg__C=0.1, logreg__penalty=l1, svd__n_components=120, score=nan, total=   2.8s\n[CV] logreg__C=0.1, logreg__penalty=l1, svd__n_components=180 ........\n","name":"stdout"},{"output_type":"stream","text":"[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:   20.6s remaining:    0.0s\n","name":"stderr"},{"output_type":"stream","text":"[CV]  logreg__C=0.1, logreg__penalty=l1, svd__n_components=180, score=nan, total=   4.3s\n[CV] logreg__C=0.1, logreg__penalty=l1, svd__n_components=180 ........\n","name":"stdout"},{"output_type":"stream","text":"[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:   25.0s remaining:    0.0s\n","name":"stderr"},{"output_type":"stream","text":"[CV]  logreg__C=0.1, logreg__penalty=l1, svd__n_components=180, score=nan, total=   4.3s\n[CV] logreg__C=1.0, logreg__penalty=l2, svd__n_components=120 ........\n","name":"stdout"},{"output_type":"stream","text":"[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:   29.2s remaining:    0.0s\n","name":"stderr"},{"output_type":"stream","text":"[CV]  logreg__C=1.0, logreg__penalty=l2, svd__n_components=120, score=-0.736, total=   2.9s\n[CV] logreg__C=1.0, logreg__penalty=l2, svd__n_components=120 ........\n","name":"stdout"},{"output_type":"stream","text":"[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:   32.1s remaining:    0.0s\n","name":"stderr"},{"output_type":"stream","text":"[CV]  logreg__C=1.0, logreg__penalty=l2, svd__n_components=120, score=-0.731, total=   2.9s\n[CV] logreg__C=1.0, logreg__penalty=l2, svd__n_components=180 ........\n[CV]  logreg__C=1.0, logreg__penalty=l2, svd__n_components=180, score=-0.691, total=   4.5s\n[CV] logreg__C=1.0, logreg__penalty=l2, svd__n_components=180 ........\n[CV]  logreg__C=1.0, logreg__penalty=l2, svd__n_components=180, score=-0.688, total=   4.5s\n[CV] logreg__C=1.0, logreg__penalty=l1, svd__n_components=120 ........\n[CV]  logreg__C=1.0, logreg__penalty=l1, svd__n_components=120, score=nan, total=   2.8s\n[CV] logreg__C=1.0, logreg__penalty=l1, svd__n_components=120 ........\n[CV]  logreg__C=1.0, logreg__penalty=l1, svd__n_components=120, score=nan, total=   2.8s\n[CV] logreg__C=1.0, logreg__penalty=l1, svd__n_components=180 ........\n[CV]  logreg__C=1.0, logreg__penalty=l1, svd__n_components=180, score=nan, total=   4.3s\n[CV] logreg__C=1.0, logreg__penalty=l1, svd__n_components=180 ........\n[CV]  logreg__C=1.0, logreg__penalty=l1, svd__n_components=180, score=nan, total=   4.3s\n[CV] logreg__C=10, logreg__penalty=l2, svd__n_components=120 .........\n[CV]  logreg__C=10, logreg__penalty=l2, svd__n_components=120, score=-0.736, total=   2.9s\n[CV] logreg__C=10, logreg__penalty=l2, svd__n_components=120 .........\n[CV]  logreg__C=10, logreg__penalty=l2, svd__n_components=120, score=-0.735, total=   3.0s\n[CV] logreg__C=10, logreg__penalty=l2, svd__n_components=180 .........\n[CV]  logreg__C=10, logreg__penalty=l2, svd__n_components=180, score=-0.694, total=   4.8s\n[CV] logreg__C=10, logreg__penalty=l2, svd__n_components=180 .........\n[CV]  logreg__C=10, logreg__penalty=l2, svd__n_components=180, score=-0.685, total=   4.5s\n[CV] logreg__C=10, logreg__penalty=l1, svd__n_components=120 .........\n[CV]  logreg__C=10, logreg__penalty=l1, svd__n_components=120, score=nan, total=   2.8s\n[CV] logreg__C=10, logreg__penalty=l1, svd__n_components=120 .........\n[CV]  logreg__C=10, logreg__penalty=l1, svd__n_components=120, score=nan, total=   2.8s\n[CV] logreg__C=10, logreg__penalty=l1, svd__n_components=180 .........\n[CV]  logreg__C=10, logreg__penalty=l1, svd__n_components=180, score=nan, total=   4.3s\n[CV] logreg__C=10, logreg__penalty=l1, svd__n_components=180 .........\n[CV]  logreg__C=10, logreg__penalty=l1, svd__n_components=180, score=nan, total=   4.2s\n","name":"stdout"},{"output_type":"stream","text":"[Parallel(n_jobs=1)]: Done  24 out of  24 | elapsed:  1.5min finished\n","name":"stderr"},{"output_type":"stream","text":"Best score is : -0.690\nBest parameters set:\n\tlogreg__C: 10\n\tlogreg__penalty: 'l2'\n\tsvd__n_components: 180\nCPU times: user 2min 12s, sys: 27.9 s, total: 2min 40s\nWall time: 1min 33s\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"We will do the same using MultinomialNB model on tf-idf data"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\nnb_model = MultinomialNB()\n\n# create a pipeline\n\npipe2 = Pipeline([('nb', nb_model)])\n\n# parameter grid\n# try with the alpha parameter\n# pipe2.get_params()\n\nparam_grid = {'nb__alpha': [0.001, 0.01, 0.1, 1, 10, 100]}\n\n# intialize the Grid SearchCV model\nmodel = GridSearchCV(estimator = pipe2, param_grid = param_grid, cv = 2, refit = True, scoring = logloss_scorer, verbose=10, n_jobs=-1)\n\nmodel.fit(X_train_tfv, y_train)\nprint(\"best score is :\",format(model.best_score_))\nprint('best parameters are: ')\nbest_parameters = model.best_estimator_.get_params()\n\nfor param_name in sorted(param_grid.keys()):\n    print('\\t%s: %r' %(param_name, best_parameters[param_name]))","execution_count":37,"outputs":[{"output_type":"stream","text":"Fitting 2 folds for each of 6 candidates, totalling 12 fits\nbest score is : -0.4518777178062823\nbest parameters are: \n/tnb__alpha: 0.1\nCPU times: user 66 ms, sys: 8.33 ms, total: 74.3 ms\nWall time: 193 ms\n","name":"stdout"},{"output_type":"stream","text":"[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n[Parallel(n_jobs=-1)]: Batch computation too fast (0.0587s.) Setting batch_size=2.\n[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    0.1s\n[Parallel(n_jobs=-1)]: Done   7 out of  12 | elapsed:    0.1s remaining:    0.1s\n[Parallel(n_jobs=-1)]: Done   9 out of  12 | elapsed:    0.2s remaining:    0.1s\n[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:    0.2s finished\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}